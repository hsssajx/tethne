% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{tethne Documentation}
\date{February 28, 2014}
\release{0.3.1-alpha}
\author{Author}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


\includegraphics[width=1.000\linewidth]{logo.jpeg}

Tethne provides tools for easily parsing and analyzing bibliographic data in Python.
The primary emphasis is on working with data from the ISI Web of Science database, and
providing efficient methods for modeling and analyzing citation-based networks. Future
versions will include support for PubMed, Scopus, and other databases.

As of v0.3, Tethne is beginning to include methods for incorporating data from the \href{http://dfr.jstor.org}{JSTOR
Data-for-Research service}, and \href{http://mallet.cs.umass.edu/topics.php}{MALLET topic modeling}.

Tethne relies on \href{http://networkx.github.io/}{NetworkX} for graph classes, and leverages its network
analysis algorithms. You can visualize networks produced with Tethne in \href{http://www.cytoscape.org/}{Cytoscape} or \href{https://gephi.org/}{Gephi}.

To get started, consult the tutorial. For support, visit our \href{https://github.com/diging/tethne/issues}{GitHub
repository}.


\chapter{Contents}
\label{index:tethne-bibliographic-network-analysis-in-python}\label{index:contents}\label{index:repository}

\section{Installation}
\label{install:installation}\label{install::doc}\label{install:id1}
The following sections describe how to install the Tethne package and TethneGUI. Since
Tethne is under active development, we're making improvements and adding features all the
time. It's a good idea to stay on top of new releases. To get notifications about new
releases, you should watch our GitHub repository.

\includegraphics[width=0.900\linewidth]{{install.2}.png}
\begin{enumerate}
\item {} 
Find our GitHub repository at
\href{https://github.com/diging/tethne}{https://github.com/diging/tethne}

\item {} 
Click the \textbf{Watch} button in the upper-right corner of the page, and select
\textbf{Watching}.

\end{enumerate}


\subsection{How to get help}
\label{install:how-to-get-help}
Tethne is under active development, so you will most certainly run into bugs and hiccups.
If you run into trouble, please create a new issue in our
\href{https://github.com/diging/tethne/issues?state=open}{issue tracker}. This will help us
to hunt down problems, and will ensure that you get updates as we work to solve those
problems.


\subsection{Requirements}
\label{install:requirements}
Tethne requires the following software and packages.:
\begin{itemize}
\item {} 
{\hyperref[install:python]{\emph{Python 2.7}}}

\item {} 
{\hyperref[install:numpy]{\emph{NumPy}}}

\item {} 
{\hyperref[install:nltk]{\emph{NLTK}}}

\item {} 
{\hyperref[install:nx]{\emph{NetworkX}}}

\end{itemize}


\subsubsection{Anaconda}
\label{install:anaconda}
We recommend installing \href{http://continuum.io/downloads}{Anaconda}, which will install
Python, Numpy, NLTK, and a variety of other useful libraries. Installation instructions
for Anaconda can be found \href{http://docs.continuum.io/anaconda/install.html}{here}. This
may be a good idea \emph{even if you already have Python installed on your system}.


\subsubsection{Python 2.7}
\label{install:python}\label{install:python-2-7}
Tethne requires Python 2.7; Python 3 is not fully backwards-compatible, and Tethne will
not work properly with that version. \textbf{If you installed} \href{http://continuum.io/downloads}{Anaconda}, \textbf{Python 2.7 should
already be installed.}

You may already have Python installed on your system. To find out, open a new
command-line window. On Mac, find \code{Terminal} in \code{Applications \textgreater{} Utilities}; on
Windows, go to \code{Start \textgreater{} All Programs \textgreater{} Accessories \textgreater{} Command Prompt}. Type in \code{python}
and press enter. If Python is installed, the command-line interpreter should start:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python
Python 2.7.5 \textbar{}Anaconda 1.6.1 \PYG{o}{(}x86\PYGZus{}64\PYG{o}{)}\textbar{} \PYG{o}{(}default, Jun 28 2013, 22:20:13\PYG{o}{)}
\PYG{o}{[}GCC 4.0.1 \PYG{o}{(}Apple Inc. build 5493\PYG{o}{)}\PYG{o}{]} on darwin
Type \PYG{l+s+s2}{\PYGZdq{}help\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}copyright\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}credits\PYGZdq{}} or \PYG{l+s+s2}{\PYGZdq{}license\PYGZdq{}} \PYG{k}{for }more information.
\PYGZgt{}\PYGZgt{}\PYGZgt{}
\end{Verbatim}

Note that the version number (\code{Python 2.7.5}) is listed in the first line when the
interpreter starts. If you have Python 2.7.x, you're good to go.

If Python is not installed, or you have the wrong version of Python, you can find the
latest versions of Python \href{http://www.python.org/downloads/}{here}.

\textbf{Windows users} should use the 32-bit version of Python. Look for the \code{Windows x86 MSI Installer}. For details about installing Python on Windows, see \href{http://python-guide.readthedocs.org/en/latest/starting/install/win/}{Installing Python on Windows}.


\subsubsection{NumPy}
\label{install:id4}\label{install:numpy}
NumPy stands for Numerical Python. NumPy is a Python library that provides functionality
for scientific computing.

\textbf{If you installed} \href{http://continuum.io/downloads}{Anaconda}, \textbf{NumPy should already be installed}. Otherwise, you can
find an installer for your operating system on the
\href{http://sourceforge.net/projects/numpy/files/NumPy/1.8.0/}{NumPy SourceForge project}.
Mac users should download and install \code{numpy-1.8.0-py2.7-python.org-macosx10.6.dmg}.
Windows users should download and install \code{numpy-1.8.0-win32-superpack-python2.7.exe}.


\subsubsection{NLTK}
\label{install:id5}\label{install:nltk}
NLTK stands for Natural Language ToolKit. \textbf{If you installed} \href{http://continuum.io/downloads}{Anaconda}, \textbf{NLTK should
already be installed.} For installation instructions, see the
\href{http://www.nltk.org/install.html}{NLTK documentation}.


\subsubsection{NetworkX}
\label{install:nx}\label{install:networkx}
\href{http://networkx.github.io/}{NetworkX} is a Python package for network analysis. The
easiest way to install NetworkX is to use \code{pip}. \code{pip} installs Python packages from
the \href{https://pypi.python.org/pypi}{Python Package Index}. You will need to be connected
to the internet in order for \code{pip} to successfully download and install packages.

First, check to see whether you have \code{pip} installed. Open the command prompt, and enter
\code{pip -{-}version}. If \code{pip} is installed, you should see something like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }pip \PYGZhy{}\PYGZhy{}version
pip 1.3.1 from /anaconda/lib/python2.7/site\PYGZhy{}packages \PYG{o}{(}python 2.7\PYG{o}{)}
\end{Verbatim}

Otherwise, you'll need to install \code{pip}. See
\href{http://pip.readthedocs.org/en/latest/installing.html}{this installation guide}.

Once \code{pip} is installed, install NetworkX by entering the following in the command
prompt:

\begin{Verbatim}[commandchars=\\\{\}]
\$ sudo pip install networkx
\end{Verbatim}

You will be prompted to enter your password.

If all goes well, you should be able to \code{import} NetworkX in Python:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python
 Python 2.7.5 \textbar{}Anaconda 1.6.1 \PYG{o}{(}x86\PYGZus{}64\PYG{o}{)}\textbar{} \PYG{o}{(}default, Jun 28 2013, 22:20:13\PYG{o}{)}
 \PYG{o}{[}GCC 4.0.1 \PYG{o}{(}Apple Inc. build 5493\PYG{o}{)}\PYG{o}{]} on darwin
 Type \PYG{l+s+s2}{\PYGZdq{}help\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}copyright\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}credits\PYGZdq{}} or \PYG{l+s+s2}{\PYGZdq{}license\PYGZdq{}} \PYG{k}{for }more information.
 \PYGZgt{}\PYGZgt{}\PYGZgt{} import networkx
 \PYGZgt{}\PYGZgt{}\PYGZgt{}
\end{Verbatim}


\subsection{Tethne for Python and Command-line}
\label{install:tethne-for-python-and-command-line}

\subsubsection{From PyPI}
\label{install:from-pypi}
Tethne is available via the Python Package Index. You can install the latest release using
\code{pip}

\begin{Verbatim}[commandchars=\\\{\}]
\$ sudo pip install tethne
Password:
Downloading/unpacking tethne
  Downloading tethne-0.3.0-alpha.tar.gz (61kB): 61kB downloaded
  Running setup.py egg\_info for package tethne

Installing collected packages: tethne
  Running setup.py install for tethne

Successfully installed tethne
Cleaning up...
\end{Verbatim}


\subsubsection{From GitHub}
\label{install:from-github}
Alternatively, you can find the latest release of Tethne in our
\href{https://github.com/diging/tethne/releases}{GitHub repository}.

\includegraphics[width=0.600\linewidth]{{install.0}.png}
\begin{enumerate}
\item {} 
Download the source code.

\item {} 
Unpack the .zip/.tar.gz archive (e.g. \code{tethne-0.3.1-alpha.zip}). This should
create a new folder, e.g. \code{tethne-0.3.1-alpha}.

\item {} 
Open the command prompt, and navigate to the folder where you unpacked Tethne. For
example, if you unpacked Tethne in your Downloads folder, use:

\begin{Verbatim}[commandchars=\\\{\}]
\$ cd \textasciitilde{}/Downloads
\end{Verbatim}

\item {} 
If you have \code{pip} installed, use:

\begin{Verbatim}[commandchars=\\\{\}]
\$ sudo pip install ./tethne-0.3.1-alpha
\end{Verbatim}

\end{enumerate}

(change \code{tethne-0.3.1-alpha} to reflect the release that you downloaded).
\begin{enumerate}
\setcounter{enumi}{4}
\item {} 
If you don't have \code{pip}, you can use:

\begin{Verbatim}[commandchars=\\\{\}]
\$ sudo python ./tethne-0.3.1-alpha/setup.py install
\end{Verbatim}

\end{enumerate}

If Tethne is installed successfully, you should be able to \code{import} it in the Python
interpreter:

\begin{Verbatim}[commandchars=\\\{\}]
\$ python
Python 2.7.5 \textbar{}Anaconda 1.6.1 (x86\_64)\textbar{} (default, Jun 28 2013, 22:20:13)
[GCC 4.0.1 (Apple Inc. build 5493)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
\textgreater{}\textgreater{}\textgreater{} import tethne.readers as rd
\textgreater{}\textgreater{}\textgreater{}
\end{Verbatim}


\subsubsection{Alias}
\label{install:alias}\label{install:id7}
To make using Tethne from the command-line a bit easier, create a permanent alias.

\textbf{Mac:}

Add the following line to \code{\textasciitilde{}/.bash\_profile}:

\begin{Verbatim}[commandchars=\\\{\}]
alias tethne='python [TETHNE PATH]'
\end{Verbatim}
\begin{enumerate}
\item {} 
To find the \code{{[}TETHNE PATH{]}}, start the Python interpreter in Terminal, and import
Tethne. Then call \code{tethne.\_\_file\_\_}. In the example below, the path that we're
looking for is \code{/anaconda/lib/python2.7/site-packages/tethne}:

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python
Python 2.7.5 \textbar{}Anaconda 1.6.1 \PYG{o}{(}x86\PYGZus{}64\PYG{o}{)}\textbar{} \PYG{o}{(}default, Jun 28 2013, 22:20:13\PYG{o}{)}
\PYG{o}{[}GCC 4.0.1 \PYG{o}{(}Apple Inc. build 5493\PYG{o}{)}\PYG{o}{]} on darwin
Type \PYG{l+s+s2}{\PYGZdq{}help\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}copyright\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}credits\PYGZdq{}} or \PYG{l+s+s2}{\PYGZdq{}license\PYGZdq{}} \PYG{k}{for }more information.
\PYGZgt{}\PYGZgt{}\PYGZgt{} import tethne
\PYGZgt{}\PYGZgt{}\PYGZgt{} tethne.\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}
\PYG{l+s+s1}{\PYGZsq{}//anaconda/lib/python2.7/site\PYGZhy{}packages/tethne/\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.pyc\PYGZsq{}}
\PYGZgt{}\PYGZgt{}\PYGZgt{}
\end{Verbatim}
\begin{enumerate}
\setcounter{enumi}{1}
\item {} 
In TextWrangler, open the file \code{.bash\_profile} in your Home directory. You may need
to set \code{Enable} to \code{Everything}, and check the \code{Show hidden files} checkbox.

\end{enumerate}

\includegraphics[width=0.600\linewidth]{{install.4}.png}
\begin{enumerate}
\setcounter{enumi}{2}
\item {} 
Add the line \code{alias tethne='python {[}TETHNE PATH{]}'}
(change \code{{[}TETHNE PATH{]}} to the Tethne installation path, from step 1) to the end of
\code{.\_bash\_profile}, then save and close the file.

\end{enumerate}

\includegraphics[width=0.600\linewidth]{{install.5}.png}
\begin{enumerate}
\setcounter{enumi}{3}
\item {} 
Open a new Terminal window, and enter \code{tethne}. If all goes well, you should see:

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne
Must specify \PYGZhy{}\PYGZhy{}dataset\PYGZhy{}id
\end{Verbatim}


\subsection{TethneGUI}
\label{install:tethnegui}
A demonstration graphical user interface was created for teaching purposes only. This is
not intended for extensive use. It provides a very basic interface to the Tethne
command-line workflow.

TethneGUI comes bundled with most of the things that it needs to run. On \textbf{Windows}
systems, however, you will need to install NumPy independently. See {\hyperref[install:numpy]{\emph{NumPy}}}, above.

You can find the most recent build of the TethneGUI on the \href{http://sourceforge.net/projects/neotomaphenax/?source=directory}{Neotoma phenax SourceForge
repository}.

\includegraphics[width=0.600\linewidth]{{install.1}.png}
\begin{enumerate}
\item {} 
Download the version of TethneGUI appropriate for your operating system. Look
for the green download button near the center of the page. Clicking this button will
take you to a new page, and after a few seconds you should start downloading a
.zip archive (e.g. \code{TethneGUI-0.1-osx.zip})

\item {} 
Once the download completes, unpack it. This will create a new directory called
\code{TethneGUI}. Move this directory to a place in your filesystem where you can find it
later (e.g. your \code{Applications} folder).

\item {} 
Look inside the \code{TethneGUI} folder. \textbf{On Mac}, double-click \code{TethneGUI.app},
inside. \textbf{On Windows}, run \code{TethneGUI.exe}.

\end{enumerate}

Once TethneGUI loads, you should see a window that looks like this:

\includegraphics[width=0.600\linewidth]{{install.3}.png}


\section{Tutorial}
\label{tutorial::doc}\label{tutorial:tutorial}
Tethne is primarily developed as a Python package, but can also be invoked from the
command-line (Mac OSX, Linux; untested for Windows).


\subsection{Getting Bibliographic Data}
\label{tutorial.getting_data:getting-bibliographic-data}\label{tutorial.getting_data:gettingdata}\label{tutorial.getting_data::doc}
The current version of Tethne supports bibliographic data from the ISI Web of Science
and JSTOR's Data-for-Research portal. Future releases will support data from PubMed and
Scopus.


\subsubsection{Web of Science}
\label{tutorial.getting_data:web-of-science}
The ISI Web of Science is a proprietary database owned by Thompson Reuters.
If you are affiliated with an academic institution, you may have access to
this database via an institutional license.

To access the Web of Science database via the Arizona State University library,
find the Web of Science \href{http://library.lib.asu.edu/record=e1000458}{entry} in the library's online catalog. You may be prompted
to log in to the University's Central Authentication System.

\includegraphics[width=0.600\linewidth]{{getting.0}.png}

Perform a search for literature of interest using the interface provided.

Your search criteria will be informed by the objectives of your research project. If you
are attempting to characterize the development of a research field, for example, you
should choose terms that pick out that field as uniquely as possible (consider using the
\code{Publication Name} search field). You can also pick out literatures originating from
particular institutions, by using the \code{Organization-Enhanced} search field.

\includegraphics[width=0.600\linewidth]{{getting.1}.png}

Note also that you can restrict your research to one of three indexes in the Web of Science Core Collection:
\begin{itemize}
\item {} 
Science Citation Index Expanded is the largest index, containing scientific
publications from 1900 onward.

\item {} 
Social Sciences Citation Index covers 1956 onward.

\item {} 
Arts \& Humanities Citation Index is the smallest index, containing publications from
1975 onward.

\end{itemize}

\includegraphics[width=0.600\linewidth]{{getting.1.2}.png}

Once you have found the papers that you are interested in, find the \code{Send to:} menu
at the top of the list of results. Click the small orange down-arrow, and select
\code{Other File Formats}.

\includegraphics[width=0.600\linewidth]{{getting.2}.png}

A small in-browser window should open in the foreground. Specify the range of
records that you wish to download. \textbf{Note that you can only download 500 records
at a time}, so you may have to make multiple download requests. Be sure to specify
\code{Full Record and Cited References} in the \emph{Record Content} field, and \code{Plain Text}
in the \emph{File Format} field. Then click \code{Send}.

\includegraphics[width=0.600\linewidth]{{getting.3}.png}

After a few moments, a download should begin. WoS usually returns a field-tagged
data file called \code{savedrecs.txt}. Put this in a location on your filesystem where
you can find it later; this is the input for Tethne's WoS reader methods.

\includegraphics[width=0.600\linewidth]{{getting.4}.png}


\paragraph{Structure of the WoS Field-Tagged Data File}
\label{tutorial.getting_data:structure-of-the-wos-field-tagged-data-file}\label{tutorial.getting_data:fieldtagged}
If you open the text file returned by the WoS database (usually named `savedrecs.txt'),
you should see a whole bunch of field-tagged data. ``Field-tagged'' means that each metadata
field is denoted by a ``tag'' (a two-letter code), followed by values for that field. A
complete list of WoS field tags can be found \href{http://images.webofknowledge.com/WOKRS53B4/help/WOS/hs\_wos\_fieldtags.html}{here}. For best results, you should avoid
making changes to the contents of WoS data files.

The metadata record for each paper in your data file should begin with:

\begin{Verbatim}[commandchars=\\\{\}]
PT J
\end{Verbatim}

...and end with:

\begin{Verbatim}[commandchars=\\\{\}]
ER
\end{Verbatim}

There are two author fields: the AU field is always provided, and values take the form
``Last, FI''. AF is provided if author full-names are available, and values take the form
``Last, First Middle''. For example:

\begin{Verbatim}[commandchars=\\\{\}]
AU Dauvin, JC
   Grimes, S
   Bakalem, A
AF Dauvin, Jean\PYGZhy{}Claude
   Grimes, Samir
   Bakalem, Ali
\end{Verbatim}

Citations are listed in the CR block. For example:

\begin{Verbatim}[commandchars=\\\{\}]
CR Airoldi L, 2007, OCEANOGR MAR BIOL, V45, P345
   Alexander Vera, 2011, Marine Biodiversity, V41, P545, DOI 10.1007/s12526-011-0084-1
   Arvanitidis C, 2002, MAR ECOL PROG SER, V244, P139, DOI 10.3354/meps244139
   Bakalem A, 2009, ECOL INDIC, V9, P395, DOI 10.1016/j.ecolind.2008.05.008
   Bakalem Ali, 1995, Mesogee, V54, P49
   â€¦
   Zenetos A, 2005, MEDITERR MAR SCI, V6, P63
   Zenetos A, 2004, CIESM ATLAS EXOTIC S, V3
\end{Verbatim}

More recent records also include the institutional affiliations of authors in the C1
block.

\begin{Verbatim}[commandchars=\\\{\}]
C1 [Wang, Changlin; Washida, Haruhiko; Crofts, Andrew J.; Hamada, Shigeki;
Katsube-Tanaka, Tomoyuki; Kim, Dongwook; Choi, Sang-Bong; Modi, Mahendra; Singh,
Salvinder; Okita, Thomas W.] Washington State Univ, Inst Biol Chem, Pullman, WA 99164
USA.
\end{Verbatim}

For more information about WoS field tags, see a list on the Thompson Reuters website,
\href{http://images.webofknowledge.com/WOKRS53B4/help/WOS/hs\_wos\_fieldtags.html}{here}.


\subsubsection{JSTOR Data-for-Research}
\label{tutorial.getting_data:jstor-data-for-research}\label{tutorial.getting_data:id1}
The \href{http://dfr.jstor.org/?\&helpview=about\_dfr}{JSTOR Data-for-Research (DfR) portal}
gives researchers access to bibliographic data and N-grams for the entire JSTOR database.
Tethne can use DfR data to generate coauthorship networks, and to improve metadata for Web
of Science records. Increasingly, Tethne is also able to use N-gram counts to add
information to networks, and can generate corpora for common topic modeling tools (coming
soon!).

Access the DfR portal at
\href{http://dfr.jstor.org/}{http://dfr.jstor.org/} If you don't already have an account,
you will need to \href{http://dfr.jstor.org/accounts/register/}{create a new account}.

After you've logged in, perform a search using whatever criteria you please. When you have
achieved the result that you desire, create a new dataset request. Under the ``Dataset
Request'' menu in the upper-right corner of the page, click ``Submit new request''.

\includegraphics[width=0.600\linewidth]{{getting.5}.png}

On the \textbf{Download Options} page, select your desired \textbf{Data Type}. If you do not intend
to make use of the contents of the papers themselves, then ``Citations Only'' is sufficient.
Otherwise, choose word counts, bigrams, etc.

\textbf{Output Format} should be set to \textbf{XML}.

Give your request a title, and set the maximum number of articles. \emph{Note that the maximum
documents allowed per request is 1,000. Setting **Maximum Articles*} to a value less than
the number of search results will yield a random sample of your results.*

\includegraphics[width=0.600\linewidth]{{getting.6}.png}

Your request should now appear in your list of \textbf{Data Requests}. When your request is
ready (hours to days later), you will receive an e-mail with a download link. When
downloading from the \textbf{Data Requests} list, be sure to use the link in the
\textbf{full dataset} column.

\includegraphics[width=0.600\linewidth]{{getting.7}.png}

When your dataset download is complete, unzip it. The contents should look something like
those shown below.

\includegraphics[width=0.400\linewidth]{{getting.8}.png}

\code{citations.XML} contains bibliographic data in XML format. The \code{bigrams}, \code{trigrams},
\code{wordcounts} folders contain N-gram counts for each document.

In the example above, the path this dataset is
\emph{/Users/erickpeirson/Downloads/DfR/ecology\_1960-64}. This is the path used in
{\hyperref[tethne.readers:tethne.readers.dfr.read]{\code{tethne.readers.dfr.read()}}} .


\subsection{Quickstart (Command-line)}
\label{tutorial.quickstart.commandline::doc}\label{tutorial.quickstart.commandline:quickstart-command-line}
Use the following sequence of commands to generate a dynamic co-authorship network using
data from the ISI Web of Science database. The examples below are from the Mac
terminal, but should work on the Windows command-prompt as well.

For detailed documentation of command-line options, see {\hyperref[commandline:commandline-options]{\emph{Command-line Options}}}.

Tethne is invoked using \code{python ./tethne}, where \code{./tethne} is the path to the Tethne
\begin{enumerate}
\item {} 
{\hyperref[commandline:cl-read]{\emph{Read}}}

\end{enumerate}

Tethne can parse data from the Web of Science, JSTOR Data-for-Research, and a few other
sources.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python ./tethne \PYGZhy{}I example\PYGZus{}data \PYGZhy{}O ./ \PYGZhy{}\PYGZhy{}read\PYGZhy{}file \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}P /Users/erickpeirson/Desktop/savedrecs \PYG{o}{(}101\PYG{o}{)}.txt \PYGZhy{}F WOS

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Read
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Reading WOS data from file /Users/erickpeirson/Desktop/savedrecs.txt...done.
Read 500 papers in 1.42379593849 seconds. Accession: 90a0e7fe\PYGZhy{}c081\PYGZhy{}4749\PYGZhy{}9e7c\PYGZhy{}43534d9b9558.
Generating a new DataCollection...done.
Saving DataCollection to /tmp/example\PYGZus{}data\PYGZus{}DataCollection.pickle...done.
\end{Verbatim}

\code{-I example\_data} tells Tethne to use the ID \code{example\_data} for this dataset. This
should be used for each workflow step. \code{-O ./} tells Tethne to save output (e.g.
statistics and networks) to the current working directory.

\code{-F WOS} tells Tethne that the data is in Web of Science field-tagged format.
\begin{enumerate}
\setcounter{enumi}{1}
\item {} 
{\hyperref[commandline:cl-slice]{\emph{Slice}}}

\end{enumerate}

The \code{slice} step tells Tethne how to partition your dataset for analysis.

If you are studying network evolution over time, your first slice axis will almost always
be \code{date}. In the example below, \code{-S date,jtitle} tells Tethne to slice first by
\code{date}, then by \code{jtitle}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python ./tethne \PYGZhy{}I example\PYGZus{}data \PYGZhy{}O ./ \PYGZhy{}\PYGZhy{}slice \PYGZhy{}S date,jtitle \PYGZhy{}M time\PYGZus{}period \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}slice\PYGZhy{}window\PYGZhy{}size\PYG{o}{=}2 \PYGZhy{}\PYGZhy{}cumulative

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Slice
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection from /tmp/example\PYGZus{}data\PYGZus{}DataCollection.pickle...done.
Slicing DataCollection by date...done.
Slicing DataCollection by jtitle...done.
Saving slice distribution to .//example\PYGZus{}data\PYGZus{}sliceDistribution.csv...done.
Saving sliced DataCollection to /tmp/example\PYGZus{}data\PYGZus{}DataCollection\PYGZus{}sliced.pickle...done.
\end{Verbatim}

\code{-M time\_period -{-}slice-window-size=2} tells Tethne to divide the dataset
up into two-year time-periods. \code{-{-}cumulative} means that each time-period will include
data from all of the earlier time-periods.
\begin{enumerate}
\setcounter{enumi}{2}
\item {} 
{\hyperref[commandline:cl-graph]{\emph{Graph}}}

\end{enumerate}

The \code{graph} step generates networks from your data (one network per slice).

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python ./tethne \PYGZhy{}I example\PYGZus{}data \PYGZhy{}O ./ \PYGZhy{}\PYGZhy{}graph \PYGZhy{}N author \PYGZhy{}T coauthors \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}edge\PYGZhy{}attr\PYG{o}{=}date,jtitle,ayjid

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Graph
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection with slices from /tmp/example\PYGZus{}data\PYGZus{}DataCollection\PYGZus{}sliced.pickle...done.
Using first slice in DataCollection: date.
Building author graph using coauthors method...done in 1.90734863281e\PYGZhy{}05 seconds.
Saving GraphCollection to /tmp/example\PYGZus{}data\PYGZus{}GraphCollection.pickle...done.
Writing graph summaries to .//example\PYGZus{}data\PYGZus{}graphs.csv...done.
\end{Verbatim}

\code{-N author -T coauthors} tells
Tethne to generate a coauthorship network, where nodes are authors.
\code{-{-}edge-attr=date,jtitle} tells Tethne to add the publication date and journal to each
coauthorship edge.

Adding \code{-{-}merged} would tell Tethne to ignore slicing and create a single network from
the whole dataset.
\begin{enumerate}
\setcounter{enumi}{3}
\item {} 
{\hyperref[commandline:cl-analyze]{\emph{Analyze}}}

\end{enumerate}

The \code{analyze} step is optional. This uses methods from NetworkX and the
{\hyperref[tethne.analyze:module-tethne.analyze]{\code{tethne.analyze}}} module to analyze your networks.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python ./tethne \PYGZhy{}I example\PYGZus{}data \PYGZhy{}O ./ \PYGZhy{}\PYGZhy{}analyze \PYGZhy{}A betweenness\PYGZus{}centrality

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Analyze
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading GraphCollection from /tmp/example\PYGZus{}data\PYGZus{}GraphCollection.pickle...done.
Analyzing GraphCollection with betweenness\PYGZus{}centrality...done.
Writing graph analysis results to .//example\PYGZus{}data\PYGZus{}betweenness\PYGZus{}centrality\PYGZus{}analysis.csv...done.
Saving GraphCollection to /tmp/example\PYGZus{}data\PYGZus{}GraphCollection.pickle...done.
\end{Verbatim}

\code{-A betweenness\_centrality} tells Tethne to calculate the betweenness centrality of each
node in each network, and save those values as node attributes.
\begin{enumerate}
\setcounter{enumi}{4}
\item {} 
{\hyperref[commandline:cl-write]{\emph{Write}}}

\end{enumerate}

Tethne can write networks to a few different formats for visualization in
\href{http://www.cytoscape.org}{Cytoscape} or \href{http://www.gephi.org}{Gephi}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python ./tethne \PYGZhy{}I example\PYGZus{}data \PYGZhy{}O ./ \PYGZhy{}\PYGZhy{}write \PYGZhy{}W xgmml

\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Write
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading GraphCollection from /tmp/example\PYGZus{}data\PYGZus{}GraphCollection.pickle...done.
Writing graphs to ./ with format xgmml...done.
\end{Verbatim}

\code{-W xgmml} tells Tethne to generate a \href{https://code.google.com/p/dynnetwork/wiki/DynamicXGMML}{dynamic network in XGMML format}.

The resulting graph might look something like (edge width \textless{}- N coauthored papers):

\includegraphics[width=0.600\linewidth]{{cytoscape}.png}

For detailed descriptions of each workflow step, see {\color{red}\bfseries{}{}`Step-By-Step Guide (Command-line){}`\_}.


\subsection{Quickstart (Python)}
\label{tutorial.quickstart.python::doc}\label{tutorial.quickstart.python:quickstart-python}
After starting Python, import Tethne modules with:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\end{Verbatim}

To parse some data from the Web of Science, use the {\hyperref[tethne.readers:module-tethne.readers.wos]{\code{tethne.readers.wos}}} module. See
the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} class for more information about what Tethne extracts from your WoS
data.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/To/FirstDataSet.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+go}{\PYGZlt{}tethne.data.Paper instance at 0x1015ed200\PYGZgt{}}
\end{Verbatim}

You can either generate a network directly from your data using the methods in
\code{tethne.networks.wos} , or you can package your data in a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}
for comparative or longitudinal analysis. If you want to generate a dynamic network, then
use a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .


\subsubsection{Simple Networks}
\label{tutorial.quickstart.python:simple-networks}
To generate a single network directly from your data, use the \code{tethne.networks.wos}
module. For example, to build a bibliographic coupling network:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.networks} \PYG{k+kn}{as} \PYG{n+nn}{nt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{citations}\PYG{o}{.}\PYG{n}{bibliographic\PYGZus{}coupling}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC}
\PYG{g+go}{\PYGZlt{}networkx.classes.graph.Graph object at 0x101b4fe50\PYGZgt{}}
\end{Verbatim}

NetworkX provides
\href{http://networkx.github.io/documentation/networkx-1.7/reference/algorithms.html}{algorithms}
for graph analysis. To generate betweenness-centrality values for each node, try:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{networkx} \PYG{k+kn}{as} \PYG{n+nn}{nx}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b\PYGZus{}centrality} \PYG{o}{=} \PYG{n}{nx}\PYG{o}{.}\PYG{n}{betweenness\PYGZus{}centrality}\PYG{p}{(}\PYG{n}{BC}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{nx}\PYG{o}{.}\PYG{n}{set\PYGZus{}node\PYGZus{}attributes}\PYG{p}{(}\PYG{n}{BC}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{betweenness}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{b\PYGZus{}centrality}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC}\PYG{o}{.}\PYG{n}{nodes}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+go}{(\PYGZsq{}BRADSHAW 1965 ADV GENET\PYGZsq{}, \PYGZob{}\PYGZsq{}betweenness\PYGZsq{}: 0.12345\PYGZcb{})}
\end{Verbatim}

You can then export your network for visualization using one of the methods
in {\hyperref[tethne.writers:module-tethne.writers]{\code{tethne.writers}}} . For example, to generate a simple interaction file (SIF):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.writers} \PYG{k+kn}{as} \PYG{n+nn}{wr}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wr}\PYG{o}{.}\PYG{n}{graph}\PYG{o}{.}\PYG{n}{to\PYGZus{}sif}\PYG{p}{(}\PYG{n}{BC}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{/Path/to/Output/File}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}


\subsubsection{Sliced Networks for Comparative or Longitudinal Analysis}
\label{tutorial.quickstart.python:sliced-networks-for-comparative-or-longitudinal-analysis}
Especially if you want to create a dynamic network (a network that changes over time), use
a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} to organize your data.

To create a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} :

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}\PYG{p}{,} \PYG{n}{GraphCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\end{Verbatim}

You can then use the {\hyperref[tethne:tethne.data.DataCollection.slice]{\code{tethne.data.DataCollection.slice()}}} method to slice your data,
e.g. by publication date. To use a 4-year sliding time-window:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}window}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\end{Verbatim}

Create a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to manage your graphs. {\hyperref[tethne:module-tethne.builders]{\code{tethne.builders}}} provides
some helpful classes for creating a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} from a
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} . For example {\hyperref[tethne:tethne.builders.authorCollectionBuilder]{\code{authorCollectionBuilder}}} build a
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} using an author-based network (e.g. coauthorship networks) in
{\hyperref[tethne.networks:module-tethne.networks.authors]{\code{tethne.networks.authors}}} :

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{authorCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{authorCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{coauthors}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}

To write \href{https://code.google.com/p/dynnetwork/wiki/DynamicXGMML}{dynamic XGMML}
for visualization in \href{http://cytoscape.org}{Cytoscape}, use the writing methods in
{\hyperref[tethne.writers:module-tethne.writers.collection]{\code{tethne.writers.collection}}} :

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.writers} \PYG{k+kn}{as} \PYG{n+nn}{wr}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wr}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{to\PYGZus{}dxgmml}\PYG{p}{(}\PYG{n}{C}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{/Path/to/Network.xgmml}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}


\subsection{Coauthorship Networks}
\label{tutorial.coauthors:coauthorship}\label{tutorial.coauthors:coauthorship-networks}\label{tutorial.coauthors::doc}
{\color{red}\bfseries{}*}This tutorial was developed for the course \href{http://devo-evo.lab.asu.edu/methods/}{Introduction to Digital \& Computational
Methods in the Humanities (HPS)}, created and
taught by \href{http://devo-evo.lab.asu.edu/?q=damerow}{Julia Damerow}
and \href{http://gradinfo.cbs.asu.edu/?page\_id=49}{Erick Peirson}.

Coauthorship networks are among the most popular models for studying the structure of
research communities, due in no small part to the ease with which coauthorship networks
can be generated.

In this tutorial, we will generate a coauthorship network using data from the ISI Web of
Science database. See {\hyperref[tutorial.getting_data:gettingdata]{\emph{Getting Bibliographic Data}}}.

Each step includes instructions for the Tethne command-line, the TethneGUI, and Python.
Command-line steps assume that you have created an {\hyperref[install:alias]{\emph{Alias}}} for Tethne.

\textbf{If you run into problems}, don't panic. Tethne is under active development, and there
are certainly bugs to be found. Please report any problems on our
\href{https://github.com/diging/tethne/issues?state=open}{GitHub issue tracker}.


\subsubsection{Getting Started}
\label{tutorial.coauthors:getting-started}
Before you start, you should choose an output folder where TethneGUI should store graphs
and descriptions of your dataset.

You should also choose a dataset ID. This is a unique ID that Tethne will use to keep
track of your data between workflow steps.


\paragraph{Initialize TethneGUI}
\label{tutorial.coauthors:initialize-tethnegui}
When you first start TethneGUI, you should see a window like the one shown below. Click
\code{Select folder...} to specify your output folder. A dataset ID should be automatically
generated for you; you can change this if you wish.

{\hfill\includegraphics{{install.3}.png}\hfill}

Once you've selected an output folder and a dataset ID, click the \code{Run Tethne...}
button.


\subsubsection{Reading WoS Data}
\label{tutorial.coauthors:reading-wos-data}
You can read WoS data from one or multiple field-tagged data files.


\paragraph{Command-line}
\label{tutorial.coauthors:command-line}
Use \code{-I examplID} to specify your dataset ID, and
\code{-O /Users/erickpeirson/exampleOutput} to specify your output folder.

\code{-{-}data-format=WOS} tells Tethne that your data are in the Web of Science field-tagged
format.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}read\PYGZhy{}file \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}\PYGZhy{}data\PYGZhy{}path\PYG{o}{=}/Users/erickpeirson/Downloads/tests/savedrecs4.txt \PYGZhy{}\PYGZhy{}data\PYGZhy{}format\PYG{o}{=}WOS
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Read
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Reading WOS data from file /Users/erickpeirson/Downloads/tests/savedrecs4.txt...done.
Read 500 papers in 2.67462515831 seconds. Accession: 0ff65dc3\PYGZhy{}b8f7\PYGZhy{}4bdc\PYGZhy{}a714\PYGZhy{}2d2a539f10a9.
Generating a new DataCollection...done.
Saving DataCollection to /tmp/exampleID\PYGZus{}DataCollection.pickle...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.coauthors:tethnegui}\begin{enumerate}
\item {} 
Select your WoS data file. If you have one data file, click the \code{Select a File...}.
If you have multiple data files in their own folder, click \code{Select a Folder...}.

\item {} 
Select the \code{WOS} file format.

\item {} 
Click the \code{Read files} button.

\end{enumerate}

Depending on the size of your dataset, this may take a minute or two. When TethneGUI is
done reading your data, you should see messages like those depicted in the image below.

{\hfill\includegraphics{{coauthors.1}.png}\hfill}

If your data are read successfully, click \code{Next \textgreater{}}.


\paragraph{Python}
\label{tutorial.coauthors:python}
First import the {\hyperref[tethne.readers:module-tethne.readers]{\code{tethne.readers}}} module, then use the {\hyperref[tethne.readers:tethne.readers.wos.read]{\code{readers.wos.read()}}}
method to create a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances. You can use
{\hyperref[tethne.readers:tethne.readers.wos.from_dir]{\code{readers.wos.from\_dir()}}} to import all of the WoS datafiles in a directory.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Parse data.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/To/FirstDataSet.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

Then create a new {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} to organize your data.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\end{Verbatim}


\subsubsection{Slicing WoS Data}
\label{tutorial.coauthors:slicing-wos-data}
In this tutorial, we will analyze the evolution of a coauthorship network over time. To do
this, we will slice our data using the \code{date} field of each paper in our dataset.

We'll use the \code{time\_period} slice method, which means that the data will be divided into
subsets each containing data from a particular time period. The default window size is 1,
and the window will advance by 1 year in each slice.

We'll also use the cumulative slicing option, which means that the data from each time
period will contain data from all of the previous time-periods. In other words, the 1957
subset will contain data from 1957, and the 1958 subset will contain data from 1957 and
1958.


\paragraph{Command-line}
\label{tutorial.coauthors:id3}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}slice \PYGZhy{}S date \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}M time\PYGZus{}period \PYGZhy{}\PYGZhy{}cumulative
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Slice
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection from /tmp/exampleID\PYGZus{}DataCollection.pickle...done.
Slicing DataCollection by date...done.
Saving slice distribution to /Users/erickpeirson/exampleOutput/exampleID\PYGZus{}sliceDistribution.csv...done.
Saving sliced DataCollection to /tmp/exampleID\PYGZus{}DataCollection\PYGZus{}sliced.pickle...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.coauthors:id4}
The slice axis should be set to \code{date} by default. If not, select it from the
\code{Slice axis} drop-down menu. Then click the \code{Slice files} button. After a few minutes,
slicing should be complete; click \code{Next \textgreater{}}.

{\hfill\includegraphics{{coauthors.2}.png}\hfill}


\paragraph{Slice Distribution}
\label{tutorial.coauthors:slice-distribution}
Tethne command-line (and TethneGUI) automatically generates a comma-separated values (CSV)
file describing the number of records in each data slice. In your output folder look for a
file called \code{{[}DATASET\_ID{]}\_sliceDistribution.csv}.

{\hfill\includegraphics{{coauthors.3}.png}\hfill}

You can use your favorite spreadsheet software (e.g. Excel, Numbers, OpenOffice) to chart
these data.

{\hfill\includegraphics{{coauthors.4}.png}\hfill}


\paragraph{Python}
\label{tutorial.coauthors:id5}
Use the {\hyperref[tethne:tethne.data.DataCollection.slice]{\code{tethne.data.DataCollection.slice()}}} method to slice your data.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}period}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{cumulative}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\end{Verbatim}


\subsubsection{Building the Coauthor Graph}
\label{tutorial.coauthors:building-the-coauthor-graph}
Tethne will generate a graph using the \code{AU} field in your WoS data. See
{\hyperref[tutorial.getting_data:fieldtagged]{\emph{Structure of the WoS Field-Tagged Data File}}} for more information about the fields available in a WoS datafile.

For now, we'll ignore data slicing and generate a single coauthor graph from the entire
dataset using the \code{merged} option. Later on, we'll come back and use the data slicing to
look at how the network evolves over time.

To generate a coauthorship network, we will tell Tethne to use authors for nodes,
and use the \code{coauthors} graph type. For a complete list of graph types available in
Tethne, see {\hyperref[tethne.networks:module-tethne.networks]{\code{networks}}}.


\paragraph{Command-line}
\label{tutorial.coauthors:id6}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}graph \PYGZhy{}\PYGZhy{}merged \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}node\PYGZhy{}type\PYG{o}{=}author \PYGZhy{}\PYGZhy{}graph\PYGZhy{}type\PYG{o}{=}coauthors
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Graph
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection without slices from /tmp/exampleID\PYGZus{}DataCollection.pickle...done.
Building author graph using coauthors method...done in 0.144234895706 seconds.
Saving GraphCollection to /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graph summaries to /Users/erickpeirson/exampleOutput/exampleID\PYGZus{}graphs.csv...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.coauthors:id7}
Select \code{author} from the \code{Node type} menu, and \code{coauthors} from the \code{Graph type}
menu. Check the \code{Ignore DataCollection slicing} option, then click \code{Build graph}.

{\hfill\includegraphics{{coauthors.5}.png}\hfill}

Once the graph is built, click \code{Next \textgreater{}}. For now, we'll skip the analysis step. Click
\code{Next \textgreater{}} again to reach \code{Step 5: Write graph(s)}.


\paragraph{Python}
\label{tutorial.coauthors:id8}
To generate a single graph from your {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}, call the
{\hyperref[tethne.networks:tethne.networks.authors.coauthors]{\code{coauthors()}}} method directly from the {\hyperref[tethne.networks:module-tethne.networks.authors]{\code{networks.authors}}} module.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.networks} \PYG{k+kn}{as} \PYG{n+nn}{nt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ca\PYGZus{}graph} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{authors}\PYG{o}{.}\PYG{n}{coauthors}\PYG{p}{(}\PYG{n}{D}\PYG{o}{.}\PYG{n}{papers}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}


\subsubsection{Write the Graph to GraphML}
\label{tutorial.coauthors:write-the-graph-to-graphml}
\href{http://graphml.graphdrawing.org}{GraphML} is a widely-used static network data format.
We will write our graph to GraphML for visualization in Cytoscape.

This step should generate a file in your output folder called
\code{{[}DATASET\_ID{]}\_graph\_all.graphml}.

{\hfill\includegraphics{{coauthors.6}.png}\hfill}


\paragraph{Command-line}
\label{tutorial.coauthors:id9}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}write \PYGZhy{}\PYGZhy{}write\PYGZhy{}format graphml
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Write
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading GraphCollection from /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graphs to /Users/erickpeirson/exampleOutput with format graphml...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.coauthors:id10}
Select \code{graphml} from the \code{Output format for graph(s)} menu, then click
\code{Write graph(s)}.


\paragraph{Python}
\label{tutorial.coauthors:id11}
Use the {\hyperref[tethne.writers:tethne.writers.graph.to_graphml]{\code{to\_graphml()}}} method in {\hyperref[tethne.writers:module-tethne.writers.collection]{\code{writers.collection}}} to create a GraphML
data file.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.writers} \PYG{k+kn}{as} \PYG{n+nn}{wr}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wr}\PYG{o}{.}\PYG{n}{graph}\PYG{o}{.}\PYG{n}{to\PYGZus{}graphml}\PYG{p}{(}\PYG{n}{ca\PYGZus{}graph}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{[OUTPUT\PYGZus{}PATH]}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\code{{[}OUTPUT\_PATH{]}} should be a path to the GraphML file that Tethne will create.


\subsubsection{Visualizing the Merged Network in Cytoscape}
\label{tutorial.coauthors:visualizing-the-merged-network-in-cytoscape}
Cytoscape was developed in 2002, with funding from the National Instute of General Medical
Sciences and the National Resource for Network Biology. The primary user base is the
biomedical research community, especially systems biologists who study gene or protein
interaction networks and pathways.

You can download Cytoscape 3 from url\{\href{http://www.cytoscape.org}{http://www.cytoscape.org}\}. This tutorial assumes
that you are using Cytoscape 3.0.2.


\paragraph{Import}
\label{tutorial.coauthors:import}
In Cytoscape, import your network by selecting \code{File \textgreater{} Import \textgreater{} Network \textgreater{} From file...}
and selecting the GraphML file generated by Tethne in your output directory.

Apply a Force Directed layout by selecting \code{Layout \textgreater{} Prefuse Force Directed Layout}.

Coauthorship networks are usually comprised of a very large connected component, and many
very small components. For convenience, we will only look at the few largest components.
Select the largest connected components (click and drag to create a selection box). Then
create a new network with those selected components: select
\code{File \textgreater{} New \textgreater{} Networks \textgreater{} From selected nodes, all edges}.

{\hfill\includegraphics{{coauthors.7}.png}\hfill}

You should now see a new graph in its own viewing window, containing only the components
that you selected.

{\hfill\includegraphics{{coauthors.8}.png}\hfill}


\paragraph{Betweenness Centrality}
\label{tutorial.coauthors:betweenness-centrality}
This coauthorship network is clearly very modular: there are dense clusters connected by a
few linking nodes that occupy sparse areas of the graph (so-called ``structural holes''). We
can identify the structurally most-significant actors by their ``betweenness centrality.''
Formally, betweenness centrality is a measure of the number of shortest paths that pass
through a particular node.

Run Cytoscape's network-analysis algorithm. Go to
\code{Tools \textgreater{} NetworkAnalyzer \textgreater{} Network Analysis \textgreater{} Analyze Network}.

{\hfill\includegraphics{{coauthors.9}.png}\hfill}

Cytoscape may ask you whether to interpret the network as directed or undirected. A
coauthorship network is always undirected, since coauthorship is a symmetric relationship.

{\hfill\includegraphics{{coauthors.10}.png}\hfill}

Once network analysis is complete, a window titled \code{Results Panel} will appear. Close
this window.

{\hfill\includegraphics{{coauthors.11}.png}\hfill}

To visualize the betweenness centrality of each node, create a new visual mapping.
\begin{enumerate}
\item {} 
Go to the VizMapper tab, in the left part of the Cytoscape workspace.

\item {} 
Find \code{Node Size} in the unused visual properties, and double-click to move it to the
\code{Node Visual Properties} list.

\item {} 
Click in the area to the right of \code{Node Size} and select \code{BetweennessCentrality}.

\item {} 
Click in the area to the right of \code{Mapping Type} and select \code{Continuous Mapping}.

\end{enumerate}

{\hfill\includegraphics{{coauthors.12}.png}\hfill}

To change the size - centrality mapping function, double-click on the figure to the right
of \code{Curent Mapping}, and drag the red open boxes up and down to change the angle of the
function.

{\hfill\includegraphics{{coauthors.13}.png}\hfill}

The largest nodes are the most central nodes in their respective connected components.
These are the nodes most responsible for connecting disparate clusters in the network.

To see a list of the most central nodes, set the Table Panel to show all nodes.

{\hfill\includegraphics{{coauthors.14}.png}\hfill}

Then sort by betweenness centrality by clicking on the column header in the Node Table
(you may have to click twice to sort in descending order).

{\hfill\includegraphics{{coauthors.15}.png}\hfill}


\paragraph{Institutional affiliation}
\label{tutorial.coauthors:institutional-affiliation}
Wherever possible, Tethne includes institutional affiliations for authors as node
attributes. You should see institutions listed in the Node Table.

{\hfill\includegraphics{{coauthors.16}.png}\hfill}

Create a visual mapping for institutional affiliation.
\begin{enumerate}
\item {} 
Go to the VizMapper.

\item {} 
Find \code{Node Fill Color} in the unused visual properties, and double-click to activate.

\item {} 
Click to the right of {\color{red}\bfseries{}{}`{}`}Node Fill Color'' and select {\color{red}\bfseries{}{}`{}`}institution'`.

\item {} 
Set the {\color{red}\bfseries{}{}`{}`}Mapping Type'' to {\color{red}\bfseries{}{}`{}`}Discrete Mapping.'' A list of institutions should appear
below {\color{red}\bfseries{}{}`{}`}Mapping Type.'`

\item {} 
Right-click on \code{Discrete Mapping'', and select
{}`{}`Mapping Value Generators \textgreater{} Random Color}.

\end{enumerate}

{\hfill\includegraphics{{coauthors.17}.png}\hfill}

Each node should now be colored according to its institutional affiliation.
Inspecting the network yields an immediate impression of whether coauthorship clusters are
due to affiliation with the same institution.

{\hfill\includegraphics{{coauthors.18}.png}\hfill}

Since some institutions may be colored quite similarly, select a cluster to view the
specific institutional affiliation of each node. You may need to set the Node Table to
\code{show selected} rather than \code{show all}.

{\hfill\includegraphics{{coauthors.19}.png}\hfill}

Circular layouts can also yield some insights into connectivity between different
institutions. In the menu bar, select \code{Layout \textgreater{} Attribute Circle Layout \textgreater{} institution}.
This should arrange the nodes in each connected component in a circle. Nodes that are
affiliated with the same institution should be adjacent to each other, so that the
circumference of each circle can be divided into regions that correspond to single
institutions. Edges crossing from one region to another should give a visual impression of
the magnitude of linkages between institutions.

{\hfill\includegraphics{{coauthors.20}.png}\hfill}

A similar layout, the \code{Degree Sorted Circle} layout, can yield more information about
the structure of the network. As the name suggests, this layout arranges nodes in
ascending order of degree (the number of links that each node has with other nodes in the
network). The lowest-degree nodes begin just west of due-south, and degree increases
clockwise around the circle so that the highest-degree nodes are just east of due-south.
In the network depicted below, there is extremely dense connectivity among the
highest-degree nodes, while the rest of the graph is sparse by comparison. In other words,
the most well-connected nodes are all highly connected to each other. This may be due in
part to papers with a very large number of authors.

{\hfill\includegraphics{{coauthors.21}.png}\hfill}

To export an image of your network, select
\code{File \textgreater{} Export \textgreater{} Current Network View as Graphics}, and follow the prompts to save your
image.


\subsubsection{Inter-institutional Collaboration in Gephi}
\label{tutorial.coauthors:inter-institutional-collaboration-in-gephi}
\href{http://www.gephi.org}{Gephi} provides additional tools for analyzing coauthorship
networks. In this section, we'll use Gephi to generate an inter-institutional
collaboration network using your coauthorship network. That is, we will mash authors from
the same institutions together into institutional nodes, and combine coauthorship edges
so that we can see the magnitude of coauthorship activity between different institutions.


\paragraph{Import \& visualize}
\label{tutorial.coauthors:import-visualize}\begin{enumerate}
\item {} 
In Gephi, select \code{File \textgreater{} Open...} and select your GraphML network file.

\item {} 
Click on the \code{Preview} tab.

\end{enumerate}

{\hfill\includegraphics{{coauthors.22}.png}\hfill}
\begin{enumerate}
\setcounter{enumi}{2}
\item {} 
Open the \code{Graph} window: select \code{Window \textgreater{} Graph}.

\end{enumerate}

{\hfill\includegraphics{{coauthors.23}.png}\hfill}
\begin{enumerate}
\setcounter{enumi}{3}
\item {} 
Open the \code{Layout} window: select \code{Window \textgreater{} Layout}.

\item {} 
In the \code{Layout} window, select the \code{Force Atlast 2 layout}, then click \code{Run}.
After a few seconds the graph should be spread out; click \code{Stop}.

\end{enumerate}

{\hfill\includegraphics{{coauthors.25}.png}\hfill}


\paragraph{Partition by institution}
\label{tutorial.coauthors:partition-by-institution}\begin{enumerate}
\item {} 
Open the \code{Partition} window: select \code{Window \textgreater{} Partition}. You may need to drag the
window to the left-hand area of the Gephi workspace.

\item {} 
In the \code{Partition} window, you should be on the \code{Nodes} tab by default. Click the
green {\color{red}\bfseries{}{}`{}`}refreshâ€™â€™ button, then select {\color{red}\bfseries{}{}`{}`}institutionâ€™â€™ from the drop-down menu. You
should see a list of all institutions.

\item {} 
To color nodes by institution, click the \code{Apply} button.

\end{enumerate}

{\hfill\includegraphics{{coauthors.26}.png}\hfill}

Zooming in on the network, youâ€™ll notice that some clusters of nodes are comprised of one
or a few colors, while other clusters are quite mixed. Just as in Cytoscape, this gives a
visual impression of which research communities involve inter-institutional
collaborations, and which are more internal to a particular institution.

{\hfill\includegraphics{{coauthors.27}.png}\hfill}

Gephi makes it easy to collapse individual author nodes into nodes corresponding to their
institutions. Cytoscape has this feature as well, but not all of the bugs are completely
worked out.

To group authors together into their respective institutions, click the \code{Group} button
in the \code{Partition} window.

Click on the dark \textbf{T} button in the lower left corner to show node labels, and use the
right-hand slider at the bottom of the Graph window to make the labels smaller or larger.

The result may look a bit messy. There are a few things to notice:
\begin{itemize}
\item {} 
The edges between authors have been pooled into edges between institutions. The edge
weight indicates the number of coauthorship relationships between a pair of
institutions.

\item {} 
The biggest node is called \code{null}. This represents all of the authors for which no
institutional information was available. You may wish to delete this node; right-click
on the node and select \code{Delete}. When prompted, click \code{Yes}.

\end{itemize}

{\hfill\includegraphics{{coauthors.28}.png}\hfill}

To re-layout the network, go back to the \code{Layout} tab, and run the layout algorithm
again. You may notice that the network contracts rapidly. You may find it useful to reduce
the edge width and zoom in, to achieve a nice node-size : edge-weight ratio.

{\hfill\includegraphics{{coauthors.29}.png}\hfill}

To save an image of your network, click the \code{SVG/PDF/PNG} button in the lower-left
corner of the Gephi workspace.

{\hfill\includegraphics{{coauthors.30}.png}\hfill}


\subsubsection{Coauthorship network evolution}
\label{tutorial.coauthors:coauthorship-network-evolution}
This section describes how to generate a dynamic network with Tethne, and visualize that
network in Cytoscape. Dynamic networks allow us to go beyond analyzing the final structure
of a network, and ask how the structure of a network changes over time. In this case,
we will use a dynamic network to see how a coauthorship network grows over time.

Since we used the \code{-{-}cumulative} option when slicing our data, our dynamic network
will only involve the addition of nodes and edges: older coauthorship relationships will
not ``expire.''

A seemingly ubiquitous property of social networks is that they tend to be ``scale-free''.
That is, the degree distribution follows a power-law: there are a few very
highly-connected actors, and a very large number of poorly-connected actors.
The intuitive interpretation of this behavior is that ``the rich get richer.'' In other
words, if you're already popular then you're more likely to make new friends.

In this tutorial, we will visualize the impact of degree centrality on edge acquisition
by using the {\hyperref[tethne.analyze:tethne.analyze.collection.attachment_probability]{\code{analyze.collection.attachment\_probability()}}} algorithm in Tethne.


\paragraph{Command-line}
\label{tutorial.coauthors:id26}
Run the \code{graph} step again, but this time remove the \code{-{-}merged} flag. This will
create a separate graph from each of the data subsets created in the \code{slice} step.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}graph \PYGZhy{}\PYGZhy{}node\PYGZhy{}type\PYG{o}{=}author \PYGZhy{}\PYGZhy{}graph\PYGZhy{}type\PYG{o}{=}coauthors
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Graph
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection with slices from /tmp/exampleID\PYGZus{}DataCollection\PYGZus{}sliced.pickle...done.
Using first slice in DataCollection: date.
Building author graph using coauthors method...done in 0.291323900223 seconds.
Saving GraphCollection to /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graph summaries to /Users/erickpeirson/exampleOutput/exampleID\PYGZus{}graphs.csv...done.
\end{Verbatim}

Use the \code{-A attachment\_probability} argument in the \code{-{-}analyze} step.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}analyze \PYGZhy{}A attachment\PYGZus{}probability
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Analyze
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading GraphCollection from /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Analyzing GraphCollection with attachment\PYGZus{}probability...done.
Writing graph analysis results to /Users/erickpeirson/exampleOutput/exampleID\PYGZus{}attachment\PYGZus{}probability\PYGZus{}analysis.csv...done.
Saving GraphCollection to /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
\end{Verbatim}

Use \code{-{-}write-format xgmml} to select the dynamic XGMML export option.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}write \PYGZhy{}\PYGZhy{}write\PYGZhy{}format xgmml
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Write
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading GraphCollection from /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graphs to /Users/erickpeirson/exampleOutput with format xgmml...done.
\end{Verbatim}

This should create a new file called \code{{[}DATASET\_ID{]}\_graph\_dynamic.xgmml} in your output
folder.


\paragraph{TethneGUI}
\label{tutorial.coauthors:id27}
Use the \code{\textless{} Back} button to return to \code{Step 3: Build Graphs}. Uncheck the
\code{Ignore DataCollection slicing} option, and then click the \code{Build graph} button
again. Then click \code{Next \textgreater{}}.

{\hfill\includegraphics{{coauthors.31}.png}\hfill}

At the \code{analysis} step, select \code{attachment\_probability} from the \code{Graph analysis
algorithm} menu, and click the \code{Analyze graph(s)} button. Then click \code{Next \textgreater{}}.

{\hfill\includegraphics{{coauthors.32}.png}\hfill}

Finally, select \code{xgmml} in the \code{Output format} menu, and click \code{Write graph(s)}.
This should create a new file called \code{{[}DATASET\_ID{]}\_graph\_dynamic.xgmml} in your output
folder.

{\hfill\includegraphics{{coauthors.33}.png}\hfill}


\paragraph{Python}
\label{tutorial.coauthors:id28}
Use the {\hyperref[tethne:tethne.builders.authorCollectionBuilder]{\code{authorCollectionBuilder}}} to build a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} from your
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{authorCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{authorCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{coauthors}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}

The {\hyperref[tethne.analyze:tethne.analyze.collection.attachment_probability]{\code{analyze.collection.attachment\_probability()}}} method automatically updates node
attributes in your {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.analyze} \PYG{k+kn}{as} \PYG{n+nn}{az}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{az}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{attachment\PYGZus{}probability}\PYG{p}{(}\PYG{n}{C}\PYG{p}{)}
\end{Verbatim}

Use the {\hyperref[tethne.writers:tethne.writers.collection.to_dxgmml]{\code{writers.collection.to\_dxgmml()}}} method to create dynamic XGMML.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.writers} \PYG{k+kn}{as} \PYG{n+nn}{wr}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wr}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{to\PYGZus{}dxgmml}\PYG{p}{(}\PYG{n}{C}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{[OUTPUT\PYGZus{}PATH]}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\code{{[}OUTPUT\_PATH{]}} should be a path to the XGMML file that Tethne will create.


\paragraph{Visualizing a dynamic network in Cytoscape}
\label{tutorial.coauthors:visualizing-a-dynamic-network-in-cytoscape}\label{tutorial.coauthors:dynanetwork}
In Cytoscape, import your .xgmml file by selecting
\code{File \textgreater{} Import \textgreater{} Dynamic Network \textgreater{} XGMML File...}. Apply a force-directed or
spring-embedded layout.

{\hfill\includegraphics{{coauthors.34}.png}\hfill}

In the VizMapper, map \code{Node Size} to \code{attachment\_probability}.

{\hfill\includegraphics{{coauthors.35}.png}\hfill}

Double-click on the function icon next to \code{Current Mapping} to edit the \code{Node Size}
mapping function.
\begin{enumerate}
\item {} 
Click the \code{Min/Max} button, and set the maximum value to \code{1.0}.

\item {} 
Slick on the \code{Add} button to create a new handle at an intermediate value. Drag
the red open box up, and drag the corresponding black arrow left and right to alter
the mapping function.

\item {} 
Click \code{OK}.

\end{enumerate}

{\hfill\includegraphics{{coauthors.36}.png}\hfill}

In the Control Panel, select the \code{Dynamic Network} tab.
\begin{enumerate}
\item {} 
Set the time resolution to roughly match the time-range of your network. In the
example below, the network covers about 35 years, so a resolution of 1/50 was selected.

\item {} 
Set \code{Time smoothness} to \code{0 ms}.

\item {} 
Use the slider to move through the states of your dynamic network. To view all states
in succession, use the \code{\textless{}\textless{} Play} and \code{Play \textgreater{}\textgreater{}} buttons.

\end{enumerate}

{\hfill\includegraphics{{coauthors.37}.png}\hfill}

The size of each node should reflect the relative probability that a node will accrue a
new neighbor in the next time slice. Try zooming in on a particular region of your
network, and move between two successive states to verify that this is the case.

{\hfill\includegraphics{{coauthors.38}.png}\hfill}


\subsection{Bibliographic Coupling}
\label{tutorial.bibliocoupling::doc}\label{tutorial.bibliocoupling:bibliographic-coupling}
\href{http://en.wikipedia.org/wiki/Bibliographic\_coupling}{Bibliographic coupling} was first
proposed as a method for detecting latent topical affinities among research publications
by Myer M. Kessler at MIT in 1958. In 1972, J.C. Donohue suggested that bibliographic
coupling could be used to the map ``research fronts'' in science, and this method, along
with co-citation analysis and other citation-based clustering techniques, became a core
methodology of the science-mapping craze of the 1970s. Bibliographic coupling is still
employed in the context of both information-retrieval and science-studies.

Two papers are bibliographically coupled if they both cite at least some of the same
papers. The core assumption of bibliographic coupling analysis is that if two papers
cite similar literatures, then they must be topically related in some way. That is, they
are more likely to be related to each other than to papers with which they share no cited
references.

{\hfill\includegraphics{{citationnetworks}.png}\hfill}

This tutorial provides a walk-through for building bibliographic coupling networks from
Web of Science citation data, using the command-line interface, the TethneGUI (developed
for demonstration purposes only), and the Python API.

The section {\hyperref[tutorial.bibliocoupling:clusters]{\emph{Cluster Detection}}} introduces Cytoscape's MCODE clustering app.

Before you begin, be sure to install the latest version of Tethne. Consult the
{\hyperref[install:installation]{\emph{Installation}}} guide for details.

\textbf{If you run into problems}, don't panic. Tethne is under active development, and there
are certainly bugs to be found. Please report any problems on our
\href{https://github.com/diging/tethne/issues?state=open}{GitHub issue tracker}.


\subsubsection{Getting Started}
\label{tutorial.bibliocoupling:getting-started}
Before you start, you should choose an output folder where TethneGUI should store graphs
and descriptions of your dataset.

You should also choose a dataset ID. This is a unique ID that Tethne will use to keep
track of your data between workflow steps.


\paragraph{Initialize TethneGUI}
\label{tutorial.bibliocoupling:initialize-tethnegui}
When you first start TethneGUI, you should see a window like the one shown below. Click
\code{Select folder...} to specify your output folder. A dataset ID should be automatically
generated for you; you can change this if you wish.

{\hfill\includegraphics{{install.3}.png}\hfill}

Once you've selected an output folder and a dataset ID, click the \code{Run Tethne...}
button.


\subsubsection{Reading WoS Data}
\label{tutorial.bibliocoupling:reading-wos-data}
You can read WoS data from one or multiple field-tagged data files.


\paragraph{Command-line}
\label{tutorial.bibliocoupling:command-line}
Use \code{-I examplID} to specify your dataset ID, and
\code{-O /Users/erickpeirson/exampleOutput} to specify your output folder.

\code{-{-}data-format=WOS} tells Tethne that your data are in the Web of Science field-tagged
format.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}read\PYGZhy{}file \PYG{l+s+se}{\PYGZbs{}}
\PYGZhy{}\PYGZhy{}data\PYGZhy{}path\PYG{o}{=}/Users/erickpeirson/Downloads/tests/savedrecs4.txt \PYGZhy{}\PYGZhy{}data\PYGZhy{}format\PYG{o}{=}WOS
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Read
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Reading WOS data from file /Users/erickpeirson/Downloads/tests/savedrecs4.txt...done.
Read 500 papers in 2.67462515831 seconds. Accession: 0ff65dc3\PYGZhy{}b8f7\PYGZhy{}4bdc\PYGZhy{}a714\PYGZhy{}2d2a539f10a9.
Generating a new DataCollection...done.
Saving DataCollection to /tmp/exampleID\PYGZus{}DataCollection.pickle...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.bibliocoupling:tethnegui}\begin{enumerate}
\item {} 
Select your WoS data file. If you have one data file, click the \code{Select a File...}.
If you have multiple data files in their own folder, click \code{Select a Folder...}.

\item {} 
Select the \code{WOS} file format.

\item {} 
Click the \code{Read files} button.

\end{enumerate}

Depending on the size of your dataset, this may take a minute or two. When TethneGUI is
done reading your data, you should see messages like those depicted in the image below.

{\hfill\includegraphics{{coauthors.1}.png}\hfill}

If your data are read successfully, click \code{Next \textgreater{}}.


\paragraph{Python}
\label{tutorial.bibliocoupling:python}
First import the {\hyperref[tethne.readers:module-tethne.readers]{\code{tethne.readers}}} module, then use the {\hyperref[tethne.readers:tethne.readers.wos.read]{\code{readers.wos.read()}}}
method to create a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances. You can use
{\hyperref[tethne.readers:tethne.readers.wos.from_dir]{\code{readers.wos.from\_dir()}}} to import all of the WoS datafiles in a directory.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Parse data.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/To/FirstDataSet.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

Then create a new {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} to organize your data.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\end{Verbatim}


\subsubsection{Slicing WoS Data}
\label{tutorial.bibliocoupling:slicing-wos-data}
In this tutorial, we will first build a static bibliographic coupling network using all of
the records in your WoS dataset. Then, if your dataset contains records from across a
broad time-domain, you may also wish to view the evolution of your bibliographic coupling
network over time by slicing your data using a \code{sliding time-window}. Since we can
choose to merge our data slices in the \code{graph} step, we'll go ahead and slice our data
now.

The sliding time-window slice method is a bit different than the simple time-period slice
method used in the {\hyperref[tutorial.coauthors:coauthorship]{\emph{Coauthorship Networks}}} tutorial. Whereas time-period slicing divides data
into subsets by sequential non-overlapping time periods, subsets generated by time-window
slicing can overlap.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics{{timeline.timeslice}.png}
\caption{\textbf{Time-period} slicing, with a window-size of 4 years.}\end{figure}
\begin{figure}[htbp]
\centering
\capstart

\includegraphics{{timeline.timewindow}.png}
\caption{\textbf{Time-window} slicing, with a window-size of 4 years and a step-size of 1 year.}\end{figure}


\paragraph{Command-line}
\label{tutorial.bibliocoupling:id2}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}slice \PYGZhy{}S date \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}M time\PYGZus{}window \PYGZhy{}\PYGZhy{}window\PYGZhy{}size\PYG{o}{=}4
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Slice
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection from /tmp/exampleID\PYGZus{}DataCollection.pickle...done.
Slicing DataCollection by date...done.
Saving slice distribution to /Users/erickpeirson/exampleOutput/exampleID\PYGZus{}sliceDistribution.csv...done.
Saving sliced DataCollection to /tmp/exampleID\PYGZus{}DataCollection\PYGZus{}sliced.pickle...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.bibliocoupling:id3}\begin{enumerate}
\item {} 
The slice axis should be set to \code{date} by default. If not, select it from the
\code{Slice axis} drop-down menu.

\item {} 
Set \code{Cumulative slicing} to \code{False}.

\item {} 
Select \code{time\_window} from the \code{Slice method} menu.

\item {} 
Set the \code{Slice window size} to \code{4}.

\item {} 
Click \code{Slice files}.

\end{enumerate}

After a few minutes, slicing should be complete; click \code{Next \textgreater{}}.

{\hfill\includegraphics{{slice1}.png}\hfill}


\paragraph{Python}
\label{tutorial.bibliocoupling:id4}
Use the {\hyperref[tethne:tethne.data.DataCollection.slice]{\code{tethne.data.DataCollection.slice()}}} method to slice your data.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}window}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\end{Verbatim}


\subsubsection{Building the Bibliographic Coupling Graph}
\label{tutorial.bibliocoupling:building-the-bibliographic-coupling-graph}
For now, we'll ignore data slicing and generate a single bibliographic coupling graph from
the entire dataset using the \code{merged} option. Later on, we'll come back and use the data
slicing to look at how the network evolves over time.

To generate a bibliographic coupling network, we will tell Tethne to use papers for
nodes, and use the \code{bibliographic\_coupling} graph type. For a complete list of graph
types available in Tethne, see {\hyperref[tethne.networks:module-tethne.networks]{\code{networks}}}.

Generating an informative graph using bibliographic coupling will require some tuning.
Depending on the criteria that you used to generate your bibliographic dataset, you may
need to adjust the coupling \code{threshold}. Papers from a relatively narrow field have a
high probability of sharing cited references, thus a threshold of \code{1} shared reference
will result in a nearly complete graph that yields little information about the latent
topical structure of that literature. If your dataset contains papers from quite disparate
fields, however, you may wish to keep the threshold low.

Since papers vary widely in the total number of references that they cite, it may be
desirable to use a normalized overlap value rather than an absolute one. If the
\code{weighted} parameter is set to \code{True}, Tethne will use the normalized similarity
metric \code{s}:
\begin{gather}
\begin{split}s = \frac{N_{i|j}}{\sqrt{ N_i N_j }}\end{split}\notag
\end{gather}
If you choose to use absolute overlap (\code{weighted} is \code{False}), we suggest starting
with a \code{threshold} of \code{5}, and then adjusting it upward or downward to achieve optimal
clustering. If you choose to use normalized overlap (\code{weighted} is \code{True}), then try
starting with a \code{threshold} of \code{0.05}.

We'll also include some node attributes: \code{date}, \code{jtitle} (journal title), and
\code{atitle} (article title).


\paragraph{Command-line}
\label{tutorial.bibliocoupling:id5}
The value of the \code{-{-}node-attr} argument should be a list of keys from the
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} class, separated by commas (no spaces).

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}graph \PYGZhy{}\PYGZhy{}merged \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}node\PYGZhy{}type\PYG{o}{=}paper \PYGZhy{}\PYGZhy{}graph\PYGZhy{}type\PYG{o}{=}bibliographic\PYGZus{}coupling \PYGZhy{}\PYGZhy{}threshold\PYG{o}{=}0.05 \PYGZhy{}\PYGZhy{}weighted \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}node\PYGZhy{}attr\PYG{o}{=}date,jtitle,atitle
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Graph
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection without slices from /tmp/exampleID\PYGZus{}DataCollection.pickle...done.
Building author graph using coauthors method...done in 0.144234895706 seconds.
Saving GraphCollection to /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graph summaries to /Users/erickpeirson/exampleOutput/exampleID\PYGZus{}graphs.csv...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.bibliocoupling:id6}
Select \code{author} from the \code{Node type} menu, and \code{coauthors} from the \code{Graph type}
menu. Check the \code{Ignore DataCollection slicing} option, then click \code{Build graph}.

{\hfill\includegraphics{{graph.merged}.png}\hfill}

Once the graph is built, click \code{Next \textgreater{}}. For now, we'll skip the analysis step. Click
\code{Next \textgreater{}} again to reach \code{Step 5: Write graph(s)}.


\paragraph{Python}
\label{tutorial.bibliocoupling:id7}
To generate a single graph from your {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}, call the
{\hyperref[tethne.networks:tethne.networks.authors.coauthors]{\code{coauthors()}}} method directly from the {\hyperref[tethne.networks:module-tethne.networks.authors]{\code{networks.authors}}} module.

Use the \code{threshold} and \code{node\_attribs} keyword arguments to set the minimum coupling
threshold and node attributes, respectively. \code{node\_attribs} should be a list of string
keys from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.networks} \PYG{k+kn}{as} \PYG{n+nn}{nt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{bc\PYGZus{}graph} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{bibliographic\PYGZus{}coupling}\PYG{p}{(}\PYG{n}{D}\PYG{o}{.}\PYG{n}{papers}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,}
\PYG{g+gp}{... }                                           \PYG{n}{node\PYGZus{}attribs}\PYG{o}{=}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{jtitle}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{atitle}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{Verbatim}


\subsubsection{Write the Graph to GraphML}
\label{tutorial.bibliocoupling:write-the-graph-to-graphml}
\href{http://graphml.graphdrawing.org}{GraphML} is a widely-used static network data format.
We will write our network to GraphML for visualization in Cytoscape.

This step should generate a file in your output folder called
\code{{[}DATASET\_ID{]}\_graph\_all.graphml}.

{\hfill\includegraphics{{coauthors.6}.png}\hfill}


\paragraph{Command-line}
\label{tutorial.bibliocoupling:id8}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}write \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}write\PYGZhy{}format graphml
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Write
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading GraphCollection from /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graphs to /Users/erickpeirson/exampleOutput with format graphml...done.
\end{Verbatim}


\paragraph{TethneGUI}
\label{tutorial.bibliocoupling:id9}
Select \code{graphml} from the \code{Output format for graph(s)} menu, then click
\code{Write graph(s)}.

{\hfill\includegraphics{{write.graphml}.png}\hfill}


\paragraph{Python}
\label{tutorial.bibliocoupling:id10}
Use the {\hyperref[tethne.writers:tethne.writers.graph.to_graphml]{\code{to\_graphml()}}} method in {\hyperref[tethne.writers:module-tethne.writers.collection]{\code{writers.collection}}} to create a GraphML
data file.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.writers} \PYG{k+kn}{as} \PYG{n+nn}{wr}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wr}\PYG{o}{.}\PYG{n}{graph}\PYG{o}{.}\PYG{n}{to\PYGZus{}graphml}\PYG{p}{(}\PYG{n}{bc\PYGZus{}graph}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{[OUTPUT\PYGZus{}PATH]}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\code{{[}OUTPUT\_PATH{]}} should be a path to the GraphML file that Tethne will create.


\subsubsection{Visualizing the Merged Network}
\label{tutorial.bibliocoupling:visualizing-the-merged-network}
Cytoscape was developed in 2002, with funding from the National Instute of General Medical
Sciences and the National Resource for Network Biology. The primary user base is the
biomedical research community, especially systems biologists who study gene or protein
interaction networks and pathways.

You can download Cytoscape 3 from url\{\href{http://www.cytoscape.org}{http://www.cytoscape.org}\}. This tutorial assumes
that you are using Cytoscape 3.1.


\paragraph{Import}
\label{tutorial.bibliocoupling:import}
In Cytoscape, import your network by selecting \code{File \textgreater{} Import \textgreater{} Network \textgreater{} From file...}
and selecting the GraphML file generated by Tethne in your output directory.

Tethne includes the \code{similarity} of each pair of papers as an edge attribute. You can
tell Cytoscape to take similarity into account when laying out your graph. To apply an
edge-weighted layout, select \code{Layout \textgreater{} Edge-weighted Spring Embedded \textgreater{} similarity}.

{\hfill\includegraphics{{cyto.1}.png}\hfill}

Your network may look like a giant hairball. If you can't see much structure at all, you
may wish to go back and rebuild the graph with a higher threshold. If your network is very
sparse, you may wish to lower the threshold.

Set edge weight as a function of \code{similarity} to see which links are the strongest in
your network.

{\hfill\includegraphics{{cyto.2}.png}\hfill}

To get some idea of whether certain clusters in the network correspond to publication
in the same journal, set node fill color as a discrete function of \code{jtitle}. You can
automatically generate node fill colors by right-clicking on the visual mapping, and
selecting \code{Mapping Value Generators \textgreater{} Random Color}.

{\hfill\includegraphics{{cyto.3}.png}\hfill}

Since you included the title of each paper (\code{atitle}) as a node attribute, you can
get some idea of what makes a particular region of the network hang together by selecting
some nodes and inspecting the \code{Node Table} in the \code{Table Panel}. In the example below,
a quick visual inspection suggests that parasites figure heavily in the selected papers.

{\hfill\includegraphics{{cyto.4}.png}\hfill}


\subsubsection{Cluster Detection}
\label{tutorial.bibliocoupling:clusters}\label{tutorial.bibliocoupling:cluster-detection}
Especially if your network is very dense, it may be difficult to find salient clusters
by visual inspection alone. Clustering algorithms provide a useful way to find
groups of nodes that hang together in some way. Most clustering algorithms use an
optimization function to find groups of nodes that are more densely connected among
themselves than with the rest of the network.

One such clustering algorithm in Cytoscape is provided by the MCODE app. To install
the MCODE app:
\begin{enumerate}
\item {} 
Select \code{Apps \textgreater{} App Manager} from the main menu.

\item {} 
Click on the \code{Install Apps} tab, and find MCODE in the list of available apps.

\item {} 
Click the \code{Install} button.

\end{enumerate}

{\hfill\includegraphics{{cyto.5}.png}\hfill}

MCODE should now appear in the \code{Apps} menu.

{\hfill\includegraphics{{cyto.6}.png}\hfill}
\begin{enumerate}
\item {} 
Select \code{Apps \textgreater{} MCODE \textgreater{} Open MCODE}. A new tab should appear in the \code{Control Panel}
at left.

\item {} 
To adjust the parameters of the MCODE cluster-finding algorithm, expand the
\code{Advanced Options}. MCODE works reasonable well with the default settings.

\item {} 
Click the \code{Analyze current network} button.

\end{enumerate}

{\hfill\includegraphics{{cyto.7}.png}\hfill}

After a few moments, a new window should appear on the right side of the Cytoscape
workspace. Click on a cluster in the \code{Cluster Browser} to select all of the nodes in
that cluster. In some cases, MCODE will find clusters that are not at all obvious
visually. This should give you an impression of the limitations of two-dimensional
layouts for studying network structure, especially in very large, dense networks.

In the example below, MCODE has found a cluster of papers dealing with invertebrate
predators in marine inter-tidal zones.

{\hfill\includegraphics{{cyto.8}.png}\hfill}

MCODE allows you to create a subnetwork from the selected cluster, or export your results.
Exporting your results produces a table like the one shown below, listing each of the
detected clusters and the papers the belong to them.

\emph{Future versions of Tethne will use this result to generate labels for each cluster based
on the terms that uniquely characterize those groups of papers.}

{\hfill\includegraphics{{cyto.9}.png}\hfill}

MCODE sets three node attributes:
\begin{itemize}
\item {} 
\code{MCODE\_Cluster} contains the name of the cluster to which each node belongs.

\item {} 
\code{MCODE\_Score} indicates how strongly the neighbors around a node cluster together.
This is similar to the \href{http://en.wikipedia.org/wiki/Clustering\_coefficient\#Local\_clustering\_coefficient}{Local clustering coefficient}

\item {} 
\code{MCODE\_Node\_Status} indicates whether a node is clustered, unclustered, or a seed
node. Seed nodes are the reference nodes chosen by MCODE at the start of the
cluster-detection process.

\end{itemize}

In the visualization below, node fill color is mapped to \code{MCODE\_Cluster}. Node size is
mapped to \code{MCODE\_Node\_Status}: unclustered nodes are small, seed nodes are large, and
clustered nodes are intermediate in size.

{\hfill\includegraphics{{cyto.10}.png}\hfill}


\subsubsection{Bibliographic Coupling over Time}
\label{tutorial.bibliocoupling:bibliographic-coupling-over-time}
If your dataset includes papers published over a long period of time, you may wish to
analyze your bibliographic coupling graph as a dynamic network. This can give a visual
impression of how fields and subfields evolve over time, in terms of whether they do
or do not share cited references.


\paragraph{Command-line}
\label{tutorial.bibliocoupling:id11}
Run the \code{graph} step again, but this time remove the \code{-{-}merged} flag. This will
create a separate graph from each of the data subsets created in the \code{slice} step.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}graph \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}node\PYGZhy{}type\PYG{o}{=}paper \PYGZhy{}\PYGZhy{}graph\PYGZhy{}type\PYG{o}{=}bibliographic\PYGZus{}coupling \PYGZhy{}\PYGZhy{}threshold\PYG{o}{=}0.05 \PYGZhy{}\PYGZhy{}weighted \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}\PYGZhy{}node\PYGZhy{}attr\PYG{o}{=}date,jtitle,atitle
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Graph
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading DataCollection with slices from /tmp/exampleID\PYGZus{}DataCollection\PYGZus{}sliced.pickle...done.
Using first slice in DataCollection: date.
Building author graph using coauthors method...done in 0.291323900223 seconds.
Saving GraphCollection to /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graph summaries to /Users/erickpeirson/exampleOutput/exampleID\PYGZus{}graphs.csv...done.
\end{Verbatim}

Re-run the \code{write} step. Use \code{-{-}write-format xgmml} to select the dynamic XGMML export
option.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }tethne \PYGZhy{}I exampleID \PYGZhy{}O /Users/erickpeirson/exampleOutput \PYGZhy{}\PYGZhy{}write \PYGZhy{}\PYGZhy{}write\PYGZhy{}format xgmml
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
        Workflow step: Write
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
Loading GraphCollection from /tmp/exampleID\PYGZus{}GraphCollection.pickle...done.
Writing graphs to /Users/erickpeirson/exampleOutput with format xgmml...done.
\end{Verbatim}

This should create a new file called \code{{[}DATASET\_ID{]}\_graph\_dynamic.xgmml} in your output
folder.


\paragraph{TethneGUI}
\label{tutorial.bibliocoupling:id12}
Use the \code{\textless{} Back} button to return to \code{Step 3: Build Graphs}. Uncheck the
\code{Ignore DataCollection slicing} option, and then click the \code{Build graph} button
again. Then click \code{Next \textgreater{}}.

Skip the \code{analyze} step.

At the \code{write} step, select \code{xgmml} in the \code{Output format} menu, and click \code{Write
graph(s)}. This should create a new file called \code{{[}DATASET\_ID{]}\_graph\_dynamic.xgmml} in
your output folder.

{\hfill\includegraphics{{coauthors.33}.png}\hfill}


\paragraph{Python}
\label{tutorial.bibliocoupling:id13}
Use the {\hyperref[tethne:tethne.builders.paperCollectionBuilder]{\code{paperCollectionBuilder}}} to build a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} from your
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{paperCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{paperCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{bibliographic\PYGZus{}coupling}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,}
\PYG{g+gp}{... }                   \PYG{n}{node\PYGZus{}attribs}\PYG{o}{=}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{jtitle}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{atitle}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{Verbatim}

Use the {\hyperref[tethne.writers:tethne.writers.collection.to_dxgmml]{\code{writers.collection.to\_dxgmml()}}} method to create dynamic XGMML.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.writers} \PYG{k+kn}{as} \PYG{n+nn}{wr}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wr}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{to\PYGZus{}dxgmml}\PYG{p}{(}\PYG{n}{C}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{[OUTPUT\PYGZus{}PATH]}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\code{{[}OUTPUT\_PATH{]}} should be a path to the XGMML file that Tethne will create.


\paragraph{Visualization}
\label{tutorial.bibliocoupling:visualization}
See {\hyperref[tutorial.coauthors:dynanetwork]{\emph{Visualizing a dynamic network in Cytoscape}}} for instructions about how to visualize your dynamic network in
Cytoscape (the parts about \code{attachment\_probability} don't apply).


\subsection{Step-By-Step Guide (Python)}
\label{tutorial:step-by-step-guide-python}

\subsubsection{Creating Networks from Bibliographic Data}
\label{tutorial.networks:creating-networks-from-bibliographic-data}\label{tutorial.networks::doc}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\textbf{Ready to Proceed?}

\medskip


Once you have collected
your bibliographic data, you're ready
to start building networks.
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\paragraph{Parsing Data}
\label{tutorial.networks:parsing-data}
Methods for parsing bibliographic data are contained in the {\hyperref[tethne.readers:module-tethne.readers]{\code{readers}}} module.
Tethne parses bibliographic data into a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects that can then
be used to generate networks.

Many (but not all) of the networks that Tethne can generate require citation data. The
current version of Tethne only supports citation data from the Web of Science, which can
be parsed using the {\hyperref[tethne.readers:module-tethne.readers.wos]{\code{readers.wos}}} module. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/savedrecs.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

Tethne can also parse data from \href{http://dfr.jstor.org}{JSTOR's
Data-for-Research portal}, using the {\hyperref[tethne.readers:module-tethne.readers.dfr]{\code{readers.dfr}}} module.
Those data can be merged with a WoS dataset (see {\hyperref[tethne.readers:tethne.readers.merge]{\code{readers.merge()}}}), or
used on their own to generate coauthor networks, with
{\hyperref[tethne.networks:tethne.networks.authors.coauthors]{\code{networks.authors.coauthors()}}}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/DfR}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}


\paragraph{Creating Networks}
\label{tutorial.networks:creating-networks}
There are many different network models that can be used to describe bibliographic data.
These can be roughly divided into two categories: networks that describe relationships
among documents, and networks that describe relationships among the authors of those
documents. For specific methods, see {\hyperref[tutorial.networks:networks-of-documents]{\emph{Networks of Documents}}} and
{\hyperref[tutorial.networks:networks-of-authors]{\emph{Networks of Authors}}}.

All network-building methods can be found in the {\hyperref[tethne.networks:module-tethne.networks]{\code{networks}}} module. \code{nt} is the
recommended namespace convention.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.networks} \PYG{k+kn}{as} \PYG{n+nn}{nt}
\end{Verbatim}

There are two main ways of using network-building methods:


\subparagraph{Generating a single network directly from a list of \texttt{Paper} objects}
\label{tutorial.networks:generating-a-single-network-directly-from-a-list-of-paper-objects}
All methods in {\hyperref[tethne.networks:module-tethne.networks]{\code{tethne.networks}}} take lists of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} as arguments. For
example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/savedrecs.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.networks} \PYG{k+kn}{as} \PYG{n+nn}{nt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{bibliographic\PYGZus{}coupling}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\end{Verbatim}


\subparagraph{Generating a \texttt{GraphCollection} from a \texttt{DataCollection}}
\label{tutorial.networks:generate-graphcollection}\label{tutorial.networks:generating-a-graphcollection-from-a-datacollection}
This is useful in cases where you want to evaluate the evolution of network structure
over time, or compare networks generated using subsets of your data.

To generate a time-variant {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}, slice your
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} using the \code{date} field. In the example below, data are sliced
using a 4-year sliding time-window (for details about slicing, see
{\hyperref[tethne:tethne.data.DataCollection.slice]{\code{tethne.data.DataCollection.slice()}}}).

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Parse data.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/To/FirstDataSet.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Create a DataCollection, and slice it.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}\PYG{p}{,} \PYG{n}{GraphCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}window}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Build a GraphCollection using a network from tethne.networks.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{authorCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{authorCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{coauthors}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}

\code{C.keys()} should now yield a list of publication dates in the original dataset.

A {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} can be sliced using any \code{int} or \code{str} field in the
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} class. If you wish to compare networks generated from two WoS downloads,
for example, you could slice using the \code{accession} id:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Parse data.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/To/FirstDataSet.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{+}\PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/To/SecondDataSet.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Create a DataCollection, and slice it.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}\PYG{p}{,} \PYG{n}{GraphCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{accession}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Build a GraphCollection using a network from tethne.networks.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{authorCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{paperCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{cocitation}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\end{Verbatim}

\code{C.keys()} should now yield two values, each an accession UUID.


\paragraph{Networks of Documents}
\label{tutorial.networks:networks-of-documents}\label{tutorial.networks:id1}
Methods for building networks in which vertices represent documents are provided in the
{\hyperref[tethne.networks:module-tethne.networks.papers]{\code{networks.papers}}} module.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.networks:tethne.networks.papers.author_coupling]{\code{tethne.networks.papers.author\_coupling}}}(papers)
 & 
Vertices are papers and edges indicates shared authorship.
\\\hline

{\hyperref[tethne.networks:tethne.networks.papers.bibliographic_coupling]{\code{tethne.networks.papers.bibliographic\_coupling}}}(papers)
 & 
Generate a bibliographic coupling network.
\\\hline

{\hyperref[tethne.networks:tethne.networks.papers.cocitation]{\code{tethne.networks.papers.cocitation}}}(papers{[}, ...{]})
 & 
Generate a cocitation network.
\\\hline

{\hyperref[tethne.networks:tethne.networks.papers.direct_citation]{\code{tethne.networks.papers.direct\_citation}}}(papers)
 & 
Create a traditional directed citation network.
\\\hline
\end{longtable}



\paragraph{Networks of Authors}
\label{tutorial.networks:networks-of-authors}\label{tutorial.networks:id2}
Methods for building networks in which vertices represent authors are provided in the {\hyperref[tethne.networks:module-tethne.networks.authors]{\code{networks.authors}}} module.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.networks:tethne.networks.authors.author_cocitation]{\code{tethne.networks.authors.author\_cocitation}}}(papers)
 & 
Generates an author co-citation network; edges indicate co-citation of authors' papers.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.author_coinstitution]{\code{tethne.networks.authors.author\_coinstitution}}}(Papers)
 & 
Generate a co-institution graph, where edges indicate shared affiliation.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.author_institution]{\code{tethne.networks.authors.author\_institution}}}(Papers)
 & 
Generate a bi-partite graph connecting authors and their institutions.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.author_papers]{\code{tethne.networks.authors.author\_papers}}}(papers)
 & 
Generate an author\_papers network NetworkX directed graph.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.coauthors]{\code{tethne.networks.authors.coauthors}}}(papers{[}, ...{]})
 & 
Generate a co-author network.
\\\hline
\end{longtable}



\subsubsection{Analyzing Bibliographic Networks}
\label{tutorial.analyze:analyzing-bibliographic-networks}\label{tutorial.analyze::doc}
All networks in Tethne are
\href{http://networkx.lanl.gov/reference/classes.graph.html}{NetworkX Graphs}.
This means means that you can use the rich suite of
\href{http://networkx.github.io/documentation/latest/reference/algorithms.html}{algorithms}
provided by NetworkX to analyze your bibliographic networks.


\paragraph{Analyzing individual networks}
\label{tutorial.analyze:analyzing-individual-networks}
If you built your network directly from a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}, you can import
and use NetworkX directly.

To calculate the betweenness-centrality of all of the nodes in a bibliographic
coupling network, for example, use:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Parse your data:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wos\PYGZus{}list} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{parse\PYGZus{}wos}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/savedrecs.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{rad}\PYG{p}{(}\PYG{n}{wos\PYGZus{}list}\PYG{p}{)}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Build a bibliographic coupling network:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.networks} \PYG{k+kn}{as} \PYG{n+nn}{nt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{bibliographic\PYGZus{}coupling}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Use the NetworkX betweenness\PYGZhy{}centrality algorithm:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{networkx} \PYG{k+kn}{as} \PYG{n+nn}{nx}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{btw} \PYG{o}{=} \PYG{n}{nx}\PYG{o}{.}\PYG{n}{betweenness\PYGZus{}centrality}\PYG{p}{(}\PYG{n}{G}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{btw}
\PYG{g+go}{\PYGZob{}\PYGZsq{}a\PYGZsq{}: 0.0, \PYGZsq{}c\PYGZsq{}: 0.0, \PYGZsq{}b\PYGZsq{}: 0.6666666666666666, \PYGZsq{}d\PYGZsq{}: 0.0\PYGZcb{}}
\end{Verbatim}

To add the betweenness-centrality values to your network as node attributes...

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{nx}\PYG{o}{.}\PYG{n}{set\PYGZus{}node\PYGZus{}attributes}\PYG{p}{(}\PYG{n}{BC}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{betweenness}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{btw}\PYG{p}{)}
\end{Verbatim}

You can find a complete list of graph analysis algorithms in the \href{http://networkx.github.io/documentation/latest/reference/algorithms.html}{NetworkX
documentation}.

A few additional methods internal to Tethne can be found in the {\hyperref[tethne.analyze:module-tethne.analyze.graph]{\code{analyze.graph}}}
module.


\paragraph{Analyzing a \texttt{GraphCollection}}
\label{tutorial.analyze:analyzing-a-graphcollection}
The {\hyperref[tethne.analyze:module-tethne.analyze.collection]{\code{analyze.collection}}} sub-package provides mechanisms for analyzing an entire
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}. Most NetworkX algorithms are accessible via
{\hyperref[tethne.analyze:tethne.analyze.collection.algorithm]{\code{analyze.collection.algorithm()}}}. To calculate betweenness centrality for an
entire {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}, for example, use:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.analyze} \PYG{k+kn}{as} \PYG{n+nn}{az}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{az}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{algorithm}\PYG{p}{(}\PYG{n}{C}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{betweenness\PYGZus{}centrality}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print} \PYG{n}{BC}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+go}{\PYGZob{}1999: 0.010101651117889644,}
\PYG{g+go}{2000: 0.0008689093723107329,}
\PYG{g+go}{2001: 0.010504898852426189,}
\PYG{g+go}{2002: 0.009338654511194512,}
\PYG{g+go}{2003: 0.007519105636349891\PYGZcb{}}
\end{Verbatim}

For more information, see the {\hyperref[tethne.analyze:module-tethne.analyze.collection]{\code{analyze.collection}}} sub-package.


\subparagraph{Methods}
\label{tutorial.analyze:methods}
\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.analyze:tethne.analyze.collection.algorithm]{\code{tethne.analyze.collection.algorithm}}}(C, ...)
 & 
Apply NetworkX method to each \code{Graph} in {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}.
\\\hline

{\hyperref[tethne.analyze:tethne.analyze.collection.connected]{\code{tethne.analyze.collection.connected}}}(C, ...)
 & 
Performs analysis methods from networkx.connected on each graph in the collection.
\\\hline

{\hyperref[tethne.analyze:tethne.analyze.collection.edge_history]{\code{tethne.analyze.collection.edge\_history}}}(C, ...)
 & 
Returns a dictionary of attribute vales for each Graph in C for a single
\\\hline

{\hyperref[tethne.analyze:tethne.analyze.collection.node_history]{\code{tethne.analyze.collection.node\_history}}}(C, ...)
 & 
Returns a dictionary of attribute values for each Graph in C for a single
\\\hline

{\hyperref[tethne.analyze:tethne.analyze.collection.node_global_closeness_centrality]{\code{tethne.analyze.collection.node\_global\_closeness\_centrality}}}(C, node)
 & 
Calculates global closeness centrality for node in each graph in
\\\hline
\end{longtable}



\section{Command-line Options}
\label{commandline:command-line-options}\label{commandline::doc}\label{commandline:commandline-options}
Invoke Tethne with \code{python {[}TETHNE\_PATH{]}}. To find the \code{{[}TETHNE PATH{]}}, start the
Python interpreter in Terminal, and import Tethne. Then call \code{tethne.\_\_file\_\_}. In the
example below, the path that we're looking for is
\code{/anaconda/lib/python2.7/site-packages/tethne}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python
Python 2.7.5 \textbar{}Anaconda 1.6.1 \PYG{o}{(}x86\PYGZus{}64\PYG{o}{)}\textbar{} \PYG{o}{(}default, Jun 28 2013, 22:20:13\PYG{o}{)}
\PYG{o}{[}GCC 4.0.1 \PYG{o}{(}Apple Inc. build 5493\PYG{o}{)}\PYG{o}{]} on darwin
Type \PYG{l+s+s2}{\PYGZdq{}help\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}copyright\PYGZdq{}}, \PYG{l+s+s2}{\PYGZdq{}credits\PYGZdq{}} or \PYG{l+s+s2}{\PYGZdq{}license\PYGZdq{}} \PYG{k}{for }more information.
\PYGZgt{}\PYGZgt{}\PYGZgt{} import tethne
\PYGZgt{}\PYGZgt{}\PYGZgt{} tethne.\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}
\PYG{l+s+s1}{\PYGZsq{}//anaconda/lib/python2.7/site\PYGZhy{}packages/tethne/\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.pyc\PYGZsq{}}
\PYGZgt{}\PYGZgt{}\PYGZgt{}
\end{Verbatim}

If you are using a Mac, we recommend creating an {\hyperref[install:alias]{\emph{Alias}}}. You can then call Tethne
with:

\begin{Verbatim}[commandchars=\\\{\}]
\$ tethne --help
\end{Verbatim}


\subsection{Universal arguments}
\label{commandline:universal-arguments}
The following arguments should be included each time you run Tethne. Tethne uses
\code{-{-}dataset-id} to track your dataset through the workflow, so it should remain the same
in each workflow step.

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Alternative
} & \textbf{
Description
}\\\hline

\code{-I DATASET\_ID}
 & 
\code{-{-}dataset-id=DATASET\_ID}
 & 
Unique ID (required).
\\\hline

\code{-t TEMP\_DIR}
 & 
\code{-{-}temp-dir=TEMP\_DIR}
 & 
Directory for storing temporary files
(optional; default is /tmp).
\\\hline

\code{-O OUTPATH}
 & 
\code{-{-}outpath=OUTPATH}
 & 
Path to save workflow output. Some
workflow steps will generate summary
statistics or other output.
\\\hline
\end{tabulary}


A base pattern for calling Tethne might look like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python \PYGZti{}/Downloads/tethne\PYGZhy{}python/tethne \PYGZhy{}I fundata01 \PYGZhy{}O \PYGZti{}/results
\end{Verbatim}

This will cause all output to be saved in the \code{results} folder inside your home
directory.


\subsection{Workflow steps}
\label{commandline:workflow-steps}
There are 5 steps in the workflow, each with a distinct set of arguments. These should be
called sequentially (only the \code{-{-}analyze} step can be skipped).
\begin{itemize}
\item {} 
{\hyperref[commandline:cl-read]{\emph{Read}}}

\item {} 
{\hyperref[commandline:cl-slice]{\emph{Slice}}}

\item {} 
{\hyperref[commandline:cl-graph]{\emph{Graph}}}

\item {} 
{\hyperref[commandline:cl-analyze]{\emph{Analyze}}}

\item {} 
{\hyperref[commandline:cl-write]{\emph{Write}}}

\end{itemize}


\subsubsection{Read}
\label{commandline:read}\label{commandline:cl-read}
Parses bibliographic data. There are two ways to do this:

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}read-file}
 & 
Read from a single data file. Requires \code{-{-}data-path} and
\code{-{-}data-format}.
\\\hline

\code{-{-}read-dir}
 & 
Read from a directory containing multiple data files. Requires
\code{-{-}data-path} and \code{-{-}data-format}.
\\\hline
\end{tabulary}


The following arguments are also required:

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Alternative
} & \textbf{
Description
}\\\hline

\code{-P DATAPATH}
 & 
\code{-{-}data-path=DATAPATH}
 & 
Full path to dataset.
\\\hline

\code{-F DATAFORMAT}
 & 
\code{-{-}data-format=DATAFORMAT}
 & 
Format of input dataset (WOS, DFR).
\\\hline
\end{tabulary}


For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python \PYGZti{}/Downloads/tethne\PYGZhy{}python/tethne \PYGZhy{}I fundata01 \PYGZhy{}O \PYGZti{}/results \PYGZhy{}\PYGZhy{}read\PYGZhy{}file \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}P /path/to/your\PYG{l+s+se}{\PYGZbs{} }data/download.txt \PYGZhy{}F WOS
\end{Verbatim}

Resulting in something like:

\begin{Verbatim}[commandchars=\\\{\}]
----------------------------------------
        Workflow step: Read
----------------------------------------
Reading WOS data from file /path/to/your data/download.txt...done.
Read 500 papers in 1.69956803 seconds. Accession: 19825ab7-6176-4742-8cf2-0093d751b5f3.
Generating a new DataCollection...done.
Saving DataCollection to /tmp/fundata01\_DataCollection.pickle...done.
\end{Verbatim}

\textbf{WOS:} Web of Science field-tagged format; \textbf{DFR:} JSTOR Data-for-Research dataset in
XML format.


\subsubsection{Slice}
\label{commandline:slice}\label{commandline:cl-slice}
Slicing divides your dataset up along one or more axes (a key in the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
class) for analysis.  This prepared your dataset for comparative analysis in later steps.
You might wish to, for example, analyze your dataset diachronically by slicing by
\code{date}, or you might wish to compare data from different journals by slicing by
\code{jtitle}. Use \code{accession} if you wish to compare data from different data files.

As of \code{v.0.3}, slicing is limited to \code{date}, \code{jtitle}, and \code{accession}.

\begin{tabular}{|p{0.475\linewidth}|p{0.475\linewidth}|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}slice}
 & \begin{description}
\item[{Slice your dataset for comparison along a key axis.}] \leavevmode
Requires \code{-{-}slice-axis}. If \code{-{-}outpath} is set, produces a
table with binned paper frequencies in
\code{{[}OUTPATH{]}/{[}DATASET\_ID{]}\_slices.csv}.

\end{description}
\\\hline
\end{tabular}


The following arguments are required:

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Alternative
} & \textbf{
Description
}\\\hline

\code{-S SLICE\_AXIS}
 & 
\code{-{-}slice-axis=AXIS}
 & 
Key along which to slice the dataset.
This can be any of the fields
listed in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}.
\\\hline

\code{-M SLICE\_METHOD}
 & 
\code{-{-}slice-method=METHOD}
 & 
Method used to slice
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}. Available
methods: \code{time\_window},
\code{time\_period}. For details, see
\code{DataCollection.slice()}. Default is
time\_period.
\\\hline
\end{tabulary}


The following arguments are optional:

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}slice-window-size=SIZE}
 & 
Size of slice time-window or period, in years. Default: 1.
\\\hline

\code{-{-}slice-step-size=SIZE}
 & 
Amount to advance time-window in each step (ignored for
time-period).
\\\hline

\code{-{-}cumulative}
 & 
If True, the data from each successive slice includes the
data from all preceding slices.
\\\hline
\end{tabulary}


For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python \PYGZti{}/Downloads/tethne\PYGZhy{}python/tethne \PYGZhy{}I fundata01 \PYGZhy{}O \PYGZti{}/results \PYGZhy{}\PYGZhy{}slice \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{}  \PYGZhy{}S date,jtitle \PYGZhy{}M time\PYGZus{}window \PYGZhy{}\PYGZhy{}slice\PYGZhy{}window\PYGZhy{}size\PYG{o}{=}4 \PYGZhy{}\PYGZhy{}slice\PYGZhy{}step\PYGZhy{}size\PYG{o}{=}1 \PYGZhy{}\PYGZhy{}cumulative
\end{Verbatim}

Resulting in something like:

\begin{Verbatim}[commandchars=\\\{\}]
----------------------------------------
    Workflow step: Slice
----------------------------------------
Loading DataCollection from /tmp/fundata01\_DataCollection.pickle...done.
Slicing DataCollection by date...done.
Slicing DataCollection by jtitle...done.
Saving slice distribution to \textasciitilde{}/results/fundata01\_sliceDistribution.csv...done.
Saving sliced DataCollection to /tmp/fundata01\_DataCollection\_sliced.pickle...done.
\end{Verbatim}

\code{\textasciitilde{}/results/fundata01\_sliceDistribution.csv} contains a comma-separated table with the
distribution of papers across \code{date} and \code{jtitle}. For example:


\begin{threeparttable}
\capstart\caption{fundata01\_sliceDistribution.csv}

\begin{tabulary}{\linewidth}{|L|L|L|L|L|L|L|}
\hline
 & 
2003
 & 
2004
 & 
2005
 & 
2006
 & 
2007
 & 
2008
\\\hline

ENVIRONMENTAL BIOLOGY OF FISHES
 & 
0.0
 & 
0.0
 & 
0.0
 & 
1.0
 & 
1.0
 & 
1.0
\\\hline

SCIENTIA MARINA
 & 
0.0
 & 
0.0
 & 
0.0
 & 
0.0
 & 
1.0
 & 
1.0
\\\hline

ACTA OECOLOGICA-INTERNATIONAL JOURNAL OF ECOLOGY
 & 
3.0
 & 
3.0
 & 
3.0
 & 
4.0
 & 
2.0
 & 
2.0
\\\hline

JOURNAL OF CHEMICAL ECOLOGY
 & 
2.0
 & 
2.0
 & 
1.0
 & 
1.0
 & 
0.0
 & 
0.0
\\\hline

ACTA THERIOLOGICA
 & 
0.0
 & 
0.0
 & 
0.0
 & 
0.0
 & 
1.0
 & 
1.0
\\\hline

TREE GENETICS \& GENOMES
 & 
0.0
 & 
0.0
 & 
1.0
 & 
1.0
 & 
1.0
 & 
1.0
\\\hline

ENVIRONMENTAL POLLUTION
 & 
1.0
 & 
1.0
 & 
1.0
 & 
1.0
 & 
0.0
 & 
0.0
\\\hline

NEUROGASTROENTEROLOGY AND MOTILITY
 & 
0.0
 & 
0.0
 & 
1.0
 & 
1.0
 & 
1.0
 & 
1.0
\\\hline

FIELD CROPS RESEARCH
 & 
1.0
 & 
1.0
 & 
1.0
 & 
1.0
 & 
1.0
 & 
1.0
\\\hline

PLOS GENETICS
 & 
0.0
 & 
1.0
 & 
1.0
 & 
1.0
 & 
1.0
 & 
0.0
\\\hline

ONCOGENE
 & 
1.0
 & 
1.0
 & 
1.0
 & 
0.0
 & 
1.0
 & 
1.0
\\\hline
\end{tabulary}

\end{threeparttable}


You can easily visualize these data using your favorite spreadsheet software.

\includegraphics[width=0.600\linewidth]{{slice}.png}


\subsubsection{Graph}
\label{commandline:graph}\label{commandline:cl-graph}
\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}graph}
 & 
Generate a graph (or collection of graphs). If \code{-{-}outpath} is set,
produces a table with the number of nodes and edges per graph in
\code{{[}OUTPATH{]}/{[}DATASET\_ID{]}\_graphs.csv}.
\\\hline
\end{tabulary}


The following arguments should be used:

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Alternative
} & \textbf{
Description
}\\\hline

\code{-N NODE\_TYPE}
 & 
\code{-{-}node-type=TYPE}
 & 
Must be one of: \code{author}, \code{paper}.
\\\hline

\code{-T GRAPH\_TYPE}
 & 
\code{-{-}graph-type=TYPE}
 & 
Name of a network-builing method. Can be
one of any of the methods listed in
{\hyperref[tethne.networks:module-tethne.networks]{\code{networks}}}. e.g. if \code{-n} is
\code{author}, \code{-t} could be
\code{coauthors}.
\\\hline
\end{tabulary}


Available network-building methods (as of v0.3.0-alpha)

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Node Type
} & \textbf{
Graph Type
} & \textbf{
Method
}\\\hline

\code{paper}
 & 
\code{author\_coupling}
 & 
{\hyperref[tethne.networks:tethne.networks.papers.author_coupling]{\code{tethne.networks.papers.author\_coupling()}}}
\\\hline

\code{paper}
 & 
\code{bibliographic\_coupling}
 & 
{\hyperref[tethne.networks:tethne.networks.papers.bibliographic_coupling]{\code{tethne.networks.papers.bibliographic\_coupling()}}}
\\\hline

\code{paper}
 & 
\code{cocitation}
 & 
{\hyperref[tethne.networks:tethne.networks.papers.cocitation]{\code{tethne.networks.papers.cocitation()}}}
\\\hline

\code{paper}
 & 
\code{direct\_citation}
 & 
{\hyperref[tethne.networks:tethne.networks.papers.direct_citation]{\code{tethne.networks.papers.direct\_citation()}}}
\\\hline

\code{author}
 & 
\code{author\_cocitation}
 & 
{\hyperref[tethne.networks:tethne.networks.authors.author_cocitation]{\code{tethne.networks.authors.author\_cocitation()}}}
\\\hline

\code{author}
 & 
\code{author\_coinstitution}
 & 
{\hyperref[tethne.networks:tethne.networks.authors.author_coinstitution]{\code{tethne.networks.authors.author\_coinstitution()}}}
\\\hline

\code{author}
 & 
\code{author\_papers}
 & 
{\hyperref[tethne.networks:tethne.networks.authors.author_papers]{\code{tethne.networks.authors.author\_papers()}}}
\\\hline

\code{author}
 & 
\code{coauthors}
 & 
{\hyperref[tethne.networks:tethne.networks.authors.coauthors]{\code{tethne.networks.authors.coauthors()}}}
\\\hline
\end{tabulary}


If you have sliced your data in a previous step, but wish to generate a network based on
the entire dataset, you may use:

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}merged}
 & 
Ignore DataCollection slicing, and build a single
graph from all Papers.
\\\hline
\end{tabulary}


Some methods use additional keyword arguments that affect the resulting graph. The
following arguments can be used to set common keyword arguments. The meaning of these
arguments varies between methods; consult {\hyperref[tethne.networks:module-tethne.networks]{\code{networks}}} for descriptions of each
network-building method.

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}threshold=THRESHOLD}
 & 
Set the `threshold' argument. Applies to all except:
\code{direct\_citation}, \code{author\_institution},
\code{author\_papers}.
\\\hline

\code{-{-}topn=TOPN}
 & 
Set the `topn' argument. Applies to: \code{cocitation}.
\\\hline

\code{-{-}node-attr=NODE\_ATTR}
 & 
List of attributes to include for each node. e.g.
\code{-{-}node-attr=date,atitle,jtitle}. Applies to: all.
\\\hline

\code{-{-}edge-attr=EDGE\_ATTR}
 & 
List of attributes to include for each edge. e.g.
\code{-{-}edge-attr=ayjid,atitle,date}. Applies to: all.
\\\hline

\code{-{-}node-id=NODE\_ID}
 & 
Field to use as node id (for papers graphs). e.g.
\code{-{-}node-id=ayjid}. Applies to: all \code{paper} methods.
\\\hline

\code{-{-}weighted}
 & 
Trigger the `weighted' argument. Applies to:
\code{bibliographic\_coupling}.
\\\hline
\end{tabulary}


For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python \PYGZti{}/Downloads/tethne\PYGZhy{}python/tethne \PYGZhy{}I fundata01 \PYGZhy{}O \PYGZti{}/results \PYGZhy{}\PYGZhy{}graph \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}N author \PYGZhy{}T coauthors \PYGZhy{}\PYGZhy{}edge\PYGZhy{}attr\PYG{o}{=}ayjid,date,jtitle
\end{Verbatim}

Resulting in something like:

\begin{Verbatim}[commandchars=\\\{\}]
----------------------------------------
        Workflow step: Graph
----------------------------------------
Loading DataCollection with slices from /tmp/fundata01\_DataCollection\_sliced.pickle...done.
Using first slice in DataCollection: date.
Building author graph using coauthors method...done in 0.426736116409 seconds.
Saving GraphCollection to /tmp/fundata01\_GraphCollection.pickle...done.
Writing graph summaries to \textasciitilde{}/results/fundata01\_graphs.csv...done.
\end{Verbatim}

\code{\textasciitilde{}/results/fundata01\_graphs.csv} contains a comma-separated table with the
number of nodes and edges per graph (indexed by \code{date}, in this case). For example:


\begin{threeparttable}
\capstart\caption{fundata01\_graphs.csv}

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline

index
 & 
nodes
 & 
edges
\\\hline

2003
 & 
402
 & 
630
\\\hline

2004
 & 
576
 & 
978
\\\hline

2005
 & 
666
 & 
1199
\\\hline

2006
 & 
781
 & 
1420
\\\hline

2007
 & 
907
 & 
1764
\\\hline

2008
 & 
739
 & 
1436
\\\hline
\end{tabulary}

\end{threeparttable}


You can easily visualize these data using your favorite spreadsheet software.

\includegraphics[width=0.600\linewidth]{{graph}.png}


\subsubsection{Analyze}
\label{commandline:cl-analyze}\label{commandline:analyze}
The analysis workflow step is optional. As of v0.3.0-alpha, \code{-{-}analyze} triggers
{\hyperref[tethne.analyze:tethne.analyze.collection.algorithm]{\code{analyze.collection.algorithm()}}}, which calls a graph analysis algorithm in
NetworkX. So far this has been tested for \href{http://networkx.github.io/documentation/latest/reference/algorithms.centrality.html}{centrality algorithms}
only.

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}analyze}
 & 
Analyze a graph (or collection of graphs). If \code{-{-}outpath} is set,
produces a table with the mean and variance of the algorithm result
for each graph, in
\code{{[}OUTPATH{]}/{[}DATASET\_ID{]}\_{[}ALGORITHM{]}\_analysis.csv}.
\\\hline
\end{tabulary}


Use the \code{-{-}algorithm} argument to select an algorithm. This should be the name of an
method in the {\color{red}\bfseries{}{}`}NetworkX centrality algorithm methods
\textless{}\href{http://networkx.github.io/documentation/latest/reference/algorithms.centrality.html}{http://networkx.github.io/documentation/latest/reference/algorithms.centrality.html}\textgreater{}{}`+\_.

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Alternative
} & \textbf{
Description
}\\\hline

\code{-A ALGORITHM}
 & 
\code{-{-}algorithm=ALGORITHM}
 & 
Name of a NetworkX graph analysis
algorithm.
\\\hline
\end{tabulary}


For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n+nv}{\PYGZdl{} }python \PYGZti{}/Downloads/tethne\PYGZhy{}python/tethne \PYGZhy{}I fundata01 \PYGZhy{}O \PYGZti{}/results \PYGZhy{}\PYGZhy{}analyze \PYG{l+s+se}{\PYGZbs{}}
\PYGZgt{} \PYGZhy{}A betweenness\PYGZus{}centrality
\end{Verbatim}

Resulting in something like:

\begin{Verbatim}[commandchars=\\\{\}]
----------------------------------------
        Workflow step: Analyze
----------------------------------------
Loading GraphCollection from /tmp/fundata01\_GraphCollection.pickle...done.
Analyzing GraphCollection with betweenness\_centrality...done.
Writing graph analysis results to \textasciitilde{}/results/fundata01\_betweenness\_centrality\_analysis.csv...done.
Saving GraphCollection to /tmp/fundata01\_GraphCollection.pickle...done.
\end{Verbatim}

\code{\textasciitilde{}/results/fundata01\_betweenness\_centrality\_analysis.csv} contains a comma-separated
table with the mean and variance of per-node betweenness-centrality for each graph
(indexed by \code{date}, in this case). For example:


\begin{threeparttable}
\capstart\caption{fundata01\_betweenness\_centrality\_analysis.csv}

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline

index
 & 
mean
 & 
variance
\\\hline

2003
 & 
4.8696666294462848e-06
 & 
5.8521060847378354e-10
\\\hline

2004
 & 
3.7662643707182407e-06
 & 
5.0172975473198493e-10
\\\hline

2005
 & 
3.2576284954217712e-06
 & 
4.8988211004664643e-10
\\\hline

2006
 & 
1.749020895995168e-06
 & 
1.5297987419477807e-10
\\\hline

2007
 & 
3.6252321590741106e-06
 & 
1.4535627363876269e-09
\\\hline

2008
 & 
2.5476025127262327e-06
 & 
1.0268407559417709e-09
\\\hline
\end{tabulary}

\end{threeparttable}


You can easily visualize these data using your favorite spreadsheet software.

\includegraphics[width=0.600\linewidth]{{analyze}.png}


\subsubsection{Write}
\label{commandline:write}\label{commandline:cl-write}
You can visualize networks using software like \href{http://www.cytoscape.org}{Cytoscape}
or \href{http://www.gephi.org}{Gephi}. The writing workflow step involves converting a
collection of NetworkX graphs into a structured graph file. Tethne can generate both
static and dynamic networks. If a static network format is chosen, each graph in the
collection will be written to a separate file.

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Description
}\\\hline

\code{-{-}write}
 & 
Write a graph (or collection of graphs) to a structured format, in
\code{{[}OUTPATH{]}}.
\\\hline
\end{tabulary}


The \code{-{-}write-format} argument is required:

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Alternative
} & \textbf{
Description
}\\\hline

-W WRITE\_FORMAT
 & 
--write-format=FORMAT
 & 
Output format for graph(s). If a static
graph format is chosen (e.g. graphml),
each slice in the GraphCollection will
result in a separate file. Supported
writers: (static) graphml; (dynamic)
xgmml.
\\\hline
\end{tabulary}


For example:

\begin{Verbatim}[commandchars=\\\{\}]
\$ python \textasciitilde{}/Downloads/tethne-python/tethne -I fundata01 -O \textasciitilde{}/results --write \PYGZbs{}
\textgreater{} -W graphml
\end{Verbatim}

Resulting in something like:

\begin{Verbatim}[commandchars=\\\{\}]
----------------------------------------
        Workflow step: Write
----------------------------------------
Loading GraphCollection from /tmp/fundata01\_GraphCollection.pickle...done.
Writing graphs to \textasciitilde{}/results with format graphml...done.
\end{Verbatim}

And generating the following files in \code{\textasciitilde{}/results}:

\begin{Verbatim}[commandchars=\\\{\}]
-rw-r--r--  1 erickpeirson  staff  196686 Feb 23 10:52 fundata01\_graph\_2003.graphml
-rw-r--r--  1 erickpeirson  staff  299885 Feb 23 10:52 fundata01\_graph\_2004.graphml
-rw-r--r--  1 erickpeirson  staff  359992 Feb 23 10:52 fundata01\_graph\_2005.graphml
-rw-r--r--  1 erickpeirson  staff  427821 Feb 23 10:52 fundata01\_graph\_2006.graphml
-rw-r--r--  1 erickpeirson  staff  515779 Feb 23 10:52 fundata01\_graph\_2007.graphml
-rw-r--r--  1 erickpeirson  staff  418702 Feb 23 10:52 fundata01\_graph\_2008.graphml
\end{Verbatim}

Opening \code{fundata01\_graph\_2007.graphml} in Cytoscape yields something like:

\includegraphics[width=0.600\linewidth]{{cytoscape2}.png}


\section{tethne Package}
\label{tethne::doc}\label{tethne:tethne-package}

\subsection{\texttt{tethne} Package}
\label{tethne:id1}\phantomsection\label{tethne:module-tethne.__init__}\index{tethne.\_\_init\_\_ (module)}
Tethne is a package for analyzing citation data from the Web of Science.
Modules within Tethne can generate a variety of networks, such as
bibliographic coupling, citation, author-paper, and co-author networks,
using networkx.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.analyze:module-tethne.analyze]{\code{tethne.analyze}}}
 & 
The {\hyperref[tethne.analyze:module-tethne.analyze]{\code{tethne.analyze}}} sub-package provides additional analysis methods not
\\\hline

{\hyperref[tethne:module-tethne.builders]{\code{tethne.builders}}}
 & 
Classes for building a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\\\hline

{\hyperref[tethne:module-tethne.data]{\code{tethne.data}}}
 & 
Classes for handling bibliographic data.
\\\hline

{\hyperref[tethne.matrices:module-tethne.matrices]{\code{tethne.matrices}}}
 & 
Methods for generating matrices from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects and other data.
\\\hline

{\hyperref[tethne.networks:module-tethne.networks]{\code{tethne.networks}}}
 & 
Methods for building networks from bibliographic data.
\\\hline

{\hyperref[tethne.readers:module-tethne.readers]{\code{tethne.readers}}}
 & 
Methods for parsing bibliographic datasets.
\\\hline

{\hyperref[tethne.utilities:module-tethne.utilities]{\code{tethne.utilities}}}
 & 
Helper functions for {\hyperref[tethne.networks:module-tethne.networks]{\code{tethne.networks}}} .
\\\hline

{\hyperref[tethne.writers:module-tethne.writers]{\code{tethne.writers}}}
 & 
Export networks to structured and unstructured formats, for visualization.
\\\hline
\end{longtable}



\subsection{\texttt{\_\_main\_\_} Module}
\label{tethne:module-tethne.__main__}\label{tethne:main-module}\index{tethne.\_\_main\_\_ (module)}\index{isfloat() (in module tethne.\_\_main\_\_)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.__main__.isfloat}\pysiglinewithargsret{\code{tethne.\_\_main\_\_.}\bfcode{isfloat}}{\emph{x}}{}
\end{fulllineitems}

\index{isint() (in module tethne.\_\_main\_\_)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.__main__.isint}\pysiglinewithargsret{\code{tethne.\_\_main\_\_.}\bfcode{isint}}{\emph{x}}{}
\end{fulllineitems}



\subsection{\texttt{builders} Module}
\label{tethne:module-tethne.builders}\label{tethne:builders-module}\index{tethne.builders (module)}
Classes for building a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.builders.builder]{\code{builder}}}(D)
 & 
Base class for builders.
\\\hline

{\hyperref[tethne:tethne.builders.authorCollectionBuilder]{\code{authorCollectionBuilder}}}(D)
 & 
Builds a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} with method in
\\\hline

{\hyperref[tethne:tethne.builders.paperCollectionBuilder]{\code{paperCollectionBuilder}}}(D)
 & 
Builds a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} with method in
\\\hline
\end{longtable}

\index{authorCollectionBuilder (class in tethne.builders)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.builders.authorCollectionBuilder}\pysiglinewithargsret{\strong{class }\code{tethne.builders.}\bfcode{authorCollectionBuilder}}{\emph{D}}{}
Bases: {\hyperref[tethne:tethne.builders.builder]{\code{tethne.builders.builder}}}

Builds a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} with method in 
{\hyperref[tethne.networks:module-tethne.networks.authors]{\code{tethne.networks.authors}}} from a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .
\paragraph{Methods}

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.builders.authorCollectionBuilder.build]{\code{build}}}(graph\_axis, graph\_type, **kwargs)
 & 
Generates graphs for each slice along graph\_axis in
\\\hline
\end{longtable}

\index{build() (tethne.builders.authorCollectionBuilder method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.builders.authorCollectionBuilder.build}\pysiglinewithargsret{\bfcode{build}}{\emph{graph\_axis}, \emph{graph\_type}, \emph{**kwargs}}{}
Generates graphs for each slice along graph\_axis in
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} D.

Other axes in D are treated as attributes.

\textbf{Usage}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/wos/data.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)} \PYG{c}{\PYGZsh{} Indexed by wosid, by default.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}window}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{authorCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{authorCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{coauthors}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C}
\PYG{g+go}{\PYGZlt{}tethne.data.GraphCollection at 0x104ed3550\PYGZgt{}}
\end{Verbatim}

\end{fulllineitems}


\end{fulllineitems}

\index{builder (class in tethne.builders)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.builders.builder}\pysiglinewithargsret{\strong{class }\code{tethne.builders.}\bfcode{builder}}{\emph{D}}{}
Bases: \code{object}

Base class for builders.

\end{fulllineitems}

\index{paperCollectionBuilder (class in tethne.builders)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.builders.paperCollectionBuilder}\pysiglinewithargsret{\strong{class }\code{tethne.builders.}\bfcode{paperCollectionBuilder}}{\emph{D}}{}
Bases: {\hyperref[tethne:tethne.builders.builder]{\code{tethne.builders.builder}}}

Builds a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} with method in 
{\hyperref[tethne.networks:module-tethne.networks.papers]{\code{tethne.networks.papers}}} from a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .
\paragraph{Methods}

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.builders.paperCollectionBuilder.build]{\code{build}}}(graph\_axis, graph\_type, **kwargs)
 & 
Generates graphs for each slice along graph\_axis in
\\\hline
\end{longtable}

\index{build() (tethne.builders.paperCollectionBuilder method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.builders.paperCollectionBuilder.build}\pysiglinewithargsret{\bfcode{build}}{\emph{graph\_axis}, \emph{graph\_type}, \emph{**kwargs}}{}
Generates graphs for each slice along graph\_axis in
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} D.

Other axes in D are treated as attributes.

\textbf{Usage}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/wos/data.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)} \PYG{c}{\PYGZsh{} Indexed by wosid, by default.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}window}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{paperCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{paperCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{bibliographic\PYGZus{}coupling}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C}
\PYG{g+go}{\PYGZlt{}tethne.data.GraphCollection at 0x104ed3550\PYGZgt{}}
\end{Verbatim}

\end{fulllineitems}


\end{fulllineitems}



\subsection{\texttt{data} Module}
\label{tethne:module-tethne.data}\label{tethne:data-module}\index{tethne.data (module)}
Classes for handling bibliographic data.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}()
 & 
Base class for Papers.
\\\hline

{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}(data{[}, index\_by{]})
 & 
A {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} organizes {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}s for analysis.
\\\hline

{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}()
 & 
Collection of NetworkX \code{nx.classes.graph.Graph} objects,
\\\hline

{\hyperref[tethne:tethne.data.LDAModel]{\code{LDAModel}}}(doc\_topic, top\_word, top\_keys, ...)
 & 
Organizes parsed output from MALLET's LDA modeling algorithm.
\\\hline
\end{longtable}

\index{DataCollection (class in tethne.data)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection}\pysiglinewithargsret{\strong{class }\code{tethne.data.}\bfcode{DataCollection}}{\emph{data}, \emph{index\_by='wosid'}}{}
Bases: \code{object}

A {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} organizes {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}s for analysis.

The {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} is initialized with some data, which is indexed
by a key in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} (default is wosid). The {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}
can then be sliced ( {\hyperref[tethne:tethne.data.DataCollection.slice]{\code{DataCollection.slice()}}} ) by other keys in
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} .

\textbf{Usage}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/wos/data.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{+}\PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/wos/data2.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}    \PYG{c}{\PYGZsh{} Two accessions.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)} \PYG{c}{\PYGZsh{} Indexed by wosid, by default.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}window}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{accession}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}
\PYG{g+go}{\PYGZlt{}tethne.data.DataCollection at 0x10af0ef50\PYGZgt{}}
\end{Verbatim}
\paragraph{Methods}

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.data.DataCollection.N_axes]{\code{N\_axes}}}()
 & 
Returns the number of slice axes for this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.distribution]{\code{distribution}}}()
 & 
Returns a Numpy array describing the number of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.distribution_2d]{\code{distribution\_2d}}}(x\_axis, y\_axis)
 & 
Returns a Numpy array describing the number of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.get_axes]{\code{get\_axes}}}()
 & 
Returns a list of all slice axes for this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.get_by]{\code{get\_by}}}(key\_indices{[}, papers{]})
 & 
Given a set of (key, index) tuples, return the corresponding subset of
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.get_slice]{\code{get\_slice}}}(key, index{[}, papers{]})
 & 
Yields a specific slice.
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.get_slices]{\code{get\_slices}}}(key{[}, papers{]})
 & 
Yields slices for key.
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.indices]{\code{indices}}}()
 & 
Yields a list of indices of all papers in this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.papers]{\code{papers}}}()
 & 
Yield the complete set of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances in this
\\\hline

{\hyperref[tethne:tethne.data.DataCollection.slice]{\code{slice}}}(key{[}, method{]})
 & 
Slices data by key, using method (if applicable).
\\\hline
\end{longtable}

\index{N\_axes() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.N_axes}\pysiglinewithargsret{\bfcode{N\_axes}}{}{}
Returns the number of slice axes for this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .

\end{fulllineitems}

\index{distribution() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.distribution}\pysiglinewithargsret{\bfcode{distribution}}{}{}
Returns a Numpy array describing the number of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
associated with each slice-coordinate.

WARNING: expensive for a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} with many axes or
long axes. Consider using \code{distribution\_2d()} .
\begin{quote}\begin{description}
\item[{Returns }] \leavevmode
\textbf{dist} : Numpy array
\begin{quote}

An N-dimensional array. Axes are given by 
{\hyperref[tethne:tethne.data.DataCollection.get_axes]{\code{DataCollection.get\_axes()}}} and values are the number of
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} at that slice-coordinate.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{RuntimeError} : DataCollection has not been sliced.

\end{description}\end{quote}

\end{fulllineitems}

\index{distribution\_2d() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.distribution_2d}\pysiglinewithargsret{\bfcode{distribution\_2d}}{\emph{x\_axis}, \emph{y\_axis}}{}
Returns a Numpy array describing the number of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
associated with each slice-coordinate, for x and y axes spcified.
\begin{quote}\begin{description}
\item[{Returns }] \leavevmode
\textbf{dist} : Numpy array
\begin{quote}

A 2-dimensional array. Values are the number of
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} at that slice-coordinate.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{RuntimeError} : DataCollection has not been sliced.

\textbf{KeyError: Invalid slice axes for this DataCollection.} :

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_axes() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.get_axes}\pysiglinewithargsret{\bfcode{get\_axes}}{}{}
Returns a list of all slice axes for this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .

\end{fulllineitems}

\index{get\_by() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.get_by}\pysiglinewithargsret{\bfcode{get\_by}}{\emph{key\_indices}, \emph{papers=False}}{}
Given a set of (key, index) tuples, return the corresponding subset of
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} indices (or {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances themselves, if 
papers is True).
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{key\_indices} : list
\begin{quote}

A list of (key, index) tuples.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{plist} : list
\begin{quote}

A list of paper indices, or {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{RuntimeError} : DataCollection has not been sliced.

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_slice() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.get_slice}\pysiglinewithargsret{\bfcode{get\_slice}}{\emph{key}, \emph{index}, \emph{papers=False}}{}
Yields a specific slice.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{key} : str
\begin{quote}

Key from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} that has previously been used to slice data
in this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .
\end{quote}

\textbf{index} : str or int
\begin{quote}

Slice index for key (e.g. 1999 for `date').
\end{quote}

\item[{Returns }] \leavevmode
\textbf{slice} : list
\begin{quote}

List of paper indices in this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} , or (if
papers is True) a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{RuntimeError} : DataCollection has not been sliced.

\textbf{KeyError} : Data has not been sliced by {[}key{]}

\textbf{KeyError} : {[}index{]} not a valid index for {[}key{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_slices() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.get_slices}\pysiglinewithargsret{\bfcode{get\_slices}}{\emph{key}, \emph{papers=False}}{}
Yields slices for key.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{key} : str
\begin{quote}

Key from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} that has previously been used to slice data
in this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .
\end{quote}

\item[{Returns }] \leavevmode
\textbf{slices} : dict
\begin{quote}

Keys are slice indices. If papers is True, values are lists of
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances; otherwise returns paper indices (e.g.
`wosid').
\end{quote}

\item[{Raises }] \leavevmode
\textbf{RuntimeError} : DataCollection has not been sliced.

\textbf{KeyError} : Data has not been sliced by {[}key{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{indices() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.indices}\pysiglinewithargsret{\bfcode{indices}}{}{}
Yields a list of indices of all papers in this {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}
\begin{quote}\begin{description}
\item[{Returns }] \leavevmode
\textbf{list} :
\begin{quote}

List of indices.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{papers() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.papers}\pysiglinewithargsret{\bfcode{papers}}{}{}
Yield the complete set of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances in this
{\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}} .
\begin{quote}\begin{description}
\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{slice() (tethne.data.DataCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.DataCollection.slice}\pysiglinewithargsret{\bfcode{slice}}{\emph{key}, \emph{method=None}, \emph{**kwargs}}{}
Slices data by key, using method (if applicable).

Methods available for slicing a {\hyperref[tethne:tethne.data.DataCollection]{\code{DataCollection}}}:

\begin{tabulary}{\linewidth}{|L|L|L|L|}
\hline
\textbf{
Method
} & \textbf{
Description
} & \textbf{
Key
} & \textbf{
kwargs
}\\\hline

time\_window
 & 
Slices data using a sliding
time-window. Dataslices are
indexed by the start of the
time-window.
 & 
date
 & 
window\_size
step\_size
\\\hline

time\_period
 & 
Slices data into time periods
of equal length. Dataslices
are indexed by the start of
the time period.
 & 
date
 & 
window\_size
\\\hline
\end{tabulary}


The main difference between the sliding time-window (\code{time\_window}) 
and the time-period (\code{time\_period}) slicing methods are whether the
resulting periods can overlap. Whereas time-period slicing divides data
into subsets by sequential non-overlapping time periods, subsets 
generated by time-window slicing can overlap.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics{{timeline.timeslice}.png}
\caption{\textbf{Time-period} slicing, with a window-size of 4 years.}\end{figure}
\begin{figure}[htbp]
\centering
\capstart

\includegraphics{{timeline.timewindow}.png}
\caption{\textbf{Time-window} slicing, with a window-size of 4 years and a 
step-size of 1 year.}\end{figure}

Avilable kwargs:

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Argument
} & \textbf{
Type
} & \textbf{
Description
}\\\hline

window\_size
 & 
int
 & 
Size of time-window or period, in years
(default = 1).
\\\hline

step\_size
 & 
int
 & 
Amount to advance time-window or period in each
step (ignored for time\_period).
\\\hline

cumulative
 & 
bool
 & 
If True, the data from each successive slice
includes the data from all preceding slices.
Only applies if key is `date' (default = False).
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{key} : str
\begin{quote}

key in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} by which to slice data.
\end{quote}

\textbf{method} : str (optional)
\begin{quote}

Dictates how data should be sliced. See table for available methods.
If key is `date', default method is time\_period with window\_size and
step\_size of 1.
\end{quote}

\textbf{kwargs} : kwargs
\begin{quote}

See methods table, above.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{GraphCollection (class in tethne.data)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.GraphCollection}\pysigline{\strong{class }\code{tethne.data.}\bfcode{GraphCollection}}
Bases: \code{object}

Collection of NetworkX \code{nx.classes.graph.Graph} objects, 
organized by some index (e.g. time).

A {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} can be generated using classes in the
{\hyperref[tethne:module-tethne.builders]{\code{tethne.builders}}} module. See 
{\hyperref[tutorial.networks:generate-graphcollection]{\emph{Generating a GraphCollection from a DataCollection}}} for details.
\paragraph{Methods}

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.data.GraphCollection.compose]{\code{compose}}}()
 & 
Returns the simple union of all \code{Graph} in the
\\\hline

{\hyperref[tethne:tethne.data.GraphCollection.edges]{\code{edges}}}({[}overwrite{]})
 & 
Return complete set of edges for this {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\\\hline

{\hyperref[tethne:tethne.data.GraphCollection.load]{\code{load}}}(filepath)
 & 
Loads a pickled (serialized) {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} from filepath.
\\\hline

{\hyperref[tethne:tethne.data.GraphCollection.nodes]{\code{nodes}}}({[}overwrite{]})
 & 
Return complete set of nodes for this {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\\\hline

{\hyperref[tethne:tethne.data.GraphCollection.save]{\code{save}}}(filepath)
 & 
Pickles (serializes) the {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\\\hline
\end{longtable}

\index{compose() (tethne.data.GraphCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.GraphCollection.compose}\pysiglinewithargsret{\bfcode{compose}}{}{}
Returns the simple union of all \code{Graph} in the 
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\begin{quote}\begin{description}
\item[{Returns }] \leavevmode
\textbf{composed} : \code{Graph}
\begin{quote}

Simple union of all \code{Graph} in the 
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\end{quote}

\end{description}\end{quote}
\paragraph{Notes}

Node or edge attributes that vary over slices should be ignored.

\end{fulllineitems}

\index{edges() (tethne.data.GraphCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.GraphCollection.edges}\pysiglinewithargsret{\bfcode{edges}}{\emph{overwrite=False}}{}
Return complete set of edges for this {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .

If this method has been called previously for this
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} then will not recompute unless overwrite =
True.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{overwrite} : bool
\begin{quote}

If True, will generate new node list, even if one already exists.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{edges} : list
\begin{quote}

List (complete set) of edges for this {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{load() (tethne.data.GraphCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.GraphCollection.load}\pysiglinewithargsret{\bfcode{load}}{\emph{filepath}}{}
Loads a pickled (serialized) {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} from filepath.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{filepath} : string
\begin{quote}

Full path to pickled {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\end{quote}

\item[{Raises }] \leavevmode
\textbf{UnpicklingError} : Raised when there is some issue in unpickling.

\textbf{IOError} : File does not exist, or cannot be read.

\end{description}\end{quote}

\end{fulllineitems}

\index{nodes() (tethne.data.GraphCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.GraphCollection.nodes}\pysiglinewithargsret{\bfcode{nodes}}{\emph{overwrite=False}}{}
Return complete set of nodes for this {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .

If this method has been called previously for this
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} then will not recompute unless overwrite =
True.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{overwrite} : bool
\begin{quote}

If True, will generate new node list, even if one already exists.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{nodes} : list
\begin{quote}

List (complete set) of node identifiers for this
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{save() (tethne.data.GraphCollection method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.GraphCollection.save}\pysiglinewithargsret{\bfcode{save}}{\emph{filepath}}{}
Pickles (serializes) the {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} .
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{filepath :} :
\begin{quote}

Full path of output file.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{PicklingError} : Raised when unpicklable objects are Pickled.

\textbf{IOError} : File does not exist, or cannot be opened.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{LDAModel (class in tethne.data)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.LDAModel}\pysiglinewithargsret{\strong{class }\code{tethne.data.}\bfcode{LDAModel}}{\emph{doc\_topic}, \emph{top\_word}, \emph{top\_keys}, \emph{metadata}, \emph{vocabulary}}{}
Bases: \code{object}

Organizes parsed output from MALLET's LDA modeling algorithm.

Used by {\hyperref[tethne.readers:module-tethne.readers.mallet]{\code{readers.mallet}}}.
\paragraph{Methods}

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.data.LDAModel.docs_in_topic]{\code{docs\_in\_topic}}}(z{[}, topD{]})
 & 
Returns a list of the topD documents most representative of topic z.
\\\hline

{\hyperref[tethne:tethne.data.LDAModel.topics_in_doc]{\code{topics\_in\_doc}}}(d{[}, topZ{]})
 & 
Returns a list of the topZ most prominent topics in a document.
\\\hline
\end{longtable}

\index{docs\_in\_topic() (tethne.data.LDAModel method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.LDAModel.docs_in_topic}\pysiglinewithargsret{\bfcode{docs\_in\_topic}}{\emph{z}, \emph{topD=None}}{}
Returns a list of the topD documents most representative of topic z.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{z} : int
\begin{quote}

A topic index.
\end{quote}

\textbf{topD} : int or float
\begin{quote}

Number of prominent topics to return (int), or threshold (float).
\end{quote}

\item[{Returns }] \leavevmode
\textbf{documents} : list
\begin{quote}

List of (document, proportion) tuples.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{topics\_in\_doc() (tethne.data.LDAModel method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.LDAModel.topics_in_doc}\pysiglinewithargsret{\bfcode{topics\_in\_doc}}{\emph{d}, \emph{topZ=None}}{}
Returns a list of the topZ most prominent topics in a document.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{d} : str or int
\begin{quote}

An identifier from a {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} key.
\end{quote}

\textbf{topZ} : int or float
\begin{quote}

Number of prominent topics to return (int), or threshold (float).
\end{quote}

\item[{Returns }] \leavevmode
\textbf{topics} : list
\begin{quote}

List of (topic, proportion) tuples.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{Paper (class in tethne.data)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.Paper}\pysigline{\strong{class }\code{tethne.data.}\bfcode{Paper}}
Bases: \code{object}

Base class for Papers.

Behaves just like a dict, but enforces a limited vocabulary of keys, and 
specific data types.

The following fields (and corresponding data types) are allowed:

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Field
} & \textbf{
Type
} & \textbf{
Description
}\\\hline

aulast
 & 
list
 & 
Authors' last name, as a list.
\\\hline

auinit
 & 
list
 & 
Authors' first initial as a list.
\\\hline

institution
 & 
dict
 & 
Institutions with which the authors are affiliated.
\\\hline

atitle
 & 
str
 & 
Article title.
\\\hline

jtitle
 & 
str
 & 
Journal title or abbreviated title.
\\\hline

volume
 & 
str
 & 
Journal volume number.
\\\hline

issue
 & 
str
 & 
Journal issue number.
\\\hline

spage
 & 
str
 & 
Starting page of article in journal.
\\\hline

epage
 & 
str
 & 
Ending page of article in journal.
\\\hline

date
 & 
int
 & 
Article date of publication.
\\\hline

country
 & 
dict
 & 
Author-Country mapping.
\\\hline

citations
 & 
list
 & 
A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\\\hline

ayjid
 & 
str
 & 
First author's name (last fi), pubdate, and journal.
\\\hline

doi
 & 
str
 & 
Digital Object Identifier.
\\\hline

pmid
 & 
str
 & 
PubMed ID.
\\\hline

wosid
 & 
str
 & 
Web of Science UT fieldtag value.
\\\hline

accession
 & 
str
 & 
Identifier for data conversion accession.
\\\hline
\end{tabulary}


None values are also allowed for all fields.
\paragraph{Methods}

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne:tethne.data.Paper.authors]{\code{authors}}}()
 & 
Returns a list of author names (FI LAST).
\\\hline

{\hyperref[tethne:tethne.data.Paper.iteritems]{\code{iteritems}}}()
 & 
Returns an iterator for the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}`s metadata fields
\\\hline

{\hyperref[tethne:tethne.data.Paper.keys]{\code{keys}}}()
 & 
Returns the keys of the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}`s metadata fields.
\\\hline

{\hyperref[tethne:tethne.data.Paper.values]{\code{values}}}()
 & 
Returns the values of the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}`s metadata fields.
\\\hline
\end{longtable}

\index{authors() (tethne.data.Paper method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.Paper.authors}\pysiglinewithargsret{\bfcode{authors}}{}{}
Returns a list of author names (FI LAST).

\end{fulllineitems}

\index{iteritems() (tethne.data.Paper method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.Paper.iteritems}\pysiglinewithargsret{\bfcode{iteritems}}{}{}
Returns an iterator for the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}`s metadata fields

\end{fulllineitems}

\index{keys() (tethne.data.Paper method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.Paper.keys}\pysiglinewithargsret{\bfcode{keys}}{}{}
Returns the keys of the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}`s metadata fields.

\end{fulllineitems}

\index{values() (tethne.data.Paper method)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.data.Paper.values}\pysiglinewithargsret{\bfcode{values}}{}{}
Returns the values of the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}`s metadata fields.

\end{fulllineitems}


\end{fulllineitems}



\subsection{\texttt{workflow} Module}
\label{tethne:module-tethne.workflow}\label{tethne:workflow-module}\index{tethne.workflow (module)}
Methods for network analysis.
\index{closeness\_introgression() (in module tethne.workflow)}

\begin{fulllineitems}
\phantomsection\label{tethne:tethne.workflow.closeness_introgression}\pysiglinewithargsret{\code{tethne.workflow.}\bfcode{closeness\_introgression}}{\emph{papers}, \emph{node}, \emph{window\_size}, \emph{normalize=False}}{}
Analyzes the global closeness centrality of a node over time.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\textbf{node} : any
\begin{quote}

Handle of the node to analyze.
\end{quote}

\textbf{window\_size} : int
\begin{quote}

Size of time-window.
\end{quote}

\textbf{normalize} : bool
\begin{quote}

If True, normalizes global closeness centrality for each year against
the average closeness centrality for that year. This will require
substantially more processing time, and values will usually be \textgreater{}\textgreater{} 0.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{trajectory} : dict
\begin{quote}

Global closeness centrality for node over specified period.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Subpackages}
\label{tethne:subpackages}

\subsubsection{analyze Package}
\label{tethne.analyze:analyze-package}\label{tethne.analyze::doc}

\paragraph{\texttt{analyze} Package}
\label{tethne.analyze:id1}\phantomsection\label{tethne.analyze:module-tethne.analyze}\index{tethne.analyze (module)}
The {\hyperref[tethne.analyze:module-tethne.analyze]{\code{tethne.analyze}}} sub-package provides additional analysis methods not
provided by NetworkX, as well as methods for using NetworkX algorithms on
an entire {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.analyze:module-tethne.analyze.collection]{\code{collection}}}
 & 
Methods for analyzing {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} objects.
\\\hline

{\hyperref[tethne.analyze:module-tethne.analyze.graph]{\code{graph}}}
 & 
Methods for network analysis.
\\\hline
\end{longtable}



\paragraph{\texttt{collection} Module}
\label{tethne.analyze:module-tethne.analyze.collection}\label{tethne.analyze:collection-module}\index{tethne.analyze.collection (module)}
Methods for analyzing {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} objects.

For the most part, these methods simply provide systematic access to algorithms
in NetworkX.
\index{algorithm() (in module tethne.analyze.collection)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.collection.algorithm}\pysiglinewithargsret{\code{tethne.analyze.collection.}\bfcode{algorithm}}{\emph{C}, \emph{method}, \emph{**kwargs}}{}
Apply NetworkX method to each \code{Graph} in {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}.

Passes kwargs to specified NetworkX method for each Graph, and returns
a dictionary of results indexed by element (node or edge) and graph index
(e.g. \code{date}).
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{C} : {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}
\begin{quote}

The {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to analyze. The specified method will be
applied to each \code{Graph} in \textbf{C}.
\end{quote}

\textbf{method} : string
\begin{quote}

Name of a method in NetworkX to execute on graph collection.
\end{quote}

\textbf{**kwargs} :
\begin{quote}

A list of keyword arguments that should correspond to the parameters
of the specified method.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{results} : dict
\begin{quote}

A nested dictionary of results: results/elem(node or edge)/graph
index.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{ValueError} :
\begin{quote}

If name is not in networkx, or if no such method exists.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\emph{Betweenness centrality:}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.analyze} \PYG{k+kn}{as} \PYG{n+nn}{az}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{az}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{algorithm}\PYG{p}{(}\PYG{n}{C}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{betweenness\PYGZus{}centrality}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print} \PYG{n}{BC}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+go}{\PYGZob{}1999: 0.010101651117889644,}
\PYG{g+go}{2000: 0.0008689093723107329,}
\PYG{g+go}{2001: 0.010504898852426189,}
\PYG{g+go}{2002: 0.009338654511194512,}
\PYG{g+go}{2003: 0.007519105636349891\PYGZcb{}}
\end{Verbatim}

\end{fulllineitems}

\index{attachment\_probability() (in module tethne.analyze.collection)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.collection.attachment_probability}\pysiglinewithargsret{\code{tethne.analyze.collection.}\bfcode{attachment\_probability}}{\emph{C}}{}
Calculates the observed attachment probability for each node at each
time-step.

Attachment probability is calculated based on the observed new edges in the
next time-step. So if a node acquires new edges at time t, this will accrue
to the node's attachment probability at time t-1. Thus at a given time,
one can ask whether degree and attachment probability are related.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{C} : {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}
\begin{quote}

Must be sliced by `date'. See \code{GraphCollection.slice()}.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{probs} : dict
\begin{quote}

Keyed by index in C.graphs, and then by node.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{connected() (in module tethne.analyze.collection)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.collection.connected}\pysiglinewithargsret{\code{tethne.analyze.collection.}\bfcode{connected}}{\emph{C}, \emph{method}, \emph{**kwargs}}{}
Performs analysis methods from networkx.connected on each graph in the
collection.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{C} : {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}
\begin{quote}

The {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to analyze. The specified method will be
applied to each \code{Graph} in \textbf{C}.
\end{quote}

\textbf{method} : string
\begin{quote}

Name of method in networkx.connected.
\end{quote}

\textbf{**kwargs} : kwargs
\begin{quote}

Keyword arguments, passed directly to method.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{results} : dictionary
\begin{quote}

Keys are graph indices, values are output of method for that graph.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{ValueError} :
\begin{quote}

If name is not in networkx.connected, or if no such method exists.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.data} \PYG{k+kn}{as} \PYG{n+nn}{ds}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.analyze} \PYG{k+kn}{as} \PYG{n+nn}{az}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{networkx} \PYG{k+kn}{as} \PYG{n+nn}{nx}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{ds}\PYG{o}{.}\PYG{n}{GraphCollection}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Generate some random graphs}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{graph\PYGZus{}index} \PYG{o+ow}{in} \PYG{n+nb}{xrange}\PYG{p}{(}\PYG{l+m+mi}{1999}\PYG{p}{,} \PYG{l+m+mi}{2004}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{g} \PYG{o}{=} \PYG{n}{nx}\PYG{o}{.}\PYG{n}{random\PYGZus{}regular\PYGZus{}graph}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }    \PYG{n}{C}\PYG{p}{[}\PYG{n}{graph\PYGZus{}index}\PYG{p}{]} \PYG{o}{=} \PYG{n}{g}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{results} \PYG{o}{=} \PYG{n}{az}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{connected}\PYG{p}{(}\PYG{n}{C}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{connected}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{k}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print} \PYG{n}{results}
\PYG{g+go}{\PYGZob{}1999: False,}
\PYG{g+go}{2000: False,}
\PYG{g+go}{2001: False,}
\PYG{g+go}{2002: False,}
\PYG{g+go}{2003: False \PYGZcb{}}
\end{Verbatim}

\end{fulllineitems}

\index{edge\_history() (in module tethne.analyze.collection)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.collection.edge_history}\pysiglinewithargsret{\code{tethne.analyze.collection.}\bfcode{edge\_history}}{\emph{C}, \emph{source}, \emph{target}, \emph{attribute}, \emph{verbose=False}}{}
Returns a dictionary of attribute vales for each Graph in C for a single
edge.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{C} : {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}

\textbf{source} : str
\begin{quote}

Identifier for source node.
\end{quote}

\textbf{target} : str
\begin{quote}

Identifier for target node.
\end{quote}

\textbf{attribute} : str
\begin{quote}

The attribute of interest; e.g. `betweenness\_centrality'
\end{quote}

\textbf{verbose} : bool
\begin{quote}

If True, prints status and debug messages.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{history} : dict
\begin{quote}

Keys are Graph keys in C; values are attribute values for edge.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{node\_global\_closeness\_centrality() (in module tethne.analyze.collection)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.collection.node_global_closeness_centrality}\pysiglinewithargsret{\code{tethne.analyze.collection.}\bfcode{node\_global\_closeness\_centrality}}{\emph{C}, \emph{node}}{}
Calculates global closeness centrality for node in each graph in
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} C.

\end{fulllineitems}

\index{node\_history() (in module tethne.analyze.collection)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.collection.node_history}\pysiglinewithargsret{\code{tethne.analyze.collection.}\bfcode{node\_history}}{\emph{C}, \emph{node}, \emph{attribute}, \emph{verbose=False}}{}
Returns a dictionary of attribute values for each Graph in C for a single
node.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{C} : {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}

\textbf{node} : str
\begin{quote}

The node of interest.
\end{quote}

\textbf{attribute} : str
\begin{quote}

The attribute of interest; e.g. `betweenness\_centrality'
\end{quote}

\textbf{verbose} : bool
\begin{quote}

If True, prints status and debug messages.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{history} : dict
\begin{quote}

Keys are Graph keys in C; values are attribute values for node.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{\texttt{graph} Module}
\label{tethne.analyze:module-tethne.analyze.graph}\label{tethne.analyze:graph-module}\index{tethne.analyze.graph (module)}
Methods for network analysis.
\index{global\_closeness\_centrality() (in module tethne.analyze.graph)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.graph.global_closeness_centrality}\pysiglinewithargsret{\code{tethne.analyze.graph.}\bfcode{global\_closeness\_centrality}}{\emph{g}, \emph{normalize=True}}{}
Calculates global closeness centrality for all nodes in the network.

See {\hyperref[tethne.analyze:tethne.analyze.graph.node_global_closeness_centrality]{\code{node\_global\_closeness\_centrality()}}} for more information.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{g} : networkx.Graph

\textbf{normalize} : boolean
\begin{quote}

If True, normalizes centrality based on the average shortest path
length. Default is True.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{C} : dict
\begin{quote}

Dictionary of results, with node identifiers as keys and gcc as values.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{node\_global\_closeness\_centrality() (in module tethne.analyze.graph)}

\begin{fulllineitems}
\phantomsection\label{tethne.analyze:tethne.analyze.graph.node_global_closeness_centrality}\pysiglinewithargsret{\code{tethne.analyze.graph.}\bfcode{node\_global\_closeness\_centrality}}{\emph{g}, \emph{node}, \emph{normalize=True}}{}
Calculates the global closeness centrality of a single node in the network.

Closeness centrality is based on the average shortest path length
between a focal node and all other nodes in the network. For multi-component
graphs, conventional closeness centrality metrics fail because it is not
possible to traverse between a given node and all other nodes in the graph.
Global closeness centrality is calculated in a way that yields values even
for multi-component graphs. For an example of how global closeness
centrality can be used to analyze co-authorship networks, see the blog post
\href{http://devo-evo.lab.asu.edu/node/459}{here}.

To calculate the global closeness centrality of a single node, try:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.analyze} \PYG{k+kn}{as} \PYG{n+nn}{az}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ngbc} \PYG{o}{=} \PYG{n}{az}\PYG{o}{.}\PYG{n}{node\PYGZus{}global\PYGZus{}closeness\PYGZus{}centrality}\PYG{p}{(}\PYG{n}{BC}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LEE 1975 EVOLUTION}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ngbc}
\PYG{g+go}{0.154245}
\end{Verbatim}

You can calculate the global closeness centrality of all nodes in the
network using {\hyperref[tethne.analyze:tethne.analyze.graph.global_closeness_centrality]{\code{global\_closeness\_centrality()}}} .

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{GBC} \PYG{o}{=} \PYG{n}{az}\PYG{o}{.}\PYG{n}{global\PYGZus{}closeness\PYGZus{}centrality}\PYG{p}{(}\PYG{n}{BC}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{GBC}
\PYG{g+go}{\PYGZob{}\PYGZsq{}a\PYGZsq{}: 0.0, \PYGZsq{}c\PYGZsq{}: 0.0, \PYGZsq{}b\PYGZsq{}: 0.6666666666666666, \PYGZsq{}d\PYGZsq{}: 0.0\PYGZcb{}}
\end{Verbatim}

For connected graphs, this is equivalent to conventional betweenness
centrality. For disconnected graphs, works around infinite path lengths
between nodes in different components.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{g} : networkx.Graph

\textbf{node} : any
\begin{quote}

Identifier of node of interest in g.
\end{quote}

\textbf{normalize} : boolean
\begin{quote}

If True, normalizes centrality based on the average shortest path
length. Default is True.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{c} : float
\begin{quote}

Global closeness centrality of node.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{matrices Package}
\label{tethne.matrices:matrices-package}\label{tethne.matrices::doc}

\paragraph{\texttt{matrices} Package}
\label{tethne.matrices:id1}\phantomsection\label{tethne.matrices:module-tethne.matrices}\index{tethne.matrices (module)}
Methods for generating matrices from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects and other data.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.matrices:module-tethne.matrices.dfr]{\code{dfr}}}
 & 
Methods for generating Numpy data objects from JSTOR Data-for-Research datasets.
\\\hline
\end{longtable}



\paragraph{\texttt{dfr} Module}
\label{tethne.matrices:module-tethne.matrices.dfr}\label{tethne.matrices:dfr-module}\index{tethne.matrices.dfr (module)}
Methods for generating Numpy data objects from JSTOR Data-for-Research datasets.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.matrices:tethne.matrices.dfr.array]{\code{array}}}(data{[}, normalize, verbose{]})
 & 
Yields a Numpy array, along with feature-index and document-index mappings.
\\\hline

{\hyperref[tethne.matrices:tethne.matrices.dfr.matrix]{\code{matrix}}}(data{[}, normalize, verbose{]})
 & 
Yields a Numpy matrix, along with feature-index and document-index mappings.
\\\hline
\end{longtable}

\index{Map (class in tethne.matrices.dfr)}

\begin{fulllineitems}
\phantomsection\label{tethne.matrices:tethne.matrices.dfr.Map}\pysigline{\strong{class }\code{tethne.matrices.dfr.}\bfcode{Map}}
Bases: \code{object}

Maps integer indices to string values.

\end{fulllineitems}

\index{array() (in module tethne.matrices.dfr)}

\begin{fulllineitems}
\phantomsection\label{tethne.matrices:tethne.matrices.dfr.array}\pysiglinewithargsret{\code{tethne.matrices.dfr.}\bfcode{array}}{\emph{data}, \emph{normalize=False}, \emph{verbose=False}}{}
Yields a Numpy array, along with feature-index and document-index mappings.

\textbf{Usage}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.matrices} \PYG{k+kn}{as} \PYG{n+nn}{mt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{ngrams}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/DfR/data}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{A}\PYG{p}{,} \PYG{n}{doc\PYGZus{}index}\PYG{p}{,} \PYG{n}{feat\PYGZus{}index} \PYG{o}{=} \PYG{n}{mt}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{normalize}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{data} : dict
\begin{quote}

Keys are document identifiers (e.g. DOIs), values are lists of feature-
frequency tuples.
\end{quote}

\textbf{normalize} : bool
\begin{quote}

If True, matrix values are relative to the maximum value in the matrix.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{A} : Numpy array
\begin{quote}

Columns are documents, rows are features.
\end{quote}

\textbf{document\_index} : class:\emph{.Map}
\begin{quote}

Maps column indices to document identifiers (keys of provided data).
\end{quote}

\textbf{feature\_index} : {\hyperref[tethne.matrices:tethne.matrices.dfr.Map]{\code{Map}}}
\begin{quote}

Maps row indices to features.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{matrix() (in module tethne.matrices.dfr)}

\begin{fulllineitems}
\phantomsection\label{tethne.matrices:tethne.matrices.dfr.matrix}\pysiglinewithargsret{\code{tethne.matrices.dfr.}\bfcode{matrix}}{\emph{data}, \emph{normalize=False}, \emph{verbose=False}}{}
Yields a Numpy matrix, along with feature-index and document-index mappings.

\textbf{Usage}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.matrices} \PYG{k+kn}{as} \PYG{n+nn}{mt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{ngrams}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/DfR/data}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{M}\PYG{p}{,} \PYG{n}{doc\PYGZus{}index}\PYG{p}{,} \PYG{n}{feat\PYGZus{}index} \PYG{o}{=} \PYG{n}{mt}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{matrix}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{normalize}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{data} : dict
\begin{quote}

Keys are document identifiers (e.g. DOIs), values are lists of feature-
frequency tuples.
\end{quote}

\textbf{normalize} : bool
\begin{quote}

If True, matrix values are relative to the maximum value in the matrix.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{M} : Numpy matrix
\begin{quote}

Columns are documents, rows are features.
\end{quote}

\textbf{document\_index} : class:\emph{.Map}
\begin{quote}

Maps column indices to document identifiers (keys of provided data).
\end{quote}

\textbf{feature\_index} : {\hyperref[tethne.matrices:tethne.matrices.dfr.Map]{\code{Map}}}
\begin{quote}

Maps row indices to features.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{networks Package}
\label{tethne.networks:networks-package}\label{tethne.networks::doc}

\paragraph{\texttt{networks} Package}
\label{tethne.networks:id1}\phantomsection\label{tethne.networks:module-tethne.networks}\index{tethne.networks (module)}
Methods for building networks from bibliographic data.

Each network relies on certain meta data in the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} associated with
each document. Often we wish to construct a network with nodes representing
these documents and edges representing relationships between those documents,
but this is not always the case.

Where it is the case, it is recommended but not required that nodes are
represented by an identifier from \{ayjid, wosid, pmid, doi\}. Each has certain
benefits. If the documents to be networked come from a single database source
such as the Web of Science, wosid is most appropriate. If not, using doi
will result in a more accurate, but also more sparse network; while ayjid
will result in a less accurate, but more complete network.

Any type of meta data from the {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} may be used as an identifier,
however.

We use ``head'' and ``tail'' nomenclature to refer to the members of a directed
edge (x,y), x -\textgreater{} y, xy, etc. by calling x the ``tail'' and y the ``head''.


\subparagraph{Modules}
\label{tethne.networks:modules}
\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.networks:module-tethne.networks.authors]{\code{authors}}}
 & 
Methods for generating networks in which authors are vertices.
\\\hline

{\hyperref[tethne.networks:module-tethne.networks.helpers]{\code{helpers}}}
 & 
Helper functions for generating networks.
\\\hline

{\hyperref[tethne.networks:module-tethne.networks.papers]{\code{papers}}}
 & 
Methods for generating networks in which papers are vertices.
\\\hline

{\hyperref[tethne.networks:module-tethne.networks.terms]{\code{terms}}}
 & 
Methods for building networks from terms in bibliographic records.
\\\hline

{\hyperref[tethne.networks:module-tethne.networks.topics]{\code{topics}}}
 & 
Build networks from topics in a topic model.
\\\hline
\end{longtable}



\paragraph{\texttt{authors} Module}
\label{tethne.networks:module-tethne.networks.authors}\label{tethne.networks:authors-module}\index{tethne.networks.authors (module)}
Methods for generating networks in which authors are vertices.


\subparagraph{Methods}
\label{tethne.networks:methods}
\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.networks:tethne.networks.authors.author_cocitation]{\code{author\_cocitation}}}(papers{[}, threshold{]})
 & 
Generates an author co-citation network; edges indicate co-citation of authors' papers.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.author_coinstitution]{\code{author\_coinstitution}}}(Papers{[}, threshold{]})
 & 
Generate a co-institution graph, where edges indicate shared affiliation.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.author_institution]{\code{author\_institution}}}(Papers{[}, edge\_attribs{]})
 & 
Generate a bi-partite graph connecting authors and their institutions.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.author_papers]{\code{author\_papers}}}(papers{[}, node\_id, paper\_attribs{]})
 & 
Generate an author\_papers network NetworkX directed graph.
\\\hline

{\hyperref[tethne.networks:tethne.networks.authors.coauthors]{\code{coauthors}}}(papers{[}, threshold, edge\_attribs{]})
 & 
Generate a co-author network.
\\\hline
\end{longtable}

\index{author\_cocitation() (in module tethne.networks.authors)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.authors.author_cocitation}\pysiglinewithargsret{\code{tethne.networks.authors.}\bfcode{author\_cocitation}}{\emph{papers}, \emph{threshold=1}, \emph{**kwargs}}{}
Generates an author co-citation network; edges indicate co-citation of
authors' papers.

Similar to {\hyperref[tethne.networks:tethne.networks.papers.cocitation]{\code{papers.cocitation()}}}, except that vertices are authors
rather than papers. To generate an author co-citation network, use the
{\hyperref[tethne.networks:tethne.networks.authors.author_cocitation]{\code{networks.authors.author\_cocitation()}}} method:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ACC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{authors}\PYG{o}{.}\PYG{n}{author\PYGZus{}cocitation}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ACC}
\PYG{g+go}{\PYGZlt{}networkx.classes.graph.Graph object at 0x106571190\PYGZgt{}}
\end{Verbatim}

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Nodes
 & 
Author name.
\\\hline

Edge
 & 
(a, b) if a and b are referenced by the same paper in
papers
\\\hline

Edge attribute
 & 
`weight', the number of papers that co-cite a and b.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\textbf{threshold} : int
\begin{quote}

Minimum number of co-citations required to create an edge between
authors.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{cocitation} : \code{networkx.Graph}
\begin{quote}

A cocitation network.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{author\_coinstitution() (in module tethne.networks.authors)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.authors.author_coinstitution}\pysiglinewithargsret{\code{tethne.networks.authors.}\bfcode{author\_coinstitution}}{\emph{Papers}, \emph{threshold=1}, \emph{**kwargs}}{}
Generate a co-institution graph, where edges indicate shared affiliation.

Some bibliographic datasets, including data from the Web of Science,
includes the institutional affiliations of authors. In a co-institution
graph, two authors (vertices) have an edge between them if they share an
institutional affiliation in the dataset. Note that data about institutional
affiliations varies in the WoS database so this will yield more reliable
results for more recent publications.

To generate a co-institution network, use the
{\hyperref[tethne.networks:tethne.networks.authors.author_coinstitution]{\code{networks.authors.author\_coinstitution()}}} method:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ACI} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{authors}\PYG{o}{.}\PYG{n}{author\PYGZus{}coinstitution}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ACI}
\PYG{g+go}{\PYGZlt{}networkx.classes.graph.Graph object at 0x106571190\PYGZgt{}}
\end{Verbatim}

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Authors.
\\\hline

Node Attribute
 & 
type (string). `author' or `institution'.
\\\hline

Edges
 & 
(a, b) where a and b are affiliated with the same
institution.
\\\hline

Edge attribute
 & 
overlap (int). number of shared institutions.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{Papers} : list
\begin{quote}

A list of wos\_objects.
\end{quote}

\textbf{threshold} : int
\begin{quote}

Minimum institutional overlap required for an edge.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{coinstitution} : NetworkX \code{graph}
\begin{quote}

A coinstitution network.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{author\_institution() (in module tethne.networks.authors)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.authors.author_institution}\pysiglinewithargsret{\code{tethne.networks.authors.}\bfcode{author\_institution}}{\emph{Papers}, \emph{edge\_attribs=}\optional{}, \emph{**kwargs}}{}
Generate a bi-partite graph connecting authors and their institutions.

This may be slightly ambiguous for WoS data where there is no explicit
author-institution mapping. Edge weights are the number of co-associations
between an author and an institution, which should help resolve this
ambiguity (the more data the better).

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Author name.
\\\hline

Edge
 & 
(a,b) in E(G) if a and b are authors on the same paper.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{Papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\textbf{edge\_attribs} : list
\begin{quote}

List of edge\_attributes specifying which {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} keys (from the
authored paper) to use as edge attributes. For example, the `date' key
in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} .
\end{quote}

\item[{Returns }] \leavevmode
\textbf{author\_institution\_graph} : networkx.MultiGraph
\begin{quote}

A graph describing institutional affiliations of authors in the corpus.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{author\_papers() (in module tethne.networks.authors)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.authors.author_papers}\pysiglinewithargsret{\code{tethne.networks.authors.}\bfcode{author\_papers}}{\emph{papers}, \emph{node\_id='ayjid'}, \emph{paper\_attribs=}\optional{}, \emph{**kwargs}}{}
Generate an author\_papers network NetworkX directed graph.

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Two kinds of nodes with distinguishing ``type'' attributes:
* type = paper    - a paper in papers
* type = person   - a person in papers
Papers node attributes defined by paper\_attribs.
\\\hline

Edge
 & 
Directed, Author -\textgreater{} his/her Paper.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of wos\_objects.
\end{quote}

\textbf{node\_id} : string
\begin{quote}

A key from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} used to identify the nodes.
\end{quote}

\textbf{paper\_attribs} : list
\begin{quote}

List of user-provided optional arguments apart from the provided
positional arguments.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{author\_papers\_graph} : networkx.DiGraph
\begin{quote}

A DiGraph `author\_papers\_graph'.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{KeyError} : Raised when node\_id is not present in Papers.

\end{description}\end{quote}

\end{fulllineitems}

\index{coauthors() (in module tethne.networks.authors)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.authors.coauthors}\pysiglinewithargsret{\code{tethne.networks.authors.}\bfcode{coauthors}}{\emph{papers, threshold=1, edge\_attribs={[}'ayjid'{]}, **kwargs}}{}
Generate a co-author network.

As the name suggests, edges are drawn between two author-vertices in the
case that those authors published a paper together. Co-authorship networks
are popular models for studying patterns of collaboration in scientific
communities.

To generate a co-authorship network, use the
{\hyperref[tethne.networks:tethne.networks.authors.coauthors]{\code{networks.authors.coauthors()}}} method:

Author institutional affiliation is included as a node attribute, if 
possible.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{CA} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{authors}\PYG{o}{.}\PYG{n}{coauthors}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{CA}
\PYG{g+go}{\PYGZlt{}networkx.classes.multigraph.MultiGraph object at 0x101705650\PYGZgt{}}
\end{Verbatim}

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Author name.
\\\hline

Edges
 & 
(a,b) in E(G) if a and b are coauthors on the same paper.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of \code{Paper} instances.
\end{quote}

\textbf{threshold} : int
\begin{quote}

Minimum number of co-citations required for an edge. (default: 1)
\end{quote}

\textbf{edge\_attribs} : list
\begin{quote}

List of edge\_attributes specifying which {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} keys (from the
co-authored paper) to use as edge attributes. (default: {[}'ayjid'{]})
\end{quote}

\item[{Returns }] \leavevmode
\textbf{G} : networkx.Graph
\begin{quote}

A co-authorship network.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{\texttt{helpers} Module}
\label{tethne.networks:helpers-module}\label{tethne.networks:module-tethne.networks.helpers}\index{tethne.networks.helpers (module)}
Helper functions for generating networks.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.networks:tethne.networks.helpers.citation_count]{\code{citation\_count}}}(papers{[}, key, verbose{]})
 & 
Generates citation counts for all of the papers cited by papers.
\\\hline

{\hyperref[tethne.networks:tethne.networks.helpers.simplify_multigraph]{\code{simplify\_multigraph}}}(multigraph{[}, time{]})
 & 
Simplifies a graph by condensing multiple edges between the same node pair into a single edge, with a weight attribute equal to the number of edges.
\\\hline

{\hyperref[tethne.networks:tethne.networks.helpers.top_cited]{\code{top\_cited}}}(papers{[}, topn, verbose{]})
 & 
Generates a list of the topn (or topn\%) most cited papers.
\\\hline

{\hyperref[tethne.networks:tethne.networks.helpers.top_parents]{\code{top\_parents}}}(papers{[}, topn, verbose{]})
 & 
Returns a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} that cite the topn most cited papers.
\\\hline
\end{longtable}

\index{citation\_count() (in module tethne.networks.helpers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.helpers.citation_count}\pysiglinewithargsret{\code{tethne.networks.helpers.}\bfcode{citation\_count}}{\emph{papers}, \emph{key='ayjid'}, \emph{verbose=False}}{}
Generates citation counts for all of the papers cited by papers.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\textbf{key} : str
\begin{quote}

Property to use as node key. Default is `ayjid' (recommended).
\end{quote}

\textbf{verbose} : bool
\begin{quote}

If True, prints status messages.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{counts} : dict
\begin{quote}

Citation counts for all papers cited by papers.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{simplify\_multigraph() (in module tethne.networks.helpers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.helpers.simplify_multigraph}\pysiglinewithargsret{\code{tethne.networks.helpers.}\bfcode{simplify\_multigraph}}{\emph{multigraph}, \emph{time=False}}{}
Simplifies a graph by condensing multiple edges between the same node pair
into a single edge, with a weight attribute equal to the number of edges.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{graph} : networkx.MultiGraph
\begin{quote}

E.g. a coauthorship graph.
\end{quote}

\textbf{time} : bool
\begin{quote}

If True, will generate `start' and `end' attributes for each edge,
corresponding to the earliest and latest `date' values for that edge.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{graph} : networkx.Graph
\begin{quote}

A NetworkX \code{graph} .
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{top\_cited() (in module tethne.networks.helpers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.helpers.top_cited}\pysiglinewithargsret{\code{tethne.networks.helpers.}\bfcode{top\_cited}}{\emph{papers}, \emph{topn=20}, \emph{verbose=False}}{}
Generates a list of the topn (or topn\%) most cited papers.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\textbf{topn} : int or float \{0.-1.\}
\begin{quote}

Number (int) or percentage (float) of top-cited papers to return.
\end{quote}

\textbf{verbose} : bool
\begin{quote}

If True, prints status messages.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{top} : list
\begin{quote}

A list of `ayjid' keys for the topn most cited papers.
\end{quote}

\textbf{counts} : dict
\begin{quote}

Citation counts for all papers cited by papers.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{top\_parents() (in module tethne.networks.helpers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.helpers.top_parents}\pysiglinewithargsret{\code{tethne.networks.helpers.}\bfcode{top\_parents}}{\emph{papers}, \emph{topn=20}, \emph{verbose=False}}{}
Returns a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} that cite the topn most cited papers.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\textbf{topn} : int or float \{0.-1.\}
\begin{quote}

Number (int) or percentage (float) of top-cited papers.
\end{quote}

\textbf{verbose} : bool
\begin{quote}

If True, prints status messages.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\textbf{top} : list
\begin{quote}

A list of `ayjid' keys for the topn most cited papers.
\end{quote}

\textbf{counts} : dict
\begin{quote}

Citation counts for all papers cited by papers.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{\texttt{papers} Module}
\label{tethne.networks:module-tethne.networks.papers}\label{tethne.networks:papers-module}\index{tethne.networks.papers (module)}
Methods for generating networks in which papers are vertices.


\subparagraph{Methods}
\label{tethne.networks:id2}
\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.networks:tethne.networks.papers.author_coupling]{\code{author\_coupling}}}(papers{[}, threshold, ...{]})
 & 
Vertices are papers and edges indicates shared authorship.
\\\hline

{\hyperref[tethne.networks:tethne.networks.papers.bibliographic_coupling]{\code{bibliographic\_coupling}}}(papers{[}, ...{]})
 & 
Generate a bibliographic coupling network.
\\\hline

{\hyperref[tethne.networks:tethne.networks.papers.cocitation]{\code{cocitation}}}(papers{[}, threshold, node\_id, ...{]})
 & 
Generate a cocitation network.
\\\hline

{\hyperref[tethne.networks:tethne.networks.papers.direct_citation]{\code{direct\_citation}}}(papers{[}, node\_id, node\_attribs{]})
 & 
Create a traditional directed citation network.
\\\hline

{\hyperref[tethne.networks:tethne.networks.papers.topic_coupling]{\code{topic\_coupling}}}(papers{[}, threshold, node\_id{]})
 & 
Two papers are coupled if they both contain a shared topic above threshold.
\\\hline
\end{longtable}

\index{author\_coupling() (in module tethne.networks.papers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.papers.author_coupling}\pysiglinewithargsret{\code{tethne.networks.papers.}\bfcode{author\_coupling}}{\emph{papers, threshold=1, node\_attribs={[}'date'{]}, node\_id='ayjid', **kwargs}}{}
Vertices are papers and edges indicates shared authorship.

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Papers, represented by node\_id.
\\\hline

Edge
 & 
(a,b) in E(G) if a and b share x authors and x \textgreater{}=
threshold
\\\hline

Edge Attributes
 & 
overlap: the value of x (above).
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\end{quote}

\textbf{threshold} : int
\begin{quote}

Minimum number of co-citations required to draw an edge between two
authors.
\end{quote}

\textbf{node\_id} : string
\begin{quote}

Field in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} used to identify nodes.
\end{quote}

\textbf{node\_attribs} : list
\begin{quote}

List of fields in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} to include as node attributes in
graph.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{acoupling} : networkx.Graph
\begin{quote}

An author-coupling network.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{bibliographic\_coupling() (in module tethne.networks.papers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.papers.bibliographic_coupling}\pysiglinewithargsret{\code{tethne.networks.papers.}\bfcode{bibliographic\_coupling}}{\emph{papers, citation\_id='ayjid', threshold=1, node\_id='ayjid', node\_attribs={[}'date'{]}, weighted=False, **kwargs}}{}
Generate a bibliographic coupling network.

Two papers are \textbf{bibliographically coupled} when they both cite the same,
third, paper. You can generate a bibliographic coupling network using the
{\hyperref[tethne.networks:tethne.networks.papers.bibliographic_coupling]{\code{networks.papers.bibliographic\_coupling()}}} method.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{bibliographic\PYGZus{}coupling}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC}
\PYG{g+go}{\PYGZlt{}networkx.classes.graph.Graph object at 0x102eec710\PYGZgt{}}
\end{Verbatim}

Especially when working with large datasets, or disciplinarily narrow
literatures, it is usually helpful to set a minimum number of shared
citations required for two papers to be coupled. You can do this by setting
the \textbf{{}`threshold{}`} parameter.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{bibliographic\PYGZus{}coupling}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{BC}\PYG{o}{.}\PYG{n}{edges}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{1216}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{BC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{bibliographic\PYGZus{}coupling}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{BC}\PYG{o}{.}\PYG{n}{edges}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{542}
\end{Verbatim}

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Papers represented by node\_id.
\\\hline

Node Attributes
 & 
node\_attribs in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\\\hline

Edge
 & 
(a,b) in E(G) if a and b share x citations where x \textgreater{}=
threshold.
\\\hline

Edge Attributes
 & 
overlap: the number of citations shared
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of wos\_objects.
\end{quote}

\textbf{citation\_id: string} :
\begin{quote}

A key from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} to identify the citation overlaps.  Default
is `ayjid'.
\end{quote}

\textbf{threshold} : int
\begin{quote}

Minimum number of shared citations to consider two papers ``coupled''.
\end{quote}

\textbf{node\_id} : string
\begin{quote}

Field in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} used to identify the nodes. Default is `ayjid'.
\end{quote}

\textbf{node\_attribs} : list
\begin{quote}

List of fields in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} to include as node attributes in
graph.
\end{quote}

\textbf{weighted} : bool
\begin{quote}

If True, edge attribute \emph{overlap} is a float in \{0-1\} calculated as
$\cfrac{N_{ij}}{\sqrt{N_{i}N_{j}}}$ where $N_{i}$ and
$N_{j}$ are the number of references in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} \emph{i} and
\emph{j}, respectively, and $N_{ij}$ is the number of references
shared by papers \emph{i} and \emph{j}.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{bcoupling} : networkx.Graph
\begin{quote}

A bibliographic coupling network.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{KeyError} : Raised when citation\_id is not present in the meta\_list.

\end{description}\end{quote}
\paragraph{Notes}

Lists cannot be attributes? causing errors for both gexf and graphml also
nodes cannot be none.

\end{fulllineitems}

\index{cocitation() (in module tethne.networks.papers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.papers.cocitation}\pysiglinewithargsret{\code{tethne.networks.papers.}\bfcode{cocitation}}{\emph{papers, threshold=1, node\_id='ayjid', topn=None, verbose=False, node\_attribs={[}'date'{]}, **kwargs}}{}
Generate a cocitation network.

A \textbf{cocitation network} is a network in which vertices are papers, and
edges indicate that two papers were cited by the same third paper.
\href{http://cluster.cis.drexel.edu/~cchen/citespace/doc/jasist2006.pdf}{CiteSpace}
is a popular desktop application for co-citation analysis, and you can read
about the theory behind it
\href{http://cluster.cis.drexel.edu/~cchen/citespace/}{here}. Co-citation
analysis is generally performed with a temporal component, so building a
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} from a :class{}`.DataCollection{}` sliced by \code{date}
is recommended.

You can generate a co-citation network using the
{\hyperref[tethne.networks:tethne.networks.papers.cocitation]{\code{networks.papers.cocitation()}}} method:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{CC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{cocitation}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{CC}
\PYG{g+go}{\PYGZlt{}networkx.classes.graph.Graph object at 0x102eec790\PYGZgt{}}
\end{Verbatim}

For large datasets, you may wish to set a minimum number of co-citations
required for an edge between two papers Keep in mind that all of the
references in a single paper are co-cited once, so a threshold of at least
2 is prudent. Note the dramatic decrease in the number of edges when the
threshold is changed from 2 to 3.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{CC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{cocitation}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{CC}\PYG{o}{.}\PYG{n}{edges}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{8889}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{CC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{cocitation}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{CC}\PYG{o}{.}\PYG{n}{edges}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{1493}
\end{Verbatim}

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Cited papers represented by {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} ayjid.
\\\hline

Edge
 & 
(a, b) if a and b are cited by the same paper.
\\\hline

Edge Attributes
 & 
weight: number of times two papers are co-cited
together.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\textbf{threshold} : int
\begin{quote}

Minimum number of co-citations required to create an edge.
\end{quote}

\textbf{topn} : int or float, or None
\begin{quote}

If provided, only the topn (int) or topn percent (float) most cited
papers will be included in the cocitation network. If None (default),
network will include all cited papers (NOTE: this can cause severe
memory consumption for even moderately-sized datasets).
\end{quote}

\textbf{verbose} : bool
\begin{quote}

If True, prints status messages.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{cocitation} : networkx.Graph
\begin{quote}

A cocitation network.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{direct\_citation() (in module tethne.networks.papers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.papers.direct_citation}\pysiglinewithargsret{\code{tethne.networks.papers.}\bfcode{direct\_citation}}{\emph{papers, node\_id='ayjid', node\_attribs={[}'date'{]}, **kwargs}}{}
Create a traditional directed citation network.

Direct-citation graphs are \href{http://en.wikipedia.org/wiki/Directed\_acyclic\_graph}{directed acyclic graphs} in which vertices are
papers, and each (directed) edge represents a citation of the target
paper by the source paper. The {\hyperref[tethne.networks:tethne.networks.papers.direct_citation]{\code{networks.papers.direct\_citation()}}}
method generates both a global citation graph, which includes all cited and
citing papers, and an internal citation graph that describes only citations
among papers in the original dataset.

To generate direct-citation graphs, use the
{\hyperref[tethne.networks:tethne.networks.papers.direct_citation]{\code{networks.papers.direct\_citation()}}} method. Note the size difference
between the global and internal citation graphs.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{gDC}\PYG{p}{,} \PYG{n}{iDC} \PYG{o}{=} \PYG{n}{nt}\PYG{o}{.}\PYG{n}{papers}\PYG{o}{.}\PYG{n}{direct\PYGZus{}citation}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{gDC}\PYG{p}{)}
\PYG{g+go}{5998}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{iDC}\PYG{p}{)}
\PYG{g+go}{163}
\end{Verbatim}

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Papers, represented by node\_id.
\\\hline

Edge
 & 
From a paper to a cited reference.
\\\hline

Edge Attribute
 & 
Publication date of the citing paper.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\textbf{node\_id} : int
\begin{quote}

A key from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} to identify the nodes. Default is `ayjid'.
\end{quote}

\textbf{node\_attribs} : list
\begin{quote}

List of user provided optional arguments apart from the provided
positional arguments.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{citation\_network} : networkx.DiGraph
\begin{quote}

Global citation network (all citations).
\end{quote}

\textbf{citation\_network\_internal} : networkx.DiGraph
\begin{quote}

Internal citation network where only the papers in the list are nodes in
the network.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{KeyError} : If node\_id is not present in the meta\_list.

\end{description}\end{quote}

\end{fulllineitems}

\index{topic\_coupling() (in module tethne.networks.papers)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.papers.topic_coupling}\pysiglinewithargsret{\code{tethne.networks.papers.}\bfcode{topic\_coupling}}{\emph{papers}, \emph{threshold=0.7}, \emph{node\_id='ayjid'}, \emph{**kwargs}}{}
Two papers are coupled if they both contain a shared topic above threshold.

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textbf{
Element
} & \textbf{
Description
}\\\hline

Node
 & 
Papers, represented by node\_id.
\\\hline

Edge
 & 
(a,b) in E(G) if a and b share \textgreater{}= 1 topics with
proportion \textgreater{}= threshold in both a and b.
\\\hline

Edge Attributes
 & 
weight: combined mean proportion of each shared topic.
topics: list of shared topics.
\\\hline
\end{tabulary}

\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\end{quote}

\textbf{threshold} : float
\begin{quote}

Minimum representation of a topic in each paper.
\end{quote}

\textbf{node\_id} : string
\begin{quote}

Field in {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} used to identify nodes.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{tc} : networkx.Graph
\begin{quote}

A topic-coupling network.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{\texttt{terms} Module}
\label{tethne.networks:module-tethne.networks.terms}\label{tethne.networks:terms-module}\index{tethne.networks.terms (module)}
Methods for building networks from terms in bibliographic records. This
includes keywords, abstract terms, etc.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.networks:tethne.networks.terms.keyword_cooccurrence]{\code{keyword\_cooccurrence}}}(papers, threshold{[}, ...{]})
 & 
Generates a keyword cooccurrence network.
\\\hline

{\hyperref[tethne.networks:tethne.networks.terms.topic_coupling]{\code{topic\_coupling}}}(model{[}, threshold{]})
 & 
Creates a network of words connected by implication in a common topic(s).
\\\hline
\end{longtable}

\index{keyword\_cooccurrence() (in module tethne.networks.terms)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.terms.keyword_cooccurrence}\pysiglinewithargsret{\code{tethne.networks.terms.}\bfcode{keyword\_cooccurrence}}{\emph{papers}, \emph{threshold}, \emph{connected=False}, \emph{**kwargs}}{}
Generates a keyword cooccurrence network.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\textbf{threshold} : int
\begin{quote}

Minimum number of occurrences for a keyword pair to appear in graph.
\end{quote}

\textbf{connected} : bool
\begin{quote}

If True, returns only the largest connected component.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{k\_coccurrence} :  networkx.Graph
\begin{quote}

A keyword coccurrence network.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{topic\_coupling() (in module tethne.networks.terms)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.terms.topic_coupling}\pysiglinewithargsret{\code{tethne.networks.terms.}\bfcode{topic\_coupling}}{\emph{model}, \emph{threshold=0.005}, \emph{**kwargs}}{}
Creates a network of words connected by implication in a common topic(s).
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{model} : {\hyperref[tethne:tethne.data.LDAModel]{\code{LDAModel}}}

\textbf{threshold} : float
\begin{quote}

Minimum P(W\textbar{}T) for coupling.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{tc} : networkx.Graph
\begin{quote}

A topic-coupling graph, where nodes are terms.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{\texttt{topics} Module}
\label{tethne.networks:topics-module}\label{tethne.networks:module-tethne.networks.topics}\index{tethne.networks.topics (module)}
Build networks from topics in a topic model.
\index{paper\_coupling() (in module tethne.networks.topics)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.topics.paper_coupling}\pysiglinewithargsret{\code{tethne.networks.topics.}\bfcode{paper\_coupling}}{\emph{model}, \emph{threshold=0.1}}{}
\end{fulllineitems}

\index{term\_coupling() (in module tethne.networks.topics)}

\begin{fulllineitems}
\phantomsection\label{tethne.networks:tethne.networks.topics.term_coupling}\pysiglinewithargsret{\code{tethne.networks.topics.}\bfcode{term\_coupling}}{\emph{model}, \emph{threshold=0.01}}{}
\end{fulllineitems}



\subsubsection{readers Package}
\label{tethne.readers:readers-package}\label{tethne.readers::doc}

\paragraph{\texttt{readers} Package}
\label{tethne.readers:id1}\phantomsection\label{tethne.readers:module-tethne.readers}\index{tethne.readers (module)}
Methods for parsing bibliographic datasets.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.readers:module-tethne.readers.dfr]{\code{dfr}}}
 & 
Methods for parsing JSTOR Data-for-Research datasets.
\\\hline

{\hyperref[tethne.readers:module-tethne.readers.mallet]{\code{mallet}}}
 & 
Reader for output from topic modeling with MALLET.
\\\hline

{\hyperref[tethne.readers:module-tethne.readers.pubmed]{\code{pubmed}}}
 & 
Methods for working with PubMed data are still under development. Please use
\\\hline

{\hyperref[tethne.readers:module-tethne.readers.wos]{\code{wos}}}
 & 
Reader for Web of Science field-tagged bibliographic data.
\\\hline
\end{longtable}


Each file reader provides methods to parse bibliographic data from a
scholarly database (e.g. Web of Science or PubMed), resulting in a
list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances containing as many as possible of
the following keys (missing values are set to None):

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Field
} & \textbf{
Type
} & \textbf{
Description
}\\\hline

aulast
 & 
list
 & 
Authors' surnames, as a list.
\\\hline

auinit
 & 
list
 & 
Authors' initials, as a list.
\\\hline

institution
 & 
dict
 & 
Institutions with which the authors are affiliated.
\\\hline

atitle
 & 
str
 & 
Article title.
\\\hline

jtitle
 & 
str
 & 
Journal title or abbreviated title.
\\\hline

volume
 & 
str
 & 
Journal volume number.
\\\hline

issue
 & 
str
 & 
Journal issue number.
\\\hline

spage
 & 
str
 & 
Starting page of article in journal.
\\\hline

epage
 & 
str
 & 
Ending page of article in journal.
\\\hline

date
 & 
int
 & 
Date of publication.
\\\hline

abstract
 & 
str
 & \\\hline
\end{tabulary}


These keys are associated with the meta data entries in the databases of
organizations such as the International DOI Foundation and its Registration
Agencies such as CrossRef and DataCite.

In addition, {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances will contain keys with information
relevant to the networks of interest for Tethne including:

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textbf{
Field
} & \textbf{
Type
} & \textbf{
Description
}\\\hline

citations
 & 
list
 & 
List of minimum {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances for cited
references.
\\\hline

ayjid
 & 
str
 & 
First author's name (last, fi), publication year, and
journal.
\\\hline

doi
 & 
str
 & 
Digital Object Identifier.
\\\hline

pmid
 & 
str
 & 
PubMed ID.
\\\hline

wosid
 & 
str
 & 
Web of Science UT fieldtag.
\\\hline
\end{tabulary}


Missing data here also results in the above keys being set to None.
\index{DataError}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.DataError}\pysiglinewithargsret{\strong{exception }\code{tethne.readers.}\bfcode{DataError}}{\emph{value}}{}
Bases: \code{exceptions.Exception}

\end{fulllineitems}

\index{merge() (in module tethne.readers)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.merge}\pysiglinewithargsret{\code{tethne.readers.}\bfcode{merge}}{\emph{P1, P2, fields={[}'ayjid'{]}}}{}
Combines two lists (P1 and P2) of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances into a single
list, and attempts to merge papers with matching fields. Where there are
conflicts, values from {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} in P1 will be preferred.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{P1} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\textbf{P2} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\textbf{fields} : list
\begin{quote}

Fields used to identify matching {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\end{quote}

\item[{Returns }] \leavevmode
\textbf{combined} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{P1} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/data1.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{P2} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/DfR}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{merge}\PYG{p}{(}\PYG{n}{P1}\PYG{p}{,} \PYG{n}{P2}\PYG{p}{,} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ayjid}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}



\paragraph{\texttt{dfr} Module}
\label{tethne.readers:module-tethne.readers.dfr}\label{tethne.readers:dfr-module}\index{tethne.readers.dfr (module)}
Methods for parsing JSTOR Data-for-Research datasets.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.readers:tethne.readers.dfr.ngrams]{\code{ngrams}}}(datapath{[}, N, ignore\_hash, ...{]})
 & 
Yields N-grams from a JSTOR DfR dataset.
\\\hline

{\hyperref[tethne.readers:tethne.readers.dfr.read]{\code{read}}}(datapath)
 & 
Yields {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} s from JSTOR DfR package.
\\\hline
\end{longtable}

\index{from\_dir() (in module tethne.readers.dfr)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.dfr.from_dir}\pysiglinewithargsret{\code{tethne.readers.dfr.}\bfcode{from\_dir}}{\emph{path}}{}
Convenience function for generating a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} from a
directory of JSTOR DfR datasets.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{path} : string
\begin{quote}

Path to directory containing DfR dataset directories.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{IOError} :
\begin{quote}

Invalid path.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{from\PYGZus{}dir}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/datadir}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}

\index{ngrams() (in module tethne.readers.dfr)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.dfr.ngrams}\pysiglinewithargsret{\code{tethne.readers.dfr.}\bfcode{ngrams}}{\emph{datapath}, \emph{N='bi'}, \emph{ignore\_hash=True}, \emph{apply\_stoplist=False}}{}
Yields N-grams from a JSTOR DfR dataset.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{filepath} : string
\begin{quote}

Filepath to unzipped JSTOR DfR folder containing N-grams (e.g.
`bigrams').
\end{quote}

\textbf{N} : string
\begin{quote}

`bi', `tri', or `quad'
\end{quote}

\textbf{ignore\_hash} : bool
\begin{quote}

If True, will exclude all N-grams that contain the hash `\#' character.
\end{quote}

\textbf{apply\_stoplist} : bool
\begin{quote}

If True, will exclude all N-grams that contain words in the NLTK
stoplist.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{ngrams} : dict
\begin{quote}

Keys are paper DOIs, values are lists of (Ngram, frequency) tuples.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{trigrams} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{ngrams}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/DfR}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{N}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{tri}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}

\index{read() (in module tethne.readers.dfr)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.dfr.read}\pysiglinewithargsret{\code{tethne.readers.dfr.}\bfcode{read}}{\emph{datapath}}{}
Yields {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} s from JSTOR DfR package.

Each {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} is tagged with an accession id for this
read/conversion.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{filepath} : string
\begin{quote}

Filepath to unzipped JSTOR DfR folder containing a citations.XML file.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{dfr}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/DfR}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}



\paragraph{\texttt{mallet} Module}
\label{tethne.readers:module-tethne.readers.mallet}\label{tethne.readers:mallet-module}\index{tethne.readers.mallet (module)}
Reader for output from topic modeling with MALLET.
\index{load() (in module tethne.readers.mallet)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.mallet.load}\pysiglinewithargsret{\code{tethne.readers.mallet.}\bfcode{load}}{\emph{top\_doc}, \emph{word\_top}, \emph{topic\_keys}, \emph{Z}, \emph{metadata=None}, \emph{metadata\_key='doi'}}{}
Parse results from LDA modeling with MALLET.

MALLET's LDA topic modeling algorithm produces a collection of output files.
{\hyperref[tethne.readers:tethne.readers.mallet.read]{\code{read()}}} takes the topic-document and (sparse) word-topic matrices, as
tab-separated value files, along with a metadata file that maps
each MALLET document id to a {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}, using the \emph{metadata\_key}.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{top\_doc} : string
\begin{quote}

Path to topic-document datafile generated with --output-doc-topics.
\end{quote}

\textbf{word\_top} : string
\begin{quote}

Path to word-topic datafile generated with --word-topic-counts-file.
\end{quote}

\textbf{topic\_keys} : string
\begin{quote}

Path to topic-keys datafile generated with --output-topic-keys.
\end{quote}

\textbf{Z} : int
\begin{quote}

Number of topics.
\end{quote}

\textbf{metadata} : string (optional)
\begin{quote}

Path to tab-separated metadata file with IDs and {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} keys.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{ldamodel} : {\hyperref[tethne:tethne.data.LDAModel]{\code{LDAModel}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{read() (in module tethne.readers.mallet)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.mallet.read}\pysiglinewithargsret{\code{tethne.readers.mallet.}\bfcode{read}}{\emph{top\_doc}, \emph{word\_top}, \emph{topic\_keys}, \emph{Z}, \emph{metadata=None}, \emph{metadata\_key='doi'}}{}
Generates {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects from Mallet output.

Each {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} is assigned a topic vector.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{top\_doc} : string
\begin{quote}

Path to topic-document datafile generated with --output-doc-topics.
\end{quote}

\textbf{word\_top} : string
\begin{quote}

Path to word-topic datafile generated with --word-topic-counts-file.
\end{quote}

\textbf{topic\_keys} : string
\begin{quote}

Path to topic-keys datafile generated with --output-topic-keys.
\end{quote}

\textbf{Z} : int
\begin{quote}

Number of topics.
\end{quote}

\textbf{metadata} : string (optional)
\begin{quote}

Path to tab-separated metadata file with IDs and {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} keys.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

List of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{\texttt{pubmed} Module}
\label{tethne.readers:pubmed-module}\label{tethne.readers:module-tethne.readers.pubmed}\index{tethne.readers.pubmed (module)}
Methods for working with PubMed data are still under development. Please use
with care.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.readers:tethne.readers.pubmed.read]{\code{read}}}(filepath)
 & 
Given a file with PubMed XML, return a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\\\hline
\end{longtable}

\index{read() (in module tethne.readers.pubmed)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.pubmed.read}\pysiglinewithargsret{\code{tethne.readers.pubmed.}\bfcode{read}}{\emph{filepath}}{}
Given a file with PubMed XML, return a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.

See the following hyperlinks regarding possible structures of XML:
* \href{http://www.ncbi.nlm.nih.gov/pmc/pmcdoc/tagging-guidelines/citations/v2/citationtags.html\#2Articlewithmorethan10authors\%28listthefirst10andaddetal\%29}{http://www.ncbi.nlm.nih.gov/pmc/pmcdoc/tagging-guidelines/citations/v2/citationtags.html\#2Articlewithmorethan10authors\%28listthefirst10andaddetal\%29}
* \href{http://dtd.nlm.nih.gov/publishing/}{http://dtd.nlm.nih.gov/publishing/}

Each {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} is tagged with an accession id for this
read/conversion.

\textbf{Usage}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{pubmed}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/PubMedData.xml}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{filepath} : string
\begin{quote}

Path to PubMed XML file.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{meta\_list} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{\texttt{wos} Module}
\label{tethne.readers:wos-module}\label{tethne.readers:module-tethne.readers.wos}\index{tethne.readers.wos (module)}
Reader for Web of Science field-tagged bibliographic data.

Tethne parses Web of Science field-tagged data into a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} 
objects. This is a two-step process: data are first parsed into a list of 
dictionaries with field-tags as keys, and then each dictionary is converted to a
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} . {\hyperref[tethne.readers:tethne.readers.wos.read]{\code{readers.wos.read()}}} performs both steps in sequence.


\subparagraph{One-step Parsing}
\label{tethne.readers:one-step-parsing}
The method {\hyperref[tethne.readers:tethne.readers.wos.read]{\code{readers.wos.read()}}} performs both {\hyperref[tethne.readers:tethne.readers.wos.parse]{\code{readers.wos.parse()}}} 
and {\hyperref[tethne.readers:tethne.readers.wos.convert]{\code{readers.wos.convert()}}} . This is the preferred (simplest) approach in
most cases.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/savedrecs.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+go}{\PYGZlt{}tethne.data.Paper instance at 0x101b575a8\PYGZgt{}}
\end{Verbatim}

Alternatively, if you have many data files saved in the same directory, you can 
use {\hyperref[tethne.readers:tethne.readers.wos.from_dir]{\code{readers.wos.from\_dir()}}} :

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{parse\PYGZus{}from\PYGZus{}dir}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}


\subparagraph{Two-step Parsing}
\label{tethne.readers:two-step-parsing}
Use the two-step approach if you need to access fields not included in 
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}}, or if you wish to perform some intermediate manipulation on
the raw parsed data.

First import the {\hyperref[tethne.readers:module-tethne.readers.wos]{\code{readers.wos}}} module:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\end{Verbatim}

Then parse the WoS data to a list of field-tagged dictionaries using 
{\hyperref[tethne.readers:tethne.readers.wos.parse]{\code{readers.wos.parse()}}} :

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wos\PYGZus{}list} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{parse}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/savedrecs.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wos\PYGZus{}list}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{[\PYGZsq{}EM\PYGZsq{}, \PYGZsq{}\PYGZsq{}, \PYGZsq{}CL\PYGZsq{}, \PYGZsq{}AB\PYGZsq{}, \PYGZsq{}WC\PYGZsq{}, \PYGZsq{}GA\PYGZsq{}, \PYGZsq{}DI\PYGZsq{}, \PYGZsq{}IS\PYGZsq{}, \PYGZsq{}DE\PYGZsq{}, \PYGZsq{}VL\PYGZsq{}, \PYGZsq{}CY\PYGZsq{}, \PYGZsq{}AU\PYGZsq{}, \PYGZsq{}JI\PYGZsq{}, }
\PYG{g+go}{ \PYGZsq{}AF\PYGZsq{}, \PYGZsq{}CR\PYGZsq{}, \PYGZsq{}DT\PYGZsq{}, \PYGZsq{}TC\PYGZsq{}, \PYGZsq{}EP\PYGZsq{}, \PYGZsq{}CT\PYGZsq{}, \PYGZsq{}PG\PYGZsq{}, \PYGZsq{}PU\PYGZsq{}, \PYGZsq{}PI\PYGZsq{}, \PYGZsq{}RP\PYGZsq{}, \PYGZsq{}J9\PYGZsq{}, \PYGZsq{}PT\PYGZsq{}, }
\PYG{g+go}{ \PYGZsq{}LA\PYGZsq{}, \PYGZsq{}UT\PYGZsq{}, \PYGZsq{}PY\PYGZsq{}, \PYGZsq{}ID\PYGZsq{}, \PYGZsq{}SI\PYGZsq{}, \PYGZsq{}PA\PYGZsq{}, \PYGZsq{}SO\PYGZsq{}, \PYGZsq{}Z9\PYGZsq{}, \PYGZsq{}PD\PYGZsq{}, \PYGZsq{}TI\PYGZsq{}, \PYGZsq{}SC\PYGZsq{}, \PYGZsq{}BP\PYGZsq{}, }
\PYG{g+go}{ \PYGZsq{}C1\PYGZsq{}, \PYGZsq{}NR\PYGZsq{}, \PYGZsq{}RI\PYGZsq{}, \PYGZsq{}ER\PYGZsq{}, \PYGZsq{}SN\PYGZsq{}]}
\end{Verbatim}

Convert those field-tagged dictionaries to {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects using 
{\hyperref[tethne.readers:tethne.readers.wos.convert]{\code{readers.wos.convert()}}} :

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{convert}\PYG{p}{(}\PYG{n}{wos\PYGZus{}list}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+go}{\PYGZlt{}tethne.data.Paper instance at 0x101b575a8\PYGZgt{}}
\end{Verbatim}


\subparagraph{Methods}
\label{tethne.readers:methods}
\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.readers:tethne.readers.wos.convert]{\code{convert}}}(wos\_data)
 & 
Convert parsed field-tagged data to {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\\\hline

{\hyperref[tethne.readers:tethne.readers.wos.from_dir]{\code{from\_dir}}}(path)
 & 
Convenience function for generating a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} from a
\\\hline

{\hyperref[tethne.readers:tethne.readers.wos.parse]{\code{parse}}}(filepath)
 & 
Parse Web of Science field-tagged data.
\\\hline

{\hyperref[tethne.readers:tethne.readers.wos.read]{\code{read}}}(datapath)
 & 
Yields a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances from a Web of Science data file.
\\\hline
\end{longtable}

\index{DataError}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.wos.DataError}\pysigline{\strong{exception }\code{tethne.readers.wos.}\bfcode{DataError}}
Bases: \code{exceptions.Exception}

\end{fulllineitems}

\index{convert() (in module tethne.readers.wos)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.wos.convert}\pysiglinewithargsret{\code{tethne.readers.wos.}\bfcode{convert}}{\emph{wos\_data}}{}
Convert parsed field-tagged data to {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.

Convert a dictionary or list of dictionaries with keys from the
Web of Science field tags into a {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instance or list of
{\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances, the standard for Tethne.

Each {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} is tagged with an accession id for this conversion.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{wos\_data} : list
\begin{quote}

A list of dictionaries with keys from the WoS field tags.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\end{description}\end{quote}
\paragraph{Notes}

Need to handle author name anomolies (case, blank spaces, etc.) that may
make the same author appear to be two different authors in Networkx; this is
important for any graph with authors as nodes.
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wos\PYGZus{}list} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{parse}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/data.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{convert}\PYG{p}{(}\PYG{n}{wos\PYGZus{}list}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}

\index{from\_dir() (in module tethne.readers.wos)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.wos.from_dir}\pysiglinewithargsret{\code{tethne.readers.wos.}\bfcode{from\_dir}}{\emph{path}}{}
Convenience function for generating a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} from a
directory of Web of Science field-tagged data files.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{path} : string
\begin{quote}

Path to directory of field-tagged data files.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} objects.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{IOError} :
\begin{quote}

Invalid path.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{from\PYGZus{}dir}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/datadir}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}

\index{parse() (in module tethne.readers.wos)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.wos.parse}\pysiglinewithargsret{\code{tethne.readers.wos.}\bfcode{parse}}{\emph{filepath}}{}
Parse Web of Science field-tagged data.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{filepath} : string
\begin{quote}

Filepath to the Web of Science plain text file.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{wos\_list} : list
\begin{quote}

A list of dictionaries each associated with a paper from the Web of
Science with keys from docs/fieldtags.txt as encountered in the file;
most values associated with keys are strings with special exceptions
defined by the list\_keys and int\_keys variables.
\end{quote}

\item[{Raises }] \leavevmode
\textbf{KeyError} : Key value which needs to be converted to an `int' is not present.

\textbf{AttributeError :} :

\textbf{IOError} : File at filepath not found, not readable, or empty.

\end{description}\end{quote}
\paragraph{Notes}

Unknown keys: RI, OI, Z9
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wos\PYGZus{}list} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{parse}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/data.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}

\index{read() (in module tethne.readers.wos)}

\begin{fulllineitems}
\phantomsection\label{tethne.readers:tethne.readers.wos.read}\pysiglinewithargsret{\code{tethne.readers.wos.}\bfcode{read}}{\emph{datapath}}{}
Yields a list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances from a Web of Science data file.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{datapath} : string
\begin{quote}

Filepath to the Web of Science field-tagged data file.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{papers} : list
\begin{quote}

A list of {\hyperref[tethne:tethne.data.Paper]{\code{Paper}}} instances.
\end{quote}

\end{description}\end{quote}
\paragraph{Examples}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Path/to/data.txt}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}



\subsubsection{utilities Package}
\label{tethne.utilities:utilities-package}\label{tethne.utilities::doc}

\paragraph{\texttt{utilities} Package}
\label{tethne.utilities:id1}\phantomsection\label{tethne.utilities:module-tethne.utilities}\index{tethne.utilities (module)}
Helper functions for {\hyperref[tethne.networks:module-tethne.networks]{\code{tethne.networks}}} .
\index{Dictionary (class in tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.Dictionary}\pysigline{\strong{class }\code{tethne.utilities.}\bfcode{Dictionary}}
A two-way index for integer/string pairs.

\end{fulllineitems}

\index{attribs\_to\_string() (in module tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.attribs_to_string}\pysiglinewithargsret{\code{tethne.utilities.}\bfcode{attribs\_to\_string}}{\emph{attrib\_dict}, \emph{keys}}{}
A more specific version of the subdict utility aimed at handling
node and edge attribute dictionaries for NetworkX file formats such as
gexf (which does not allow attributes to have a list type) by making
them writable in those formats

\end{fulllineitems}

\index{concat\_list() (in module tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.concat_list}\pysiglinewithargsret{\code{tethne.utilities.}\bfcode{concat\_list}}{\emph{listA}, \emph{listB}, \emph{delim=' `}}{}
Concatenate list elements pair-wise with the delim character
Returns the concatenated list
Raises index error if lists are not parallel

\end{fulllineitems}

\index{contains() (in module tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.contains}\pysiglinewithargsret{\code{tethne.utilities.}\bfcode{contains}}{\emph{l}, \emph{f}}{}
Searches list l for a pattern specified in a lambda function f.

\end{fulllineitems}

\index{dict\_from\_node() (in module tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.dict_from_node}\pysiglinewithargsret{\code{tethne.utilities.}\bfcode{dict\_from\_node}}{\emph{node}, \emph{recursive=False}}{}
Converts ElementTree node to a dictionary.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{node} : ElementTree node

\textbf{recursive} : boolean
\begin{quote}

If recursive=False, the value of any field with children will be the
number of children.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{dict} : nested dictionary.
\begin{quote}

Tags as keys and values as values. Sub-elements that occur multiple
times in an element are contained in a list.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{overlap() (in module tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.overlap}\pysiglinewithargsret{\code{tethne.utilities.}\bfcode{overlap}}{\emph{listA}, \emph{listB}}{}
Return list of objects shared by listA, listB.

\end{fulllineitems}

\index{strip\_non\_ascii() (in module tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.strip_non_ascii}\pysiglinewithargsret{\code{tethne.utilities.}\bfcode{strip\_non\_ascii}}{\emph{string}}{}
Returns the string without non-ASCII characters.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{string} : string
\begin{quote}

A string that may contain non-ASCII characters.
\end{quote}

\item[{Returns }] \leavevmode
\textbf{clean\_string} : string
\begin{quote}

A string that does not contain non-ASCII characters.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{subdict() (in module tethne.utilities)}

\begin{fulllineitems}
\phantomsection\label{tethne.utilities:tethne.utilities.subdict}\pysiglinewithargsret{\code{tethne.utilities.}\bfcode{subdict}}{\emph{super\_dict}, \emph{keys}}{}
Returns a subset of the super\_dict with the specified keys.

\end{fulllineitems}



\subsubsection{writers Package}
\label{tethne.writers:writers-package}\label{tethne.writers::doc}

\paragraph{\texttt{writers} Package}
\label{tethne.writers:id1}\phantomsection\label{tethne.writers:module-tethne.writers}\index{tethne.writers (module)}
Export networks to structured and unstructured formats, for visualization.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.writers:module-tethne.writers.collection]{\code{collection}}}
 & 
Write {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to a structured data format.
\\\hline

{\hyperref[tethne.writers:module-tethne.writers.graph]{\code{graph}}}
 & 
Write NetworkX graphs to structured and unstructured network file formats.
\\\hline

{\hyperref[tethne.writers:module-tethne.writers.matrix]{\code{matrix}}}
 & 
Methods for writing matrices to commonly-used file formats, for external visualization and analysis.
\\\hline
\end{longtable}



\paragraph{\texttt{collection} Module}
\label{tethne.writers:module-tethne.writers.collection}\label{tethne.writers:collection-module}\index{tethne.writers.collection (module)}
Write {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to a structured data format.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.writers:tethne.writers.collection.to_dxgmml]{\code{to\_dxgmml}}}(C, path)
 & 
Writes a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to
\\\hline
\end{longtable}

\index{to\_dxgmml() (in module tethne.writers.collection)}

\begin{fulllineitems}
\phantomsection\label{tethne.writers:tethne.writers.collection.to_dxgmml}\pysiglinewithargsret{\code{tethne.writers.collection.}\bfcode{to\_dxgmml}}{\emph{C}, \emph{path}}{}
Writes a {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to 
\href{https://code.google.com/p/dynnetwork/wiki/DynamicXGMML}{dynamic XGMML.}.

Dynamic XGMML is a schema for describing dynamic networks in Cytoscape 3.0.
This method assumes that \emph{Graph} indices are orderable points in time 
(e.g. years). The ``start'' and ``end'' of each node and edge are determined by 
periods of consecutive appearance in the {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} . Node 
and edge attributes are defined for each \emph{Graph}. in the 
{\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}.

For example, to build and visualize an evolving co-citation network:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Load some data.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.readers} \PYG{k+kn}{as} \PYG{n+nn}{rd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{papers} \PYG{o}{=} \PYG{n}{rd}\PYG{o}{.}\PYG{n}{wos}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{n}{datapath}\PYG{p}{)}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Build a DataCollection, and slice it temporally using a}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{}  4\PYGZhy{}year sliding time\PYGZhy{}window.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.data} \PYG{k+kn}{import} \PYG{n}{DataCollection}\PYG{p}{,} \PYG{n}{GraphCollection}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D} \PYG{o}{=} \PYG{n}{DataCollection}\PYG{p}{(}\PYG{n}{papers}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{D}\PYG{o}{.}\PYG{n}{slice}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{time\PYGZus{}window}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{window\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Generate a GraphCollection of co\PYGZhy{}citation graphs.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{tethne.builders} \PYG{k+kn}{import} \PYG{n}{paperCollectionBuilder}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{builder} \PYG{o}{=} \PYG{n}{paperCollectionBuilder}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{C} \PYG{o}{=} \PYG{n}{builder}\PYG{o}{.}\PYG{n}{build}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{date}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{cocitation}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threshold}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c}{\PYGZsh{} Write the GraphCollection as a dynamic network.}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{tethne.writers} \PYG{k+kn}{as} \PYG{n+nn}{wr}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{wr}\PYG{o}{.}\PYG{n}{collection}\PYG{o}{.}\PYG{n}{to\PYGZus{}dxgmml}\PYG{p}{(}\PYG{n}{C}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/path/to/network.xgmml}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{C} : {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}}
\begin{quote}

The {\hyperref[tethne:tethne.data.GraphCollection]{\code{GraphCollection}}} to be written to XGMML.
\end{quote}

\textbf{path} : str
\begin{quote}

Path to file to be written. Will be created/overwritten.
\end{quote}

\end{description}\end{quote}
\paragraph{Notes}

Period start and end dates in this method are inclusive, whereas XGMML end
dates are exclusive. Hence +1 is added to all end dates when writing XGMML.

\end{fulllineitems}



\paragraph{\texttt{graph} Module}
\label{tethne.writers:module-tethne.writers.graph}\label{tethne.writers:graph-module}\index{tethne.writers.graph (module)}
Write NetworkX graphs to structured and unstructured network file formats.

Many methods simply invoke equivalent methods in NetworkX.

\begin{longtable}{ll}
\hline
\endfirsthead

\multicolumn{2}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline
\endhead

\hline \multicolumn{2}{|r|}{{Continued on next page}} \\ \hline
\endfoot

\hline
\endlastfoot


{\hyperref[tethne.writers:tethne.writers.graph.to_gexf]{\code{to\_gexf}}}(graph, output\_path)
 & 
Writes graph to \href{http://gexf.net}{GEXF}.
\\\hline

{\hyperref[tethne.writers:tethne.writers.graph.to_graphml]{\code{to\_graphml}}}(graph, output\_path)
 & 
Writes graph to \href{http://graphml.graphdrawing.org/}{GraphML}.
\\\hline

{\hyperref[tethne.writers:tethne.writers.graph.to_sif]{\code{to\_sif}}}(graph, output\_path)
 & 
Generates Simple Interaction Format output file from provided graph.
\\\hline
\end{longtable}

\index{to\_gexf() (in module tethne.writers.graph)}

\begin{fulllineitems}
\phantomsection\label{tethne.writers:tethne.writers.graph.to_gexf}\pysiglinewithargsret{\code{tethne.writers.graph.}\bfcode{to\_gexf}}{\emph{graph}, \emph{output\_path}}{}
Writes graph to \href{http://gexf.net}{GEXF}.

Uses the NetworkX method
\href{http://networkx.lanl.gov/reference/generated/networkx.readwrite.gexf.write\_gexf.html}{write\_gexf}.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{graph} : networkx.Graph
\begin{quote}

The Graph to be exported to GEXF.
\end{quote}

\textbf{output\_path} : str
\begin{quote}

Full path, including filename (without suffix).
e.g. using ''./graphFolder/graphFile'' will result in a GEXF file at
./graphFolder/graphFile.gexf.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{to\_graphml() (in module tethne.writers.graph)}

\begin{fulllineitems}
\phantomsection\label{tethne.writers:tethne.writers.graph.to_graphml}\pysiglinewithargsret{\code{tethne.writers.graph.}\bfcode{to\_graphml}}{\emph{graph}, \emph{output\_path}}{}
Writes graph to \href{http://graphml.graphdrawing.org/}{GraphML}.

Uses the NetworkX method 
\href{http://networkx.lanl.gov/reference/generated/networkx.readwrite.graphml.write\_graphml.html}{write\_graphml}.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{graph} : networkx.Graph
\begin{quote}

The Graph to be exported to GraphML.
\end{quote}

\textbf{output\_path} : str
\begin{quote}

Full path, including filename (without suffix).
e.g. using ''./graphFolder/graphFile'' will result in a GraphML file at
./graphFolder/graphFile.graphml.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{to\_sif() (in module tethne.writers.graph)}

\begin{fulllineitems}
\phantomsection\label{tethne.writers:tethne.writers.graph.to_sif}\pysiglinewithargsret{\code{tethne.writers.graph.}\bfcode{to\_sif}}{\emph{graph}, \emph{output\_path}}{}
Generates Simple Interaction Format output file from provided graph.

The SIF specification is described 
\href{http://wiki.cytoscape.org/Cytoscape\_User\_Manual/Network\_Formats}{here}.

{\hyperref[tethne.writers:tethne.writers.graph.to_sif]{\code{to\_sif()}}} will generate a .sif file describing the network, and a few
.eda and .noa files containing edge and node attributes, respectively. These
are equivalent to tab-delimited tables, and can be imported as such in
Cytoscape 3.0.
\begin{quote}\begin{description}
\item[{Parameters }] \leavevmode
\textbf{graph} : networkx.Graph
\begin{quote}

The Graph to be exported to SIF.
\end{quote}

\textbf{output\_path} : str
\begin{quote}

Full path, including filename (without suffix).
e.g. using ''./graphFolder/graphFile'' will result in a SIF file at
./graphFolder/graphFile.sif, and corresponding .eda and .noa files.
\end{quote}

\end{description}\end{quote}

\end{fulllineitems}

\index{to\_table() (in module tethne.writers.graph)}

\begin{fulllineitems}
\phantomsection\label{tethne.writers:tethne.writers.graph.to_table}\pysiglinewithargsret{\code{tethne.writers.graph.}\bfcode{to\_table}}{\emph{graph}, \emph{path}}{}
\end{fulllineitems}



\paragraph{\texttt{matrix} Module}
\label{tethne.writers:matrix-module}\label{tethne.writers:module-tethne.writers.matrix}\index{tethne.writers.matrix (module)}
Methods for writing matrices to commonly-used file formats, for external
visualization and analysis. Not yet implemented.


\chapter{About}
\label{index:about}
Tethne is developed by the ASU Digital Innovation Group (\href{http://devo-evo.lab.asu.edu/diging}{DigInG}), part of the Laubichler
Lab in the Center for Biology \& Society, School of Life Sciences.

This material is based upon work supported by the National Science Foundation Graduate
Research Fellowship Program under Grant No. 2011131209, and NSF Doctoral Dissertation
Research Improvement Grant No. 1256752.


\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\emph{genindex}

\item {} 
\emph{modindex}

\item {} 
\emph{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{t}
\item {\texttt{tethne.\_\_init\_\_}}, \pageref{tethne:module-tethne.__init__}
\item {\texttt{tethne.\_\_main\_\_}}, \pageref{tethne:module-tethne.__main__}
\item {\texttt{tethne.analyze}}, \pageref{tethne.analyze:module-tethne.analyze}
\item {\texttt{tethne.analyze.collection}}, \pageref{tethne.analyze:module-tethne.analyze.collection}
\item {\texttt{tethne.analyze.graph}}, \pageref{tethne.analyze:module-tethne.analyze.graph}
\item {\texttt{tethne.builders}}, \pageref{tethne:module-tethne.builders}
\item {\texttt{tethne.data}}, \pageref{tethne:module-tethne.data}
\item {\texttt{tethne.matrices}}, \pageref{tethne.matrices:module-tethne.matrices}
\item {\texttt{tethne.matrices.dfr}}, \pageref{tethne.matrices:module-tethne.matrices.dfr}
\item {\texttt{tethne.networks}}, \pageref{tethne.networks:module-tethne.networks}
\item {\texttt{tethne.networks.authors}}, \pageref{tethne.networks:module-tethne.networks.authors}
\item {\texttt{tethne.networks.helpers}}, \pageref{tethne.networks:module-tethne.networks.helpers}
\item {\texttt{tethne.networks.papers}}, \pageref{tethne.networks:module-tethne.networks.papers}
\item {\texttt{tethne.networks.terms}}, \pageref{tethne.networks:module-tethne.networks.terms}
\item {\texttt{tethne.networks.topics}}, \pageref{tethne.networks:module-tethne.networks.topics}
\item {\texttt{tethne.readers}}, \pageref{tethne.readers:module-tethne.readers}
\item {\texttt{tethne.readers.dfr}}, \pageref{tethne.readers:module-tethne.readers.dfr}
\item {\texttt{tethne.readers.mallet}}, \pageref{tethne.readers:module-tethne.readers.mallet}
\item {\texttt{tethne.readers.pubmed}}, \pageref{tethne.readers:module-tethne.readers.pubmed}
\item {\texttt{tethne.readers.wos}}, \pageref{tethne.readers:module-tethne.readers.wos}
\item {\texttt{tethne.utilities}}, \pageref{tethne.utilities:module-tethne.utilities}
\item {\texttt{tethne.workflow}}, \pageref{tethne:module-tethne.workflow}
\item {\texttt{tethne.writers}}, \pageref{tethne.writers:module-tethne.writers}
\item {\texttt{tethne.writers.collection}}, \pageref{tethne.writers:module-tethne.writers.collection}
\item {\texttt{tethne.writers.graph}}, \pageref{tethne.writers:module-tethne.writers.graph}
\item {\texttt{tethne.writers.matrix}}, \pageref{tethne.writers:module-tethne.writers.matrix}
\end{theindex}
\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{t}
\item {\texttt{tethne.\_\_init\_\_}}, \pageref{tethne:module-tethne.__init__}
\item {\texttt{tethne.\_\_main\_\_}}, \pageref{tethne:module-tethne.__main__}
\item {\texttt{tethne.analyze}}, \pageref{tethne.analyze:module-tethne.analyze}
\item {\texttt{tethne.analyze.collection}}, \pageref{tethne.analyze:module-tethne.analyze.collection}
\item {\texttt{tethne.analyze.graph}}, \pageref{tethne.analyze:module-tethne.analyze.graph}
\item {\texttt{tethne.builders}}, \pageref{tethne:module-tethne.builders}
\item {\texttt{tethne.data}}, \pageref{tethne:module-tethne.data}
\item {\texttt{tethne.matrices}}, \pageref{tethne.matrices:module-tethne.matrices}
\item {\texttt{tethne.matrices.dfr}}, \pageref{tethne.matrices:module-tethne.matrices.dfr}
\item {\texttt{tethne.networks}}, \pageref{tethne.networks:module-tethne.networks}
\item {\texttt{tethne.networks.authors}}, \pageref{tethne.networks:module-tethne.networks.authors}
\item {\texttt{tethne.networks.helpers}}, \pageref{tethne.networks:module-tethne.networks.helpers}
\item {\texttt{tethne.networks.papers}}, \pageref{tethne.networks:module-tethne.networks.papers}
\item {\texttt{tethne.networks.terms}}, \pageref{tethne.networks:module-tethne.networks.terms}
\item {\texttt{tethne.networks.topics}}, \pageref{tethne.networks:module-tethne.networks.topics}
\item {\texttt{tethne.readers}}, \pageref{tethne.readers:module-tethne.readers}
\item {\texttt{tethne.readers.dfr}}, \pageref{tethne.readers:module-tethne.readers.dfr}
\item {\texttt{tethne.readers.mallet}}, \pageref{tethne.readers:module-tethne.readers.mallet}
\item {\texttt{tethne.readers.pubmed}}, \pageref{tethne.readers:module-tethne.readers.pubmed}
\item {\texttt{tethne.readers.wos}}, \pageref{tethne.readers:module-tethne.readers.wos}
\item {\texttt{tethne.utilities}}, \pageref{tethne.utilities:module-tethne.utilities}
\item {\texttt{tethne.workflow}}, \pageref{tethne:module-tethne.workflow}
\item {\texttt{tethne.writers}}, \pageref{tethne.writers:module-tethne.writers}
\item {\texttt{tethne.writers.collection}}, \pageref{tethne.writers:module-tethne.writers.collection}
\item {\texttt{tethne.writers.graph}}, \pageref{tethne.writers:module-tethne.writers.graph}
\item {\texttt{tethne.writers.matrix}}, \pageref{tethne.writers:module-tethne.writers.matrix}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
